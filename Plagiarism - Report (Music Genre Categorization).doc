{\rtf1\ansi\deff0{\fonttbl{\f0\fnil\fcharset0 Segoe UI;}{\f1\fnil\fcharset0 Tahoma;}}
{\colortbl ;\red43\green57\blue66;\red255\green255\blue255;\red7\green81\blue160;\red255\green255\blue0;}
\viewkind4\uc1\pard\qc\cf1\highlight2\lang1033\f0\fs24{\pict\wmetafile8\picw3703\pich2857\picwgoal2099\pichgoal1620 
010009000003d05800000000ba5800000000050000000b0200000000050000000c02290b770eba
580000430f2000cc0000006c008c0000000000290b770e00000000280000008c0000006c000000
010018000000000030b10000c40e0000c40e00000000000000000000f6fffff7fefffffffefffd
fcfffefffcfefffafffefafffcfdfefffffdfffffdfffffcfffffefefffefdfffefffffffeffff
fefbfffcfbfffefafffdf8fefdf8fefdf9fdfef9fdfefdfffffdfffffcfefefcfefefafffdfaff
fdf9fffbfafffdfffefffffefffdfefafdfff9fffffbfffffcfafbfff8fbfffdfefffdfefffffe
fffdfffffdfffffdfffefffffcfffffcfffffeffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffdfffffdfefffbfefffafdfffafffffaff
fffafffefbfffffbfffffffdfffffefffffefdfffffcfffffefffcfdfffcfffffbfffffefffffe
fffffefffffefffffefffffefffffefffffefffffefffffefffffefffffefffffefffffefffffe
fffffefffffffffffffffffffffffffffffefffffefffffefffffefffffefffffefffffefffffe
fffffefffffefffffefffbfffff8fffcf6fff9fbfffbfffffcfffdfffffdfffffffefffffeffff
fffbfdfefdfdfdfffefffffbfffffafffffefffdfcfeffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffafdfffafefffdfffefafdfbfefdfffcfefffaff
fefafffdfcfefffffefffffdfffffdfffefdfffffefefffcfdfffcfdfbfefcf8fffcf8fefdf8fe
fdf5fdfdf5fdfdf7fcfff8fdfff7fafef7fafef7fafef7fbfcf7fbfcf6fcfbf7fdfcf7fdfcf9f8
fcfcfbfff8fdfcf6fbf9fbfcf8fcfdfbfbfcfffdfdfffffefffffefffffffffffffefdfffefdff
fefffffcfffffcffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffdfffffbfefffbfefffbfefffbfffffbfffefbfffffbff
fffdfefffffefffdfefcfffffcfffefffffdfffffefffffdfffffefffffefffffefffffefffffe
fffffefffffefffffefffffefffffefffffefffffefffffefffffefffffefffffeffffffffffff
fffffffffffffffffefffffefffffefffffffffffefffffffffffefffffefffffefffffefffffe
fffdfffffbfffcfbfffbfdfffcfffffefffdfffffdfffffefffffffffffefffdfffffcfefefffe
fffffdfffffbfffffeffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffefffdfcf6fbf9edf4f1edf2f0ecf1efeef3f1eef1eff1f1f1f1f0
f2efeef7efeef7ebeef2eaeeefeceeefebedeeeaeff0e7efefe4edf0e4edf0e5eef2e5eef2e6ec
f3e6ebf4e7e9f4e8eaf5e8eaf4e8eaf4e8eaf4e6ecf3e6ecf3e6ecf1e8ecf1ebeef6e5ebf2e0e6
ebe7ecedf2f6f7fafafffefbfffffdfffffefffffffbfffff9fdfffbfbfffcfdfffeffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffefffffefffffefffffefffffefffffffffdfffefbfffefbfffff8fcfdeff4
f3eef3f2f2f3f7f2f3f7f5f4f6f3f2f4f4f3f5f4f3f5f4f3f5f4f3f5f4f3f5f4f3f5f4f3f5f4f3
f5f4f3f5f4f3f5f4f3f5f4f3f5f4f3f5f4f3f5f4f3f5f4f3f5f4f3f5f2f4f5f4f3f5f4f3f5f4f4
f4f4f4f4f4f4f4f4f5f3f4f4f4f4f5f3f6f4f4f6f4f4f6f4f4f6f4f4f6f4f4f6f4f4f7f2f3f7f2
f3f8f1f4f9f2f5f9f2f7f8f2f7f7f2f4f5f1f6f5f3f9fdfefffdfffffcfffdfffefffffdfffffe
fffffffeffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffe2e8edd3e3eab6d9e69ecbd99ac6d396c2cf9ac3d29ac0d29ec2d29bc1d394bed590bcd38fbc
d18ebcce8ebbd08fbcd18ebbd089b8cd87b6cc84b4cc84b4cc86b3ce83afcc84adcd81a9cc83a9
cc84a8cc82a8ca80a6c87ca5c57aa3c378a1c17ba2c27aa3c477a0c185a8c2b3c7d2e2ebeff9fc
fffefdfffffefffffffefffffbfffffbfffffcfdfffefdfffffdffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffe
fffffefffffefffffefffffffffffffefdfffcfafffff5f9ffe6e8ffd5d7f9cdd0f6cfd0f6cfd0
f6d0d2f5cfd0f2d0d0f4d0d0f4d0cff6d0d0f4d0cff6d0d0f4d0cff6d0d0f4d0cff6d0d0f4d0cf
f6d0d0f4d0cff6d0d0f4d0cff6d0cff6d0cff6d0cff6d0cff6d0d0f4d0d0f4d0d1f3d2d1f1d2d1
f1d2d1f1d2d1f1d2d1f1d2d2f0d2d2f0d2d2f0d2d2f0d4d1f1d8d1f4d7d0f3d6d0f3d4d0f3d2d0
f4d3d0f0d4d0edd4d2e6e7e6f0fafcfdfdfffefcfffbfffffefffffffffefdfffdfcffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffbae2f484bdd747a6
ce36a8d733aad72ea5d236a9db33a3d734a4d930a6da2daadd2dade030afe231b0e331afe531af
e634afe737b2ec35afeb35afeb36afed2ea4e5269be02ea0e72e9ce82f9cea2f9be92e9ae8309c
ea2d9be72b9ae32e9ce82c97e8319dee2d9be747a1da82adc8d2e1eaeaf1f4fdfffefffffeffff
fefffffefffffffffbfffffdfffffefffefefeffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffefffffe
fffffffcfffffbfafffef4fbffb5b3ee5855ab514db44c49b74e4eb84d4eb64d4fb54d4eb64e4e
b84e4eb84e4eba4e4eb84e4eba4e4eb84e4eba4e4eb84e4eba4e4eb84e4eba4e4eb84e4eba4e4e
b84e4eba4e4eba4d4cba514ebc4e4bb84d4bb5514fb94f4eb6504db45452b64f4eb04645a74443
a54746a64645a54544a44645a54644a44941a54d48ab4044a33c44a24148a940469f44458f8486
b6e4e6f8f8fdfbfdfffbfbfef5fffffbfffffefffcfdfffeffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffcffaffacecff50b9ec25ade819b2f116b3
f514aef515aff814aef910aff90cb2f70ab3f70bb1f60ab0f709aef708acf809abf90dadfb0aac
fb0aacfb0dabfe06a3fa009af30298f60496f90696fc0494fa0494fa0797fd0696fb0496f90597
fb0696ff0291fa0797fc289eef5599c8a9cadedeeaeefdfffcfefffbfefffbfffffffffefffffa
fffffcfffffefffdfdfdffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffefffffffffefffffefffffffcfffffcfaff
fff3f7ff9996e63229a12c23b32823bc2322b81d1fb32123b72123b71f20b81f20b81f20b81f20
b81f20b81f20b81f20b81f20b81f20b81f20b81f20b81f20b81f20b81f20b81f20b81f20b82321
bb211fb92422bb2322b8211fb52423b52525b5201ead12119d0c0b970b0b950d0d970c0c940a0d
940c0c940c0c96110b980d0a96060c93020e92060f950c138e1d1e806d6dadebeefffcfffdffff
fbfdfff7fffffbfffffefffcfefffeffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffecfdffd7fbff94dbff3fabe11cabef0cacfa09a6f609a7fa07a8
fc05a9fb03abf803acf705acf707abf808aafc08a9fd07a8fc08a9fd07a8fc07a8fc09aaff06a6
fe009bf80092f40092fa0292fc018ffe008efd0391ff0392ff0292fc0092fc0094ff008ff90592
f91c9af33899dd69a7d0cbdfeaf5f4f0fffffbfffffcfffffffefdfffcfcfffdfdfffdfffffdff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffefdfffcfdfffefffefffffefffffffffdfffff8fefff3f5ff9b94ef261c
9e1e16b01915ba1616bc1417bf1115c10e12be1315c11515c11515c11515c11515c11515c11515
c11515c11515c11515c11515c11515c11515c11515c11515c11515c11515c11414c01614c11615
bf1715bb1a19bd1615b80b0aa804039f02019d04049e05059f03039d01039d04049e03039d0400
9f0905a40307a202079f02059609098b1b167f827ac0f9f6fffffefffffffefffffcfdfffefcfe
fefbfdfdffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffff7fcffecfdffd0f9ff85d3fe2dabec12a9f90da8fd08a9ff02a9ff01aaff04aafd06ab
fa06abfa06aafc09aaff09a9ff05a7ff03a8fe06a9ff06a9ff06a8ff07a9ff02a0fe0093f60092
fa0192ff028fff018eff028fff0390ff0290ff008ffe0090fe0192ff0390f90f92f3269df33f96
d4a0c2d9e3e8e9fafdfbfefffbfffefefdfcfefcfdfffbfffffdfffffdffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffdfffefdfffefffffffffefffffefffffefffbfdfff6f6ffb6b0f74e48ad3b38b3201ead1211
b41414c41013c91315cd1111c91112c81112c81112c81112c81112c81112c81112c81112c81112
c81112c81112c81112c81112c81112c81112c81011c71213c91110c41111c31816c61414c00807
b10000a60000a30000a30001a30001a30000a20000a20001a30000a10100a40100a300009b0405
950a0c8836359d6f69bac9c3fafbf8fffefdfffffefdfffffefdfffffafefffdfffffdffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff8fcfdf6ff
ffedfdffc7f3ff62c1f921a4ee17abfd09a9ff00a8ff00a8ff05a7ff08a7fe06a7fb06a7fd07a5
ff06a5ff03a8ff01a9fe04a9ff04aafd03a8fe08aaff07a6ff009afb0094f90193fd0492ff0491
ff0390ff0390ff0492ff0391ff028fff0592ff0392fb0591f60b93f92f9aeb6ba0c5c9dce9eaf1
f4fcfafafffefffffefffffffffdfffffefffdfefffdffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffeffffffffffff
fefffffffffefffffefffffefffdfcfff8f6ffebecffd6daff7f81d92f28b11912b91a15ca0f0c
c61111c91111c91111c91111c91111c91111c91111c91111c91111c91111c91111c91111c91111
c91111c91111c91111c91112c81314ca1213c71414c41615c30b0bb70000a90000a40000a50102
a60001a50000a40001a50102a60001a50001a30407a603049c0b0b952324948084cbd6dbfff4f6
fff5f5fffdfcfffcfefffffffcfdfffcfcfdfffdfdfffffefffefefeffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffdfffffbfdfdfcfeffe5fcffa9ea
ff52b8f31da7f00ba9fd01a8ff00a8ff06a8ff08a8ff07aaff07aaff07a9ff07a9ff01a8ff00a7
fe02aaff02aafd02a7fd05aaff09a8ff04a1ff0095f80092fa0290ff0492ff028fff0391ff0493
ff0592ff0690ff048eff0391fc0393fc0393fd209af44997cc95bdd9dae6f0faf8f8fffdfffffe
fffffefdfffffefefffdfffffeffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffefffffefffffffefffffeffffffffff
fffffffffffffefbfcfaf8fbfff1f8ffe8ecff817bf2221abb100cbf1514ce1010c81011c71010
c81011c71010c81011c71010c81011c71010c81011c71010c81011c71010c81011c71010c81011
c71112c60f10c41315c71515c50a0ab60000a90000a60000a40000a40001a50000a40000a30000
a40001a50000a30102a00306970c0e8b4342aabcbbfff3f5fff7fafff0f3f8fdfffffcfefffdff
fffffffbfffffcfefdfffffdfffffefffdfdfdffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffefffbfdfefafbfcfaf4ffffddfbffa1e5ff3ab2ee13aa
f508a9ff02a8ff04a9ff04a9ff01a9fe00a9fe00a9fe00a8fd00a7fe00a7fe01aaff02aaff03a9
fc03a8fe08a8ff08a5ff0098fa0091f70190fd0491ff0390ff028ffd0492fd0391fc0691ff028c
fc028ffd0494fe0697fd0f97f1339fe6589fcbc0d5e4f3eeeffffdfffffdfffffdfcfefffbfdff
fefbfffeffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffdfffffdfffffbfffefdfffeffffffffffffffff
fffcfefff4faffebf1ff706ddb211db81212c20e12c91011c71211c51210c71211c51210c71211
c51210c71211c51210c71211c51210c71211c51210c71211c51210c71211c51214c61114c31415
c30c0eba0101ab0000a60101a70001a50201a50302a50201a40100a30302a60201a50000a50506
9e0f0f8b6061b9dbdcfff6f6fff7f3fffffcfffffdfffdfcfefcfffdfffffcfffffbfffffcfffe
fffffefffdfffffcfefeffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffdfff9fefffafffffcf8fafbf4feffd4fcff7bd5fe2cace715a9f707a8fe03a8
fe01a9fe00a9fe00aafc00aafc00a9fe00a8ff00a7fe01a9fe02aaff06aafd04a7fd05a7ff09a8
ff059ffe0095f90091fb0493ff0391ff0390fe0391fc0490fb0792ff028ffd0592ff0494fe008e
f40795f41f9df53995d697b9d6dbdee6f9f8fcfffefefffffcfffffcfafffdfafffdfdffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffdfffffdfffffdfffefdfffefdfffffffefffffefefbfbfbf8feffd8dd
ff4544b81e1cbc1518c70d11c71213c91413c71413c71413c71413c71413c71413c71413c71413
c71413c71413c71413c71413c71413c71412c91413c71212c41718c60d0fbb0001a90000a40001
a50000a40001a50000a30201a50100a40200a30400a50400a00404980f0f8b6869c1dddefff7fa
fffffffffffefffffcfffffcfffaf9fbfffffefffffcfffffbfffefafffefffffefffcfefefdff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff8ff
f6fdfffbfdfbfbfffdfff9fcffe9feffc3f7ff76cff12aabea0da5f608a8fc01a6fc00aafc02ad
fd00a5fa05aaff02a9ff02aaff04a9ff06aafd09a9fd08a9ff04a8ff04a8ff09a9ff009bf80093
fb0092ff0090ff028fff0792ff0790fe0592ff0291fe0091fe0294fe0094fc0191fa0c93fb319b
f06195c4bed3e8e0ebeffdfffcfbfffafcfffdf7fcfafbfffefdfffefffffefdfffefdfffeffff
fffffffffffffefffffefffffefffffefdfffefdfffefdfffffffffffffefffffefffbfdfdfcff
fdfffffefffdfcfffdfffffdfffcfbfffefdfffdfefafbfffff2f8ff9fa4e32724af1a17c71211
c51011c71311c81512c61512c61512c51313c51312c61112c61112c81314ca1011c51012c41113
c51212c41312c61311c9110fc71816cd0f0cbf0404b00000a400009e00019e0002a10103a70001
a50000a40a07b00300a50800a50c03991515876f73c1f3f2fffafafffdfdffffffffffffffffff
fffffefffffffffffffffffffefffffefffffeffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffafef8fcfffbfcfbfdfffe
fffcfbfdf2fbfee8ffffb9f3ff59c1f024abef0fa7f809acff01a9fc02aafd07acff01a6fd04a9
ff04a9ff04aafd06aafd06a9ff06a8ff04a8ff04a8ff09aaff03a1fb0096f90092fb0092ff0292
ff0590fe0590fe0592ff0291fe0093ff0094fe0193fd0190fd0690ff2095f64b9ad985b3d5ccdf
e6eff5f0fdfffef7f9f9fbfffef8fdfbfffffefffffefdfffefdfffffdfffffffffffffeffffff
fefffffefffffefdfffefbfffefdfffffffffffffefffffefffdfffffafffdfefdf9fffdfcfffc
fffffcfffffdfffffefffffffcf6f8ffdfe3ff5054b31d1db71210c71514c81613c71511c81511
c81512c61512c51313c51313c51112c61112c81112c81213c71112c61113c51313c51110c41210
c71715cc110ec20806b60000a90000a30002a000039e0002a10000a40002a60000a50000a40801
a510079e170f8b7476c4ecf0fffafbffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffefffffffdfcfefdfffff9fefcf4fcfcf3fc
ffddfbffa6ecff4bb7e71facf509aaff06a7fd05a8fe06abff02a7fe06a9ff04a9ff01abfd00ab
fd00aaff01a9ff04a8ff08a7ff09aaff08a7ff029af90091f70094fe0293ff0190fd0391fc0492
fd0392ff0093ff0192ff0692fd0791fc0790fe1193f630a2ef4294c3b2d0dbe5e9e4fffcfefefd
fffcfefefcfefefffffffffefffffffffdfffffdfffffffffffffffffffffffffffffffffffbff
fefafffefbfffffdfffffffffffffffffafffbfbfffcfefcfbfffbfcfefcfcfafafafffdfffffd
fdfcfbf7f6f7ff8e8ee82123ad1417bf0e12c51212c41613c61512c61511c81312c61312c61313
c51313c51113c51112c61011c71112c81513ca1412c91110c41313c51714c71615c30306ae0002
a70000a60000a40002a40002a40000a20000a30000a40000a40200a30b079c1111876b6fbee6eb
fff6fcfffdfeffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffcfdfffdfdfbfdfef9fefdfdfffefdfffff8faffebf9ffd8ffff9ae3
ff38b0eb18aaf60aa5fa04a6fe04a9ff02a7fe04a9ff04aafd01abfd00abfd00aaff00a9ff06a8
ff08a8ff06a8ff09a9ff08a1fc0196f60093fb0192ff0292fc0292fc0391fc0392ff0093ff0091
fe0591fc0892fd0591fc0692f7119cf3319bda7badc4d5e4e7eff2f6fffcfefffefffdfcfefffe
fffffefffffefffdfffffdfffffdfffffffffffffffffffffffffffffbfffffbfffefbfffffdff
fffffffffffffef9fdf8fdfffcfffefefffdfdfffffffefefefffefdfffdfffbfbffcacaff3b39
b51a1bbf1216c81013c91111c31513c31512c61511c81312c61312c61312c61313c51113c51112
c61314ca0f0fc71412ca1513cb110fc61717c91817c50809b10000a20001a00100a40302a60201
a50000a30000a30201a50002a60003a20907a00e0d8b5d61b4e2e7fff6fbfff8fafaffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffbfcfffefefbfffff8fcfdfffdfcfffefdfafcfdf8feffeefafed8ffff81d6fc31ace614a9
f904a8ff03a8ff04a9ff02aaff02aafd04aafd04aafd02a9ff02a9ff06a8ff06a8ff05a7ff07a9
ff06a9ff02a0fa0092fa028ffd0593fe0492fd0390fe0392ff0192ff0091fe0391fc0492fd0392
ff0093fb0092f425a3f14a95c3a3cbded8e7eafefcfcfffbfffffcfffffdfffffefffffefffdff
fffdfffffdfffffffefffffefffffefffffffffdfffffbfffffbfffefbfffefdfffefffffefeff
fbfefffbfffffefcfcfcfffefffffdfdfffdf8fefaffe9e6ff6665c32121b30c0fbe1114cd0e10
c91412c91313c51312c61312c61311c81312c61112c61112c61113c51112c61513ca1210c8120e
cb1512cc1713ca1614c40d0db50001a300009e00029d0003a10104a30401a40200a30000a40001
a50000a004059d090b8f5152b4e2e6fff8f9fff4f4fafffffeffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffefefef9fe
fff9fdfefffdfefffcfbfcfdfbfdfffefcfcfceafdffc9feff6ec9f027aaed0da7fa06a7fd06ab
ff02aaff02aafd04aafd06aafd04a9ff04a9ff06a8ff06a8ff04a6ff03a8ff07adff04a6fe0194
fa028ffd0592ff0491ff0390fe0392ff0091fe0091fe0292fc0392ff0192ff0093ff0092fb1097
f3399dde62a3c9c3dee8f0f2f2fffafffffcfffffefffffffffdfffffbfffffbfffffdfffffffe
fffffefffffefffffefffffffffffffffdfffffdfffefdfffefdfffefffffcfffefafffffffafc
fdfcfbfffbfafefffefff3f1ff8d8adf2928a8191abe0d10c60f11ca0e10c91111c91513ca1312
c61312c61311c81311c81112c61112c61112c61112c61311c81513cb120fc91411cb1815c90b0b
b70000a40002a10402a20102a000039e00039e0201a40100a50000a40001a00606a00d0f934043
a5d0d3fff4f6fffdfcfffffeffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffff9fefcf7fcfaf6fbfcfcfdfffffeffffff
fefffffafcfffafafffef3ffffe5fbffc4f7ff5cc0f025acf00fa9fa07aaff08a9ff08a9ff02aa
fd02aafd04aafd06aafd04a9ff04a9ff04a6fe03a8ff06abff06a8ff089bff0491ff0290ff0391
ff0391ff0291fe0091fe0193fd0291fe0291fe0191ff0092ff0092fe0692f6209df23b95d09ec5
dbd7dee1fcfdfffdfcfefdfffffbfffefbfffffbfffffbfffffdfffffffefffffefffffdfffffd
fffffefffffefffffffffffffffdfffefdfffefffefafffcfbfffefffdfefffefafffdfcfff4f7
ffafb1eb3433ab1d1cba1110be1819cd1011c70f12c81010c81212ca1112c61112c61112c81112
c81112c81112c81311c81311c81210c71513ca1712cb1511c80f0cbc0201ab0000a00103a50501
a70300a500019f0002a00000a40001a60001a302039b0a0c962d2e96c9cbfff8f9fffaf9fffdfa
fcfffdfffffcfefffeffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffff9fffbfafffefafefffdfefffffdfffffdfefffffbf9fdf7f7fd
fcfafffff8fffce6ffffaeeeff53b8ec1faaef0caafd09a8ff08a8ff04aafd02abfc02aafd04aa
fd04aafd04aafd02a7fd04a9ff04a8ff06a6ff0ba1ff0497ff008efd0191ff0391ff0290ff0093
ff0093ff0392ff0390fe0290ff0391ff0191ff008df80c96fa309eea639cc3c2d9e8e4edf1fcfe
fefbfffefbfffefbfffefbfffefbfffefdfffffffffffffefffffdfffffdfffffdfffffefffffe
fffffffffdfffefffffefffefafffdfcfdfcfefdfdfff8f8fef4f4ffcbceff4346a81f1fb31514
c21613c7100fc31214c61012c41313cb0f0fc71112c61113c51112c61112c81112c81112c81311
c81311c81412c91211c51a17cb1412c20200ad0000a60304a80000a30100a70400a60402a20003
a20001a40000a30002a0070993232591babafff7f7fffdfdfdfffffbfffffefefbfdfffdfffffe
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffafffcfbfffefdfffffffefffffefffffffffdfffcfdfffcfdfffff9fefdf6fffceefd
ffe6feffaae3ff43b4ec11a6f007a6fd03a7ff04a8fb06acff01aaff01aaff03aafb05acfd01aa
fb03abff04a4ff07a3ff0fa9ff069fff0091fa0090fe0492ff0290ff0090ff0092ff0392ff0391
fc0590fe0690ff028dff0591ff018ffa1c98f04298d486b9d9cee1e8f5f9f4f8fbf9fdfffefafe
f9fcfffbfdfffcf9fdf8fdfefcfefcfcfefbfdfffefffffefffffbfdfffdfefffffffdfefcfeff
fdfffdfcfffdfcfffefdfdfcfef8fbffdce0ff5053bc2525b71617bb1513c31611c81511c81114
c31115c21312c61311c80f10c41315c71214c61011c51112c81111c91210c81311c91410c71916
c91311bf0504ae0000a50000a40201a50201a50201a50000a20201a40204a60000a10308a50002
9715198fa3a3e3f2f0fffdfcfffefcfbfffff9fffff7fffefefefdffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffdfffefdff
fefffffffffefffffffffffffffdfffcfdfffcfdfdfdfefdfffafffff9fefff8fdfedbfbff86db
ff33aeec14aaf803a6fc0cadff01a7fa04adff02acfe02a9fa06aafc02acfa01a9fe03a6ff06a5
ff07a8ff06a5ff0099fe0090fa0391fc0491ff0190ff0090ff0091fe0492fd0892fd0790fe0990
ff038eff018ffe1398f92f9cea4d9acbafd2e0dfe8e5fdfffefcfaf9fffffefffffcfcfef8ffff
fbfbfffafbfefcfffffffcfbfdfffcfefffefffffffffffffffffffffffffefffffefffbfaffff
fcf7f7ffe6eaff686bc02425b51313bf1513c31512c61611c81512c61314c21115c21512c61312
c61413c71214c61113c51112c61213c91111c9120fc91311c91815c91312c00909b10001a50000
a20002a40200a60100a50201a40101a10000a10003a20205a40407980b108b7c7fd4ebecfffdfd
fffcf9fbfffefafffff9fffff9fffffffdfcfeffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffefffffffffdfffffdffffffff
fefffffefffffefffffefdfcfefffefffffcfffffefff7fdf8eaffffc9faff7dd0fd26a8e913ae
fd05a6fa03abff00a8fb02abfc06aafd09aafe05acfd00a7fa01a9ff02a9ff00a7ff04a8ff05a4
ff0095f70292f80691ff0491ff008fff0091fe0494fe0693fc068ffd0990ff068fff058fff0992
f91299f52e97da7db2cdcde0e5eceff3fffdfefffefdfffcf9fffffbfffffbfdfffbfafffbfaff
fff9fefdfcfefffdfffffbfafcfdfbfbfffefefffefefffffefffffef3f8f7f3f6ff7a7ad82828
b21414ba1312c61510c91510c91311c81313c51514c21514c21512c61312c61514c81012c41012
c41213c71311c81210c71611ca1713ca1513c30909b30001a50001a00001a00001a30200a60100
a70201a500009f0005a20408a300009b100e906263b4e9eafff8f9fffafbfffffefefffffefafd
fbfdfffefdfcfefffdffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffefffffefffdfffffbfffffffffefffffcfffffeffff
fffffdfffffdfffcf8fefefdfff9fffaeefdf9eafeffc4f4ff69c8fa23a6e90fabf802aafd00a9
f708acfe08a8fc09a8ff07abfe00a8fb01aaff00aaff00a7fd02aaff07aaff029ef80193f60391
fc028fff028fff0391ff0492fd0492fd0391fc0390ff0690ff078fff018df80292f826a1f1529d
c9a4c9dfd7e1ebfffbfffffbfdfffcfbfffffcfffff9fcfffafafffcf6fffcf8fffffbfffffbff
fffefdfffefdfffffffffffffffefefefafcfff1f4ff9195dc2928ae1916bf1715c51311c81310
ca1310ca1112c81112c61613c31613c31512c61312c61213c71012c41214c61112c61110c41413
c71814cb1613c60909b50002a70000a20003a10002a00000a20100a50200a80200a60000a20004
a1000095121197413da2e2dffffbf9fff8f9fffcfdfffdfffffafdfbfcfffdfdfffffcfbfdfffd
fffffeffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffefefffefffdfffffbfffffdfffcfffffbfffffcfffffefffcfffffdfffcfb
fdfafcfcfbfffff9fffef9fcffe9fcffc2f3ff5fbbea1babec03adf503abf809acfb0ca9ff08a4
fd08a9ff04a9ff01abfd00a9fe00a9ff01a9ff04abfc07a7fb0297f70191fa008efe028fff0690
ff0790fe0390fe0193fd0091fb0091fe0791ff078fff0591fc1496f1379dde5fa3cec0dbf0e9eb
f5fdfdfffffefffffdfcfffffbfcfdf9fbfffcf7fefbf8fffff8fcfdfafefffffefffffefffdfd
fdfbfdfdf6fbfef3f5ffa0a1f92929ab1d1cc0120fc21612c51712c71311c91111c90f11c91112
c81611c61612c51512c61112c61112c61112c61413c71211c51312c61717c91614c40b0bb70101
a90000a20002a10104a20002a10000a20000a60000a70300a90301a70103a50a0c96312f8fc9c4
fffaf5fffef8fffffdfffdfffff9fffef8fef9fffffcfffffbfbfafcfffefffffeffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffe
fefffefffdfffffbfffffbfffefdfffcfffffcfffffefffdfffcfbfdfdfffefbfefcf7fcfbfdff
fffffefdf8fbffe7fcffb5eeff45b8ea15aaec0aabf707a9fb0aaafe07a6fd08a8ff05aaff00a9
fe00a8fd03aaff01a9fe04a8fa0aabff039efb0095f9008ffd028fff0890ff0790fe0390fe0293
ff0091fb0294fe0592ff0690ff0792ff088ef31f9af03a97d490b9d9d2e0ecf3fafffbfefffffc
fefffdfcfffefdfbfffafafffdfbfffff8fcfdfcfefffffefffafafafdfefcfbfdfff6f7ffa9aa
ee3635b51a1ac01012c41415cb1713c61913c61311c81111c90f11c91112c81512c61611c61312
c61112c61213c91213c91311c81312c61515c71616c60e0eba0000a80000a40000a20002a10003
a20001a30001a50001a50000a40000a70201a4060597211e91a4a3e1f8f6fffefafffffdfffefb
fdfbfdfefafffdfbfffcfffffbfdfcf8fffefffdfcfffffeffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffefffffefffffffdff
fffafffffbfffffffffffffffefdfffef7fcfafffffbfefffbf6fbf9fafcfcfffdfcfffefdf3fb
fadfffff9ee5ff46b2ec1aacf804a9ff00a7f805acfd04a9ff03aaff00a8ff00a8ff06a9ff07a8
fe06a7fd07aaff07a5ff009cfd0092fe008fff058fff0891ff0491ff0493ff0390fe0593fe0393
fd0292fc0190fd0492fd0691f82d9eee609bc2b5cfdfd9ebf6f1f8fffffefffffcfdfffffefffc
fbfffffffffffffefdfffffefffffefefffefefffffef5f3ffbdb7fe3e39ac1d1db71215c40c10
c31213c71814c7120dc21510c91311c91112c81112c61112c61113c51112c61112c61213c91111
c91311c91413c71613c60e0eba0304ac0000a20003a20003a20001a30000a30001a50001a50000
a40000a40000a2070b9f151587807cc8f4f3fff8fbfffdfffefcfdf9fffefffffefffefffdfbfc
f8fafdfbfcfefefffefffdf9fefffeffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffefffffefffffffdfffffbfffffbffffffff
fffffffff8fdfbf8fef9fcfef8fffffbfdfffefcfefefefcfbfffefafffffaeffcfed8fdff94dc
ff31abed10a8f608acf900aaf804a9ff02a9ff00a9ff00aaff05a8fe09a9fd08a8ff06a6fe09a8
ff03a2fe0097fb0091fa0390fe0791ff0493ff0392ff0994ff038efc0493ff0293ff008efb0090
fd0090ff1896f4479dd37fb3d1bed8e9eaf5fdfafdfffffffffffefdfffdfefffefffffdfffffd
fffffffffcfcfcfdfdfff7f6ffcdc8ff4740af2822b71616c00c10c31216c91213c7110ec21916
ca1311c91311c91311c81112c61112c60f13c61112c61112c81213c91311c81311c81815c81211
bf0202ac0000a10205a40001a00104a30201a40100a40000a60000a40000a20005a201039d0f10
90605eb0eae9fffafcfffcfffbfefffafdfefafffdfdfefcfcfffffefefffdfdfffffbfdfdfefd
fffffeffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffdfffffdfffffffffffffffffdfffffdff
fefffffefffffefffffffffffffffffffffffefcfdf9fbfffff2feffd4fbff7fd4ff2faae813aa
f403aafb03a8ff02a9ff00a7fd00aaff03abfe05a9fc0baaff09a7ff08a8ff07a9ff00a1f90098
f60392ff028fff0090fe0094ff0491ff0691ff0390ff0191ff0192ff0192ff0190ff0b92fa259c
eb3e94c8a8cbe5d4dde6f8fefdf8fcf7fffdfcfffefffffbfffffcfffffefefdfdfdf9fffef2f8
ffd2d0ff504cb3211eb01716c01313c51112c81011c71011c51312c61312c61112c81011c71112
c61314c81213c71112c81112c81112c81312c61212c41a17c71513c00202aa0000a30203a70001
a000009e0306a50300a40300a50000a60102a60004a3000499170f984239a1dbdafff5fafff5f9
fafffffcfffefffffcfefffffffffffefffffffdfffffdfffffdffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffdfffefbfdfdfcfcfceefdffc5f6ff7bd2fe2eacec11a9f70aabff00a6
fd00a9fe04aeff00a9fb00a7fa09a9ff07a6ff05a7ff05aaff03a9fc009df70091fb018eff0191
ff0090ff0492fd0692fd0490ff0390ff0392ff0392ff0390ff0690ff0992f435a2ec659bc4c8de
f0d9e5e5fdfffcfffffefefbfdfffcfffffefffbf9f8fbfffff3fbffdce2ff5653ba2521b01717
bf1213c91112c81112c81112c81112c81112c61112c60f10c41314c81213c71011c51011c71112
c81011c71213c91313c51918c6110fbd0403ad0301a70100a30000a10003a20306a500009b0602
a70602a80400a60100a30105a00a0c962b2290c3bbfff6f8fff6fcfbfdfffefffffefcf6fbfffc
fffffffefffffcfdfffffdfffffdffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffdff
fff9fffef3f9f8fdfcfef9fdffecffffc6f5ff6dc7f62aa7eb12abfa00a8fd04aafd04aafd00a9
fb01aaff04a9ff05a7ff04a8ff04a8ff04acff03a5fe0094fc008efd0591ff048efe0693fc0693
fa0492fd0392ff0391ff0491ff0490ff0690ff0b92fe2296f44296d882b6dbccdce8f6f7f5fbff
fff9fbfcfffbfffefcfcfdfff9f6fcffebeeff6c6dc72526b41717c11313c51112c81112c81112
c81112c61112c61112c81112c80f10c61314ca1112c81011c71314c81213c71211c51212c41817
c51616c20505b10000a30200a60502a50000a10104a30104a30103a50000a20102a60d07ac0300
9d08069c14138b9e9fe3f3f7fff4fcfcf9fff7fffffefdfafcfffdfffffefffffffcfffffbfdff
fefdfffffffffefffffefffffefffffeffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffdfffff7fdfcf7fdfcfdff
fffdfffff8fbf9eaffffb8f0ff65c2f322a9ed0daafa0babff04a8fb02aaff04aeff02a8fb04a9
ff04a8ff02a6ff03abff06abff059eff0091fe028eff0690ff0693fc0494f90394fa0393fd0491
ff0490ff0490ff0491ff0690ff1090f7319ef44793ceb1d0e7dbe2e5f7fdfcf9fefdfffdfffdfc
fff6fbfaf2f6ff8788d92828aa1416bb1113cb1111c91112c81112c81213c91213c71213c71112
c81112c81213c91112c81112c81213c91213c71112c61414c61414c41316bf0808b20000aa0000
a80201a50202a20002a40001a300009f0204a60003a50000a20702a509029917108f7a78d1eff6
fff1fbfbf6fff5f9fff6fdfefcfffcfefffefffffdfdfffffcfffffbfdfffefdfffeffffffffff
fefffffefffffeffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffcfcfcfdfffff6fcfbf9fffdfafdfbf3fe
fce6ffffb4eeff55bbef25abf30fa6fb07a9ff09acff07abfe02a6f907aaff05a7ff05a7ff03a9
fc06abff09a7ff029aff008efd028fff0193fd0194fa0394fa0393fc0491ff0390ff0091ff0093
ff0090fa0c95fc1393f93497e771a5cac5d8e5e2ebeefefefefcf8fdfffbfff9f5ffafaeec3435
b51618bd1416c80b0dc51010c81112c81112c81213c71213c71213c71213c91112c81313cb1010
c81513cb1412c90f0ec21212c41818c81416c2070ab30000a60000a80300a90000a20001a00200
a60000a30002a600009e0408a70202a20600a4150e995d58adeaecfff2fbfff6fff7fbfff9fcff
fafafbf9fffffffffffefdfbfafffffcfdfffcfdfffffdfffffffeffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffefefefefef6fbf9f7fefbfcfffbf7fdf8f5fefbdffeffa1e5
ff51b8f119a3f00ba8ff0aa9ff06a7fd07a8fe08abff02a7fe06abff03a9fc02a8fb08aaff06a3
ff0195ff008ffe0093ff0093fd0393fc0393fd0491ff0390ff0091ff0093ff0295fd0291fa0692
fd2499f44893cb94bfdad2e2e9f3f5f5f9f7fdfaf7ffccc7ff4541aa1d1cba0b0ec41213c91314
ca1010c81112c81112c81213c71213c71213c71112c81112c81212ca1010c81412ca1311c81211
c51717c71517c30609b10000a50000a50000a70100a70000a40001a50000a60000a50104a60003
a20002a103019b0e099a3e39a6d5d5fff9fbfffafffef7fff8f9fdf8fefffdfefcfbfffdfcffff
fcfefffbfdfffefdfffffdfffffdfffffffefffffefffffeffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffefffdfdfdfcfffdfafffdf8fffcf8fffefafffef0fcffdffdff9adcff3fb7f312a8
f607a6fe07a6ff0aa9ff09aafe00aafc00adfd00abfb00a9fa05abfe0aa9ff0a9dff0392ff0191
ff0090ff0391ff0491ff0491ff0491ff0390ff0391ff0595ff0393fc0392fb1092f1339ee8539a
ccb9d3e4e2e5e9fafcffdfdfff5854c52622bd100ebb1615c91010c21514c81112c81112c81112
c81213c71214c61112c61112c81112c81311c9120fc91210c81311c81916c91615c30a0ab40000
a300009f0105a40102a60000a60000ab0000ab0000a50003a20003a00002a00401a40e0b9c2423
8ab8b9f5f8f9fffbfdfdfbfdfefcfdfffcfcfffcfbfdfffffefffff9fcfdf9fffffefdfffffdfe
fffdfffffdfffffffefffffefffffeffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffcfbfdfdfc
fefcfdfbfcfffdf9fffdf8fefdfdfffffbfeffeff9ffd8fdff80d6ff32adeb15a8f80aa9ff08a7
fe04a8fb00adfd00a9f900a9fa04abfc02abfc08abff0ea3ff0797ff0191ff018fff048fff0490
ff0491ff0491ff0690ff0690ff0390fe0393fc008ff80892f61597f2379ade7aa9c9cddef3e4ed
ff7477c22727b7100dc11817cb1211c51613c61110c41311c81112c81112c81112c61113c51113
c51112c61112c81311c91412ca1210c81312c61715c50a0ab60000a60103a50003a100029d0000
a20001a60000aa0000a80000a20001a00002a005059f08069b1311899496d7f3f6fffbfefffdfe
fafbfafefffdfffcf9fffffefffcfbf7fffffbfffffcfefefefdfefffdfefffdfffffdfffffffe
fffffeffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffefffdfefffdfffffffffefffffcffff
fefffefffffefffbfefff5fbffeafcffd3fcff8cdaff2dabeb0ba7f40dafff05aaff04a9ff06aa
fd04a8fb06adfe03adfb01a8f90ba7ff0ea3ff0394ff0190ff038eff028eff0392ff0393fd0890
ff078eff0590fe008ff90696ff008df30996fd2198ee4696cb9cc9fc7080cd2b2c9e1f1ebc1311
c81212ca1111c91210c71513ca110fc71311c81311c81312c61313c51313c51413c71311c81412
c9100ec51815c91a17ca0c0ab80000a80000a50002a40605a300009e0003a20005a70000a40301
a70000a40001a30001a307079b1211896d6ebff3f3fff9fafffcfdfffffffffffffffffffffffe
fffffffefffffbfffffbfffffffffefffdfefffdfffffffffefffffcfffffffffeffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffefffdfefffffefffffffefffffcfffffefffffffffefffdfd
fffafdfff6fcfff3feffd1fbff75d3fe29aee811abf405a6fa08a8ff08a8ff06a7fb02a6f803ad
fb05aeff07a8fc09a7ff079fff0093ff028ffe0592ff0193fd0091fb058fff0890ff0993ff0491
ff0292fc0696ff008ffc0e93f52d9ae4307cc806248d171ca11617bb100ec51010c81214cd0f11
c91213c91311c81311c81312c61312c61212c41313c51312c61312c61211c51616c81714c70e0d
bb0403ad0000a70000a50100a40401a40303a30205a400009c0002a40000a20000a20504a70602
a1120e954b4ba5e5e6fff4f3fffefefefffefffcfbfdfffffefffffefffffefffffcfffffbffff
fcfffefffffdfffdfefffdfffffffffbfffffbfffffffffefffffffffffffeffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffefffffefffffffffffffefffffcfffffcfdfffffdfffffcfbfdfffefff8f9
fdeafcffcbfbff7ad1f324a8e412adfc0ba7ff07a6ff07aaff04aafd03aafb01aafb01aafb04ac
ff05a9ff019ffd0194fa0292fc0093fd0092fc0190fd0592ff008dfc0390ff028dfb0992ff0992
ff0790f71098f8248ef3002397000d961618ba1410c3140fc81312cc0e12c80e13c61112c61312
c61312c61312c61312c61211c51212c41313c51614c41918c6100ebc0201ab0000a60100a50100
a40100a50000a60301a70300a30303a30002a40000a40806ac02009d110a9b2c2697cbc6fff5f5
fffcfdfffffffcfefdfffffefffffffefffffcfffffefffffefffffcfffffefffefffffefffffe
fffffffefffffbfffffcfffefffffefffffffefffffcfffffeffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffcfdfffcfffffefffffffffefefdfbfbfffdfcf8fdfcedffffc1f4
ff67c7f527a9ea12a7f709aaff02a8fb02aafd07abfe04a8fb01aafb00aafa00a9fb06abff059d
fc0091f50093fb0094fe0190fd0592ff0693ff0592ff0b93ff098ffe078efa0490fb0191fb1895
ff2070e3001091000aa41c16c31911c9110ec81116c90c15c31012c41211c51312c61413c71413
c71211c51212c41313c31817c50f0fbb0403ad0000a50000a40201a50100a40100a50201ab0000
a50702a50702a30001a30102a60200a30e089d1f178ca7a1f0f5f2fff9f9fff8fbf9f5f9f4ffff
fffefefefffffefffffefffffffffffffffffefffffffffefffffefffffffffffffcfffffcffff
fcfffefffffefffffffefffffcfffffeffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffdfffffdff
fefffffefffffefffffefffffefefefefcfdfbfffffbfdfffcf2f9fce6fdffbff3ff6bc3f123ab
e60aaef602adfb00a8fa08a7fe0ba8ff04a5f901aafb00aafa05adff07a6fe0398f80091f70193
fd0492fd0590fe048eff038dfe058dfd0891ff088ffb0791fb0b95ff0a8ff7289dff0049ba0006
921510b31b14c9110ec81217c60e14c11013c21211c51312c61412c91311c81312c61613c61716
c41212be0304ac0000a30001a50201a50100a40400a50000a40000a80000a50503a30400a00501
a70602a80400a0140e91847fcaf8f4fffbfafffefffdfdfffffafcfcfcfdf9fefffbfffefffffe
fffffefffffefffffffffffffffffefffffefffffffffffffefffffefffffffffefffffefffdff
fefdfffcfffffeffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffdfffffbfffffbffffffffffffffffffff
fffffffefafcfcfcfffdfdfff9fbfcf8fafcfdf4fdffe5fcffbbf2ff5cc5f11baae40aaef703ad
ff06a3fa0da7ff06a7fd05abfe03adff00a8f90aaafe0ca5ff0094f80091fb0694ff038efc0792
ff0792ff028dfb0691ff0993fe028cf6058ffa0c95fc0e97f9208df6002dad0000941212be1813
c81112c01115c21313c31313c51312c61210c71311c81413c71613c61514c20607af0000a20000
a20104a30000a20000a20501a60000a40000a30304a800009f0503a30500a407039f0f0b935754
b7e9e8fffdfcfffefffdf8f9f5fffffffffffffbfffafdfffcfffefffffefffffefffffeffffff
fffffffffffefffffefffffffffffffefffffffffffffffefffdfffffdfffffdfffeffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffdfffffdfffffdfffffdfffffffefffffdfffffdfffffefffdfffff7fa
f8fffffefdfffffafdfffafefff1fafee3fbffb7edff5ebbec1ca8ef09aafe07a8fe09abff07ac
ff00a5fc04abff01a6fc08a9fd0daaff049dff0193fd0491ff0290fb0494fa0091f70294fe0392
ff028ef90692fd0592ff008dfb018df81f9bff146bdf0016980008a51c15be1611c01715c51313
c31313c51312c61210c71412ca1412c9100dc00909b50000a50000a20101a10203a100009f0100
a30501a60300a40201a40003a20004a30002a102019f0e0c94403f9bcfd2fff6fafff5faf9ffff
fefefcfbfffdfcf7f8f6fdfffffafffefdfffffdfffefdfffefdfffefffffefffffffffefffffe
fffffefffffffffffffefffffefffffefdfffefdfffffdffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffdfffffdfffffdfffffffffffffefffffdfffffcfffffdfffcfefefdfffefdfdfdfcfefff7fa
fef8fcfdfffffef6fdffe4fbffade5ff49b4ed1aa8ef10aafb02a5fb06abff01a8ff02a7fe06ab
ff07a9fb06a7fd0aa7ff029aff008ff90494fd0092f60296fa0294fe0293ff0391fc0490fb0693
ff0592ff0593ff088ffb2399ff0356ca0005901012ad1916c01512c21212c41113c51112c81412
c91614cb1512c50b09b70000a70000a40002a40101a101009f0201a40201a50100a40201a50201
a40000a10002a400049f060896252492b0b1e9f6fafffafffff8fff8fcfdfbfffffffbf9f9fffe
fef9fbfbfbfffffdfffefdfffcfdfffefdfffefffffefffffffffffffffefffffeffffffffffff
fefffffcfffffefdfffefdfffffdffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffefffffefffffefffffffffffffffffffffffffffdfffffdfffffffffffbff
fff6ffffdcfcffa2e8ff52bbec1ba5ed0aa8fc07a9ff05a9ff06a9ff07abfe06aafd00a4fa07a9
ff08a6ff0096f90091f60093f90194fc0090fd0291fe0795ff0692fd058ffa0792ff0596ff008e
f80b97fc2694fe002aa70009961214b61713c01414c60f12c80f12c81516ca1412c20806b30302
a60000a20503a90000a40200a30701a60400a60000a40200a60000a50404aa0000a50000a1090e
9f1013868d8dd9f6f7fffdfdfdfffffbfffff9fdfffcfdfffffffefffffefffffffefffffeffff
fefffffefffffffffffffffffffffffffffffffffffffffffffffffffffffffffffeffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffefefeeefafed6fc
ffa0e6ff47b6ee1faaf30aa5fa04a9ff07a8fe07abfe04aafd00a8fb00a7fc06abff07a6ff0096
f50090f60092fc0492ff0391ff0390fe0692fd0993fe0591fc008efb0596ff0091f61396fe297f
f100149400099f1413b71313c30f10c41315c71717c70a08b50000a30201a40202a20302a50403
a70400a50300a50000a60000a40001a30001a30000a50405a90606a00b0d8a6e71c2e6eafffbfc
fffffffbfffffbfffffcfdfffefdfffffffefffffefffffffefffffcfffffeffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffcfcfcfafdfff2feffdbfdff9ee4ff49b3
e91baaf505a8fe06a8ff03a8ff00a6f902aafd00a9fe01a9fe07aeff04a3fa0095f50090f90191
ff0491ff058efc0990fc0a94ff0791fc068efe0791ff008ffd008dfb2298ff0b5fd600078e1014
a91517bc1717c31b1ac40a07b00000a20703a80102a60001a300009d01039e00009f0000a20002
a60003a501039e0102a00101a70504a20f0b924c4aaadde2fff6fdfff7fafefdfcfefffefffdff
fffdfffffdfffffffefffffefffffffffffffeffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffdfbfbfbfafcf2fdffd9fcff9be1ff3fb1ed18a9f408a8
fc03aaff00a7fa02abfc03acff00a7fa02a9fa0babff0aa0fe0293f9008ffb0090ff0690ff078f
ff0692fd0891ff0a90ff0b92ff0090ff0194ff0490fb2797ff033eb900038b0f1ab21719bb0f0e
b20100a20300a40504a80000a50104a600049f00029c0002a10000a40002a40003a200019f0103
9e0303a309089438349bc7c5fff5f8fffdfffbf6f8f9fdfefffdfefffdfefffdfffffffeffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffefffefdfcfaf9fffdfffafdfff4fdffddfdff91d8fd44b3eb14a8f601a9fe03acfd01aa
fb02aaff04a9ff05a3fd0ba7ff10a7ff089dfd0092fb008efc0390ff038eff028ffe0893ff0991
ff038dfd0391ff0093ff0195ff0d94fe2688f60028a0000c94080fa202049f0202a20102a60000
a30001a50003a20105a000029f0103a70001a60000a00001a30001a50104a3060499201c8daeae
e4fafafffdfbfffffffffdfffff9fefdfdfffffdfffffffefffffefffffefffdfffffdfffffdff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffcfdfbffff
fefefdfffffdfffffdffeff9ffd8fdff8edafe3bb5f10da4ee05a9f602abfc01a6fc06a8ff0ba7
ff0aa6ff0ba7ff0aa7ff019cff0091fa008fff008fff018eff0693ff0794ff008bf60492fd0191
fb0091fb0291fa1d9aff1c7be900158f0000830004940504a00000a30204a90002a400009f0001
9f00009e0002a70000a50000a30403a60000a501029a14128a8380cff5f6fff9fbfbfffdfffffa
fcfffffefafef9fffffefffffffffdfffffefffdfffffdfffffdfffffdffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffdfffff9fdfefafffff8fdfcfffffffdf8
fafcfdfff0ffffd6ffff89dbfa44b9ec15a9ef06aafd02a7fe02a6ff0aa9ff09a8ff00a7fe04aa
ff07a6ff009afd0093fc0092ff0191ff0491ff0393fc0495fb0592fb0b98ff018cfa0793fe078f
f92599ff0857c5000e8400008806059b0501a60404ac0000a00105a40202a20301a10301a70000
a40101a90102a600009d1311936461b0ebeafffafafffdfdfffaf8fefffefffefffbfffffcffff
fefffefffffefffffffffbfffcfbfffcfdfffffdfefffffeffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffdfffff8fdfefafffff8fdfcf8fbf9fffffffffefefcfefeeafd
ffd1ffff8bdcfd3bb3ee13a8f208a9fd02a9ff08abff04a7fd01a9fe00a7fe08a8ff05a4ff0099
fb0094fb0293ff0290fb0595fe0090f60895fe028ef90a92ff028cfc0894ff0e91f92c97ff003f
ae00027f00039004039f0000a30004a60002a40200a00500a10300a40000a30001a900009e0f0d
953f3c9fe0dffff8f8fff9fbfffdfdfffafbfffffefffaf8f7fffefafffefffffefffffefffdff
fffbfffcfbfffcfdfffffffeffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffdfffffcfffdf7fcfafcfefefcfffdfffffcfefcfbfafbfff4fcffedfeffd2fcff94e5
ff41b8f00ea7f200abfd00a8fd02abff09aaff08a7fe08a8fc08a9ff02a6ff009cfa0193f70994
fb0493fc0492fd0491ff0591ff0591ff0592ff0892fd0991fb1194fc238bf6002b9e00007b0107
960704a00000a00203a70504a204039f00009e0201a40002a60507952a298bc3bffafbf8fffffe
fffbfffffafffffbfffffffffffffefffffdfffffffefffffefdfffffbfffffdfffefdfffcffff
fefffffeffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fefffffefbfbfbfffffef8faf4fcfffbfffefff9f9fffafdffe7f9ffc1efff4595dc2da9ff0fa8
ff03abff00a9fb04a5f90aa8fb0cacff04a8fb03a8fe05a5fd0296f40493f60493fc0391ff0390
ff0491ff0390ff0290ff0391fc0493fc0191fb1b9aff227ae4001c900000830003940709a40100
a301009e0504a20403a60102a005079b15178da1a0e0f7f3fffffcfffffffefbfffffafffefbff
fcfffffefffdfffffdfffffefffffffefdfffffbfffffdfffffffffefffffcfffffcffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffdfffffbfdfffeffffff
fbfbfff9f9fff9fbf9f8fffefff7fbfcedf7ff7785de04279f0a53cd309eff15aaff01aafb07af
fc03a9f606a7fb0cacff07aaff07a8fe0ba5fe0095f50292fb028fff038fff0490ff0191ff0091
ff0092fc0294fe0291fe0991fb1d9dff1273db000e8200038501099902029c0401a40200a40200
a902029c11148e6e71c2f6f4fffaf6fffffdfffdfffffbfffffbfffefffffbfffffbfffffefffe
fffffefffbfffffbfffefbfffefffffffffffffffffefffffcffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffefffffcfefffcfdfdfefcfbfffcfafffaffff
fcf8f6fcf3f6ffaaadea3634b01018b20013a9044ad32a9eff17acff04a9f803adfb07aaff08a7
ff04a6fe05a8fe0cabff09a4ff0096fb0090fd018eff0390ff0292ff0093ff0093ff0093fd0491
ff008af50395f9209eff0e5ec900067b0003860005960605a30400a30601a4100d985053aee4e7
fffbfafffffffffffefffdfefffbfffffdfffefffffcfffffbfffffefffffffbfefffafffffaff
fefdfffcfffffffffefffffefffffffeffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffbfdfefbfffffefdfffffffff7faf8f6faffcccbff3f3d
ae211eb71c1cc80b12c00012b50950dd2697ff0facff00a7fc05a7ff09a7ff06a5ff05aaff05a9
ff07a8ff049dff0197fc0091fb0090fd0392ff0392ff0392ff0393fd0391fc0995ff0290fb0b92
fc2099ff0050b900037800058900049903009a0f09983936a4d0d1fff6f9fffaf7fffdfafcfdff
fffdfffffffefffffffffffffefffffefffffefffffefbfffffafffffbfffefdfffcfffffeffff
fffffefffffeffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffcfcfcfdfffffafffefafffefaf9fbfffdfff8fbffdadeff5552c02621b8120fb91613c71715
cc0712c0000fb20048d5209aff15acff0aa6ff08a8ff08abff01a6fd03a9ff01a5fe0aa8ff06a0
ff0098fb0092fa028ffd0590fe0491ff0492fd0492fd0894ff0690ff048ffd0995fa2197fc0040
ad00017900048c0d0c91292491b1adf8f0f3fff8fbfffefdfffffffffdfffffdfffffffefffffe
fffffefffffffffffffffdfffffdfffffdfffffdfffcfffffcfffffefffffffffdfffffdfffffe
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffdfcfefcfefef5fa
f8fafffbf9faf6fbfbffeeedff7775ce2320b21a18c80f0fc11214c6080ebb181fcc0b12bf000f
b30749d82d97ff19abff00a7f805adfb01a8f906a6fe0aa8ff0aabff08a8ff03a2fe0098fb048f
fd068efe0492fd0393fd0494fe008cfa058fff0890ff0a92fc1794fc2c92fc00309d0003740e14
759a99d7f6f6fff9fcfffafef8fffffcfbfcf8fffffcfffffcfffefffffefffffffffdfffffbfe
fffdfefffffdfffffffffffffcfffffbfffffcfffffffffefffffdfffffeffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffefffffefffffffffefffffe
fffffffffffffffffffffdfffffdfffffffffffffffffffffff7f9f9fdfffcfbfefcfafefff2f4
ff9695e52c2ba91717bf0e10c91214cc0d11c31218c50f13c01711c41417c6000baf0242d02599
ff19aeff05a8f708b0fe05a5fd0aa9ff05a8fe06acff07a9ff03a0fe0393fd0390fe0393fd0393
fd0390fe0693ff038fff0490ff048ef90e95ff1393fa298ff200318e4561a8dfeafff7f9fffdfe
fafffff9fffffbfffffcfffffbfffffcfffefffffefffffffffdfffffbfefffdfefffffdfffffd
fffffffefffffcfffffefdfffffffefffffefffffeffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffefffffffefffffbfdfffbfdfffffdfefffffdfffffefffffffffdff
fefbfffefbfffefffffffffffffffdfdfffdfcfdfcf8fdfefff2f7ffb3b8f53032ae1b1dbf0f11
c30e11ca1212ca1412c91311c81413c71714c41513c30e15c3000eb20039c72994ff21b3ff00a5
f202aaff02aaff01a9fe03abff02a7fd0aacff07a4ff0093f80093fb0191fb0792ff0390ff0091
fe0192ff0290ff028ffd0493fc1898f72f93e15ea0d5bcd8f0e1e7ecf4f4f4fffffefffefdfeff
fdf8fffcfafffefffefdfffdfefffffffafcfdf9fcfffdfefffffefffffefffffefffffefffdff
fffdfffffffffefffffcffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffefffffffefdfffbfbfffbfbfffefdfffffffdfffffdfffffffffdfffefbfffefbfffeffff
fffffffffffffffffdfcfffefef5f7ffd6d9ff454aad1e22b70f13c50f12c80f11c91311c91510
c91510ca1511c81513c31513c31511c80d15c60013b2003ac11d8df71fafff0bacff00a7fc00a9
fe00a7fc04acff00a5fb04a8ff0aaaff0098fb008ff70492fd0491ff0092fc0090fd0090ff0393
ff0094ff0794f5209ded3e9fd97bb1d2bad5e3e1e8ebfdfbfafdfafcfbfafcfafffffafffefffe
fdfffefdfffffffffffffdfffffdfffffffffffffefffffefffffffffffffffffffefffffeffff
fcffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffefffffffffefffffefffbff
fffbfffefbfffcfdfffcfffefffffefffffffffdfffffbfffffbfffffffffffffffefdfbfbfdfc
fef5fafde9efff635fc92521b6191cbe0c10bc1114c31211c51610c9160fca1510ca1210c81313
c51313c51915cc0f0ec20c1bbe0011a60025ac2787f922b2ff03abf901a6fc04acff01a9fc00a8
fb06acff06a8ff02a0fe0099fc0092f70093fb0393fd0391fc0390fe0491ff0690ff098ffe0f92
f9269af1429fdc6baaccc1d9dfe0e4dffbfafefffdfffdfffffcfcfcfffefffffcfdfdf8f9ffff
fffdfffff5faf9fdfffefffffefdfffefffffefffffcfffffefdfffffdfffffffeffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffefffffffffefffdfffffbfffffbfffffbfffefdff
fefffffffffffffffffefdfffffdfefffdfffffffffefffffefefdfffbfbffedf2ff7f84cf2723
b21813c21618c41317c31513c31511c41611c81710cb1510ca1210c81011c51113c51611c81c18
cb0c0eb30004a000039b0024a91a83ea27b2ff0da8fd00a6f905adff04adfe02a8fb03a8fe05a5
fd09a8ff009af80094f80392fb0793fe0691ff048efe048eff0990ff088fff0d90f72199ec44a3
db7aacc8bfd5e0dde3eef2f1fafdfefffdfafcfffdfefffefffffefdfffefdf9fefcfafffdfbff
fffdfffffdfffefffffcfffffcfffffefbfefffbfefffdffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffefffffefdfffffbfffffbfffffbfffffffefffffefffffffffffffeffff
fcfdfffcfdfffffffefffffffefffffef8fcfdf1f3ffa7a7fb2d2cac1918bb1413c70e0cc31614
cb1713c61713c61712c91711ca1510ca1210c81112c61515c71a14c7110ab90200a30002a00005
a300069a001e9e1d75e129b4ff09affc00a7f800a8fb04a9ff05aaff0aabff08a9ff08a7ff029c
fb0192f8048ffd0690ff058fff0390fe0491ff078eff0c92ff0992f6209aee489fe172a9d6bed3
e8e1e5eaeef3f4fdfffffffefffefaf9fffffcfdfffcf7fcfafbfffffbfffffdffffffffffffff
fcfdfffcfbfffefbfefffbfdfffdffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fefdfffefbfffefbfffffdfffffffefffffdfffffdfffffffffdfffefdfffcfdfffcfffffeffff
fffffffffbfefff3f8ffc5c6ff3c38b5211cbf1313c31515cd110ec8130ec71611c81611c61410
c71410c71311c91513cb1314c81515c5100bba0100a30b06a90503a30306a500059f000697001a
980f74da24afff14afff01a4fa06a8ff04a7fd07abfd06aafd0babff08a5ff069bfd0293f90090
fa0291fe0393fd0491ff058dfd0a92ff0593fe068ff32296ef469ee477abd3b8d4e5d7e5ebf2f6
f7fffefffffefefbfcfafcfffbfbfffef5faf9fdfefffdfffffffffffffffefdfffefbfffffdfd
fffdfdfffffeffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffdfffefbfffcfbfffcfdff
fffffdfffffcfffffefffffffefdfffffbfffffbfffffdfffffffffefffffefdfffff6f9ffdadd
ff4e50b42422b8100dc01112c80d0dc51915cc1510c7140fc81210c80f10c61011c71412ca1814
cb1310c30e0cb90000a30905aa0000a20103a50003a20004a100069e000b990012901166d425a7
ff0ea9ff05a5f908acfe01a8f904acff04a7ff08a9ff09a8ff04a0f90098f90094f90091fe0690
ff088ffb068ef8058ffa0a93fa0c91f2229cf03499dd5da1ceb4ccdedadde1ebeef3fdfefffffe
fffbf9f9fdfffffcfefffffefffffffffffffefdfffefdfffffffefffffdfffffdfffffeffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffdfffefdfffefdfffefffffefffefffffdffffff
fefffffefbfffffafffffdfefffffefffffffcfffefffafaffeff2ff676ac52c2db31414bc1414
cc0d0dc51816cd120dc21712c71412ca1212ca0f12c80f12c81513ca1512c60b09b70100a80300
a50000a20103a70003a50001a00002a10004a300059f00099a000a8d005acb2ca8ff19abff03a3
f703abfe00a5fc02a5ff05a6ff09aafe0aabff00a5fc0099fa0090fa018efc0491fa0993fd058f
fa0692fd0190f90794f5169bf2369ee168a1c8b4cfe3cddde9e5ebf2fffefffffcfefcfdfffdfe
fffffffffffffefffffcfdfffefffffffffefffffefffffeffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffefffffefffffffffffffefffffbfffffbfffffefffffff7fbfcfbff
fffbfafcfefcfcfffdfcf8f9fff1f2ff8a8cda2a2cae1415b90f11c31215cb1113c51212c21813
c81410c71415cb0e11c70d12c51317ca1613c60604b20000a60502ab0300a70100a50000a40002
a10001a30001a30000a50000a40003a000099b000c94034ac32ba1ff1cb1ff00a3f905adff07a8
ff09a7ff07a6fd09aafe08aeff02a6ff0097fa008ff70194fc0393fd0491ff038fff0090ff0193
fd0694f91496ef39a6ea4798c5a2caddcedee4e6ebeefdfffffcfcfff8f7fbfffdfefffffeffff
fcfcfbf7fffffcfbfffafffdfdfffeffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffdfffffdfffffefffffffefffff9fffff9fffffefdfffffafefffcfefffffefefffffffafc
fdf5f7ffa8a8ee3a3aac1a1bb91213c71013c90f12c80f11c31212c21613c61312c60f13c60e13
c61317c91115c20606b20000a80101a70000a60100a80000a70000a40002a10002a10100a30300
a70100a70305a900009d0009a1000993003ab32497ff21b0ff05a4fb06a5fd06a6fe09aafe08a9
fd01a7fa04a9ff07a5ff019afd0093fb008ffc028fff0592ff0292ff008ffe0090fd0896fb1098
f22f9fe5509ac498c5dabcd6dddbe7ebf4f8fdfffefffff9fefffcfdfffffcfffffafdfff9fafe
f8fefefefffdffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffdfffffdfffffe
fffffffffffffcfffffcfdfffefdfffffdfdfff7f6fafffffefdfbfbf7fcffcacffc4947b81c1a
b41213c11113cb0f11c90c0fc51112c81413c71212c21013c20e12c51317ca1214c00708b00100
a30000a20000a40000a50000a70000a50001a40001a30102a00500a10600a50500a70000a40305
aa0001a500039f000899002ba92b93f825adff0ca9ff00a8fb04a9f808abfa09a9ff09a8ff09a9
ff0aa7ff049afe0193fd008efe008fff0590ff0690ff0890ff0b92fe0a8ef91997f62b9dea3995
ca86c0d6bbdbe1d3dfe3f4f5f9fffcfffcfafff9fdf8f9fff7fafff8f9fff9fcfefefcfbfdffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffefffffefffffefffffffffdfffffbff
fffbfffffdfffffefcfffefdfffbf9f8f9fbffe1e3ff5659ae2826b51817c51112c80f11c90d0f
c70f10c61412ca1213c91114c31215c41416c81111c10606ae0000a20402a20202a20000a20002
a50000a50001a40001a30002a10301a10500a30600a50500a70400a80401aa0000a50001a50306
a400078f0022852489d727adf312adf20aaef605adfa05a6fc06a5ff07a9ff05a7ff07a4ff069f
ff0196fe0090fc018efd0791ff0b91ff0a90ff0a8fff098ffe0d93f8279eed449dcf6fabc8b4d6
e6d1e0e9e9ebf5f9f9fffdfffef9fff9f8fff8fbfffcfdfffffafcfcffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffefffffefffffffefffffffbfefffbfefffbfefffdfefffefa
fffcfbfdf7fcffeef2ff7471d42623af1312b61215c41113c51011c51412c91412ca1210c71112
c81314c81417c61011bf0404ac0000a30301a10200a00101a10003a50001a30002a40002a30003
9e01039e0300a30300a50300a50100a50501a70400a60a04a900009f0402a2050b92142b8193c4
fc7bd2fe40b9ea0fabec02aefa04abfc04a9ff03a9ff00a4fd02a9ff05aaff07a5ff029cfb0093
fb0190fd058fff0890ff058fff038dfd0b91fd0e8ef41d95ee3ca1e6559ac59fc8dfcdd9e3f1ee
f0fff9fefffcfffefdfffbfdfdfbfbfbffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffefffffffffffffcfdfffefbfffffbfefffdfdfffffefffcf9fbfcfbfff3f7ff9499
de2823ae1c18c51414c40c10c21114c31313c51613c71511c81210c71314ca1214c60b0fbc0203
ab0100a40200a20301a10000a20001a00001a30002a40002a30003a100039e0102a00100a50100
a70000a50000a40100a10803a60300a10d09a50100921b1c8ea0a2e2e2f5ffcafaff8ddffe3db7
eb13a8eb0faef807abfd00a4fd03a9ff03abff03abfe07abfe08a8ff03a0fe0098fb0191fb028f
fd0291fe018efd0a90ff0a8ffe0c93ff1795f33a9fe35099c598c1d8c3d3dfe3e3effaf5fefffd
fffffefffbfbfbfffffeffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffefffdfefffdff
fffdfffcfdfffbfdfffefdfffffffefffffefffffefef5f6ffb1b1f73636aa1717b71011c71415
cb1112c61113c51414c61511c41510c51713ca1413c7080bba0104ad0000a10302a50300a50000
a30003a50002a10000a00103a50101a10101a10300a40300a50000a80000a80000a50001a30102
a00504a20300a30503981216878388d3eef0fff4f9ffebfbffdafeffa1e1ff58bbed22acee0aa8
f604a5fb06a8ff06a8ff05a7ff01a9fe03abfe07aaff05a5fd019afc0095fa008ef80695ff0790
fe0790fe0691ff0891f71498f32c9fe8449ace7ab3d3b5cfdfdee7ebeef0f1fffefdfffffff9fb
fbffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffefffffefffffffffffffffefffffefffffeffffff
fffffffffffffefffffefffffefffffffffffffffffffffffffdfffffdfffffbfffefbfffcfdff
fcfffffefffffffffdfff9f9ffdadaff4b4ab81d1bb41718c60e10c80f0fc71415c91212c41515
c51512c21714c41b17ca0f0cbf0000ab0000a40504a70100a30000a40000a60002a40004a30204
a60000a20301a10301a10300a50100a70000a80000a70000a40002a10104a301009c05039c100f
8d6e72c0eef2fffafafff9fafefbfeffeffaffe3fdffb5ebff61c2f42cadec1aabf60ba5f807a6
fe04a8ff02a9ff00a8fb04aafd08abff05a7ff019ffd0096f90092f80391fc0792ff028ffe0190
fd0393fc0c94f2299fec3c98d36caacea9cee2cedde6eaedf1f8fafafdfefcffffffffffffffff
fffffffefffffefffffefffffffffffffdfffffdfffffffffffffffffffffffffffffffffffdff
fffffffffffffefffffffffffeffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffdfffffdffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffcfffffcfffffefffefffffdfffffdfffffefffffefffdfffefdfffcfdff
fcfdfffcfdfffefdfffefffffffffffffcfdfbfcfefef6fafbfafffffbfffffbfdfdfdfcfef9f7
ffededff6365bd2424b41412c21210c71412ca1112c61013c21413c11616c21917c41614c10b09
b60000a90000a50102a60000a40001a30000a40000a40001a30001a30000a40001a30000a00001
a00103a50002a60000a20002a10306a40002a10000a404039f110f915958b4e9e8fffbfcfffafa
fffbfffff8fffff6fffff2fbffe8fbffccf8ff8ad5fb3cb0e71aa9ed0aacfb00a9fe04a9ff04a6
fe04a9ff06abff00a8fb07adff04a4fc029cfb0393fc018efd008efe0191ff0592ff0690fa0d94
f61f9cf1319ee24b9acd96b9dad0dbe9dfe4e3fbfbf5fbfdfdfcfefffefffdfefffbfffffafdfe
fafdfdfdfcfefffafdfffbfffffffffefffefdfffdfefffdfffdfffffbfffffdfffefdfffcfdff
fefdfffcfffffefffffefffffefffffefffffffffffffffefffffefffffffffffffffbfffefbff
fefdffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fefffffefffffffffefffffefffffefffffefffffefffffffefdfffcfdfffcfdfffcfdfffeffff
fffffefffffefffefcfbfffffff9fcfff7fafefdfffffdfffffbfcfff4f4ff7f81d5292ba81515
bb1413cd1210c8100ec51112c61316c51514c21a19c31514be0707af0000a60000a50001a50000
a40000a40000a40001a30001a30000a40000a40000a40000a40003a50002a40000a00002a40202
a200019f00009d0304a20503a30e0d994342a4d8d8fffafafffcfbf7fffefff7fafef4fcfbf8fe
fdfffffefefdfff2fcffd5faff98e2ff51bfef22aaec0fa9f60aaafe07a9ff03a5fe01a6fd01ab
fd00aafa06acff06a6fe079dff0496ff0090ff008dfe028ffe0491ff008ffc0694f91499f52e9a
e74c93cc79a6c8b7d1dfd4e3e5edf2f5fafcfdfffffefefffbfffffcfffefafcfcfcfdfffffbff
fffbfffffffffffffffefffefffffffffdfcfff9fbfcfdfffffdfffefdfffefffffefffffeffff
fefffffefffffefffffefffffffffffffffffffffffffffffffbfffffbfffefdffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffefffffefffdfffffdff
fffdfffffdfffffffefffffffffffffffffffefffffefffffffffefffffefffffdfffffdfffefd
fff7f7f7fdfffffafcfcfafbf7fbfcfff8f8ffa8a8e82f30b01616bc1916c6130fc61413c71413
c71210c71413c71918c61211bb0706b00000a70000a50000a50001a50000a40000a40000a40000
a40000a40000a40000a40000a40000a40003a60000a30100a40100a20501a60605a90000a10102
a00a099b3837a5cfd0fff8fbfffafffff8fdfcfffdfffffdfffbfffff6fbf9fffefffffefff6f9
fdf0fdffe4feffbcf0ff74cbf737aeec12a7f702a7fe05a8fe0aadff03a8ff01a8ff02aaff02a9
ff05a5ff059fff089aff0592ff038ffa0490fb0594fd008df60b93fd1192f528a0f33da1e1579d
c59ec8dfcedae4e8e7e9fafafafdfbfbfdf8f9fffefffffffbfcfbf7fffffefcfffdfdfcfefefe
fefffffefffffefffefffffdfffffefffffefffffdfffffdfffffdfffffefffffefffffffeffff
fefffffefffffeffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffdfcfffdfdfffbfffffbfffffbfffffbffffffff
fffffffffffffffffffffffefffffefffffefffffdfffffdfffffdfffffefffdfdfdfdfbfafeff
fdfdfefcf7f9ffccceff4547ab1d1cba1614cc1410c7100dc11818ca1313c5100fc31a17ca1210
bd0505ad0000a40000a50202a80000a50000a30001a50000a40000a40000a40000a40000a40000
a40000a40000a40005a80000a20501a60a02a90200a40100a30504a7050696232395b0aff7f8f9
fff9fcfaf2f7f5fafefffdfdfffbf9fffcfefefcfefefffefefefcfcfbfbfbfcfefefbffffecff
ffcefcff8ad9ff42b4f023adf517abf90ba7fa0aabff00a6fd00a9fb01aaff01a7ff05a5ff0ca2
ff0a9dff0596fc0395f90092f60695fe0491ff0390fe0091f41297ee379fe44d96c88cb6d3bfd4
e3d7e2eaf1f4f8fffefffffcfbfffffcfffffcfffffefffffffffefffffffffefffbfcfdf9fffe
fefffefffffefffffefffffefffffefffffdfffffdfffffffffffffefffffcfffffefffffeffff
fffffefffffefffffffffffffeffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffdfdfffdfefffbfffffbfffffbfffffbfffffffffffffefffffefffffe
fffffefffffffefffffefffffffffefffdfffffefdfffffefffffafbfffdfdfcfcffe3e5ff5a5f
c61e23b41616c2110fc61211c51112c61314ca1112c61615c3110fbc0000a90000a70000a70000
a60000a60000a40000a40000a40001a30001a30000a40000a40000a40000a40000a40000a40002
a50103a70400a40c03ad0500a70600a605059f1519909c9fdcf6f7fff9f8fffefefefdfffffdff
fffafcfcfdfffffbfbfbfffffffbfdfefafcfdfdfffefbfffef7fcfdf1fdffeefeffe1feffbbf0
ff76caf438aced19a7f408a8f604aefc02acfa04adfe05aaff03a8ff08a7ff08a7ff06a3ff06a1
fe0398f8008ff30093fb0294fe0093fb0897fa1597f62e9ef03f9ad763a5ceabcbe2ced9e1e5e9
e4fffff7fbfaf6fffefefffbfffefdfffdfffffdfffefffffefffdfcfffdfcfefffdfdfffcfdff
fcfdfffffdfffffdfefffdfffffffffffffffefffffefffffefffffffffefffffeffffffffffff
fefffffcfffffeffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffefffdfffffdfffffdfffffdfffefdfffffffffffffefffffdfffffefffffffffffffeffff
fcfffffefffffffdfffffcfcfcfcfcfcfffefffdfcfff0f2ff787cca2127b01115c11111c31514
c81615c91213c70f13c61214c6100fb90100a50000a50000a50000a60000a50000a30001a50001
a50000a40001a30001a30000a40000a40000a40000a40000a40000a40000a10305a90400a40500
a40900aa07039e0c0e8b7579ccf2f6fffcfefffcfbfdfefbfdfffcfefbfbfbf9fcfafcfffbffff
fffcfcfcfbfdfefdfffffcfefef8fafaf7fcfdfafffff7f8f4faffffecfeffd1faff8fddff48b6
f025abeb16acf20caaf707aaf905acfd04aafd03a8fe05aaff08abff08a8ff08a4fe049cfb0098
fb0093fb0091fb0393fd0290fb0a90f51e97ed3ca1e5569ac991bcd7c4dbe3d6e3e1f4f8f9fffe
fffffefffdfefffdfffffcfffdfffffffffffefffffefffffcfffffbfffffbfffffefffefffdff
fffdfffffdfffffdfffefffffefffffffffefffffdfffffefffffffffffffcfffffcfffffeffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffcfffffcffff
fefffffefffffffffffffffffffffefffffefffffefffffffffffffefffffcfffffeffffffffff
fffcfffbfdfefafffffff2f2ff9596ee2e32b61117b60d12c11313c31411c41110c41214c60f14
c30509b50200a80300a40301a70000a40000a30000a40001a50001a50000a40000a30000a40000
a40000a40000a40000a40000a40000a50000a50002a60000a40501a60400a20601a20b0b8d595d
abe8edfff7f8fffdfcfefffdfffffdfffffdfdfffffefdfffcf8fcf7fefefefdfdfdfffefefffe
fffffcfffffefffafffef4fbf8fbfffefafffdf9feffeefeffdcfeffb9f1ff7bcefb3fade922ad
f60aa7f705a9fb04acff00a8fd03a8fe08abff08a9fd07a6fd0cabff02a0fe0098fb0193fd028f
fd0693ff0892fd1296fb1493ef279eed3599d46aa8ceaccde1cdd9e3e5e8ecf6fafbfafeffffff
fffefefefefdfffffffffffffefffffbfffffcfffffcfffefffffdfffffefffffffffbfffefbff
fefbfffefdfffffffefffffdfffffdfffffffffffffcfffffbfffffeffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffff9fffffbfffffeffffffffffffffff
fffffffefffffffdfffffbfffffdfffffdfffefdfffefffffefffefffffffffcfffaf7fdfcf7f8
ffb9b9f93738b81618bd1114c31214c61714c71311c11616c81616c6050ab30000a50000a20501
a60100a40001a50001a50000a40000a40001a50000a40000a20000a40000a40000a40000a40000
a40000a40000a50000a50000a40100a40201a504049e0b0b9534369ad1d4fff7fbfffdfefffffd
fffefafffffbfffffdfdfffffef7faf8fdfffefcfdfbfffffefffffefffdfefffdfffdfcfff7fc
fbfbfffef9fefcfdfffffffdfdfdfcfef3fcffe8feffcef9ff9de2ff57bbf22dabec17a8f30fac
fc04a7fd02a7fd07aaff04a8fb09aafe08a9ff06a8ff08a6ff059dff0295fd0191fb0391fc0490
fb0994fb0796f91e9ff63b9ce05496c98cb5d5c2d9e9d3e3eae9f1f1fbfdfefffffffefdfffffe
fffffffffffffefffffefffefffffdfffffcfffffdfffffefffdfffefbfffefbfffefdfffffffe
fffffdfffffefffffefffffffcfffffcfffffeffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffbfffffcfffefffffefffffefffffffefffffcfdfffef8fd
fcf7fcfdf7fbfcfafefffbfdfdfffefefffefffefcfcf6fff5f3fdffc9ccff4a4bb91b1cba1314
ca1311c9120ec51512c51816c61212c20406b20000a30000a10000a40000a30000a40000a40001
a30001a30001a30001a30000a40000a40000a40000a40000a40000a40000a40000a40000a50000
a40201a40403a60102a607099723258bb0b3f0f5f6fffbfbfffdfffffffefffffdfffffeffffff
fefffffefffefffffefffffffcfffffbfffffcfffffefffffffdfffffbfffffbfffffdffffffff
fffffefffffefffdfdfff6feffeffeffe3feffcef7ff97d8fe4eb7f023a9f110aafd06abff06a9
ff03a7fa06a8ff05a7ff07a6ff07a6ff03a6ff04a7ff059eff0294f80491f80791fb0990fc0b92
fc1195fa2599f0429cdd5f9dc6abcadfccd8dee4e7ebf9f7f7fefefefefdfffefdfffafcfdfbff
fffbfcfffff9fffffbfffffafffffbfffdfffffafdfbfdfffefdfffefbfffffbfefffbfefffdff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffcfffffefffdfffffdfffffefffffffefffffcfdfffcfafffef6fbfcfafffff8fd
fcf9fcfafffefdfffdfffdfcfff4fdffd6e0ff5154bc1f1db21917c7110dca1712cc1915cc1a18
c80e0eba0202ae0000a70201a50302a50201a40000a40000a40000a40001a30001a30001a30001
a30000a40000a40000a40000a40000a40000a40000a40000a40000a50000a40201a400009d0505
9f0c0e8a8386caedf1fffbfbfffffefffffefffffefffffdfffffefffffffcfffffcfffefffffe
fffffffcfffffbfffffcfffffefffffffbfffffbfefffbfefffffefffffffffffefffffefffffe
fffffefffdfffffafffff4feffdffdffafefff6ecdfe37b0ee1ca6ee17a9f511abfc09aafe05a7
ff08a8ff0aaaff02a9ff01a8ff07a5ff0ba3ff0496f90494fa0591fc028ffe008fff0794fd229a
f343a2e75596c288b3ceb7d1e1cfdce4e2e9ecf9fbfcfbfefff9fefff7fffef4faf9fffefffffc
fffcfafffdfefffafcfdfdfffefffffefffffefdfffffafffffafffffbfffffffefffffeffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffdfffefdff
fffffdfffffcfffffefffffffffffffcfdfffcf8fdfcf7fcfbf8fdfcfbfffcfdfff9fcfcf6fffd
fcfaf9ffe4eaff626ac32a2aba1712c11810c9160fca1612c91513c30f0fb90404aa0000a20000
a30302a50201a40100a30201a40001a30001a30001a30001a30000a40000a40000a40000a40000
a40000a40000a40000a40000a40000a40000a40000a40002a402029c0f0d95504fb1e2e2fffafd
fffafdfffcfefffffffffffefffffcfffffefffffffbfffff9fdfffffbfffffbfffbfbfffbfdff
fefdfffffbfefffbfefffbfffffdfffffffffefffffcfffffefffffffffefffdfffffbfffffaff
fff4fdffeefdffe8ffffd8ffffb1edff75ccf43eb0ec1ca6ee10aefc03a9fc04a8fb08a9ff05a7
ff08a8ff0baaff0cabff0aa8ff07a2ff039afc0496fa0290fb068df90d90f71a96f42ea2ef3a9c
d8579fc790bed6c6d8e3dce2e7ebf1f6f5fdfdf7fffafafff8f8fcf6fdfffefbfffff9fefffbff
fff9f8fafffffefffffefffffcfbfffcf8fffefafffffffefffffdfffffeffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffbfffffbfffffdfdfffdfcfffdfe
fffffffffffffcfffffcfdfffffafcfcfafdfbf9fffaf8fff8f9fefdfbfcffeeeeff7074cc1d21
a51916c01811ce170dcb1a12cb1816c60707b10000a50001a50302a50303a30100a30000a20100
a30201a40001a30001a30001a30001a30000a40000a40000a40000a40000a40000a40000a40000
a40000a40000a40000a40000a40201a4080898221f8cb9b7f9fafafffcfdfbfdfffffbfdfefdff
fffdfffffdfdfffffefffffffbfffff9fdfffefbfffffdfffefdfffefbfffffbfffffbfefffbfe
fffbfffffdfffefffffcfffffcfffffefffffefffffffffffffdfffefbfffff4f9fafafffeffff
f9f9fffbecffffd0fbff97e2ff61c7fb31ade91facef17acf60eabfb07a8fe05a7ff07a8fe06a7
fd06a9ff07a9ff09a8ff08a3ff0699f90290f5008ff80393f90491f2199aef39a2e54c9bcc72a5
c5a5c6dac6dce8ddecefeefbf3fafff8fdfff9fbfdf7f9fefcf9fffef5fafbfdfffffffeffffff
fefffffcfdfffcfafffcfafffffffefffffdfffffeffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffdfffffdfffffbfefffbfefffbfffffdfffffffffeffff
fefdfbfbfdfbfafefffbfbfffef5fcfff4fbfff1f4ff7679c42628ac1f1dc31611c8150ecb1e15
d01713c60303a90004a30000a30001a50602a104009f00009f0001a30201a50201a50000a40000
a40000a40000a40000a40000a40000a40000a40000a40000a40000a40000a40000a40000a40000
a40100a40501a60f0c917978bcf5f6fff6f8fffffffffffefffefdfffdfffefbfffefdfefffffe
fffffffefffffcfffffcfffffffffefffffdfffffefffdfffffdfffffdfffffdfffefdfffefdff
fefffffefffffffffffefffffcfffffcfffffefffefffffffffefefefdfbfbfcfbfdfafdfff1ff
ffdefeffccfcffa5e3ff6fc4f138aee91aaaf109acfb00a9fe04a9ff08acff01a9fc02aaff05aa
ff07aaff07a8fc05a4fb009dfb0096f90292f80b93f91494f3279df0329bde499bca87b8d2b7d1
ddccdde0e4ebe8fcfbf7fffffafffffbfdfffcf9fffef8fdfefffefffffefffffffefffffcfdff
fcfdfffefffefffffeffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffdfefffbfefffbfffffdfffefffffefffffefffdfefffffefdfb
faf3f7fcf3faffe7edff7477c82f2fa51b19b9130fc6150fc81712c9120dc20404b00003a20001
9f0003a50100a404009f0600a10201a40001a50000a40000a40000a40000a40000a40000a40000
a40000a40000a40000a40000a40000a40000a40000a40000a40000a40000a40101a108049f2b28
9bd8dafff7fbfcfffefffbf9f9fffdfdfffffffdfffefbfffefdfffffffefffffffffffffeffff
fefffffffffdfffffdfffffefffdfffffffffffffffefffffefffffefffffffffffffffeffffff
fffffffefffffefffffefffefffefcfcfffdfdfffcfffffcfffffefffffffffafffff1feffe7fd
ffcbf7ff95e5ff59c6f92cafee18abf114abf50aa8f507abfd01abfd00a8fd01a9fe06adfe08ae
ff05a7ff009ffb0096fb0090fa0092fc0391f61399f12ea2e9489bcf5d99bd96bfd8bdd7e7d8e1
eaf0eff1fdfcf8fafcf6f8fffcf8fefdfdfefffffefffffffffffffefffffefdfffefffefffffe
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fefffffffffefffdfffffbfffffdfffefffffefffffcfffafafffefffaf7f9f8faffdfe3ff7579
d22b2bb51e1ac01816c41512c51817c50d0fbb0000a80004a90001a30000a20100a30200a30500
a50700a70701a60400a50000a60000a60000a50000a40000a40000a40000a40000a40000a50000
a50000a50000a50000a40000a40000a40000a40000a405039d120c936a67c3edf4fff4fbf6ffff
fffffdfefefdf9fffffbfdfffcfdfffefffffffffffffffffffffffffffefffffefffffefffffe
fffffffffffffefffffefffffefffefffffefffffefffffefffdfefffbfffffbfffffbfffffdff
fffdfffefbfefcfdfffefffffffefdfff9fdfefafefffefdfffcfefff7fdffebfdffe1ffffcbfa
ffa3e4ff71c8f43eb3ea1da9eb0ca7f604a9ff04abff02a9ff02a7fe06a7fd0baaff0eadff09a8
ff02a1ff0095fc0092fa0692f61094f21e9cf430a0ec3c97d45a9bc8a2c4e2d2dfefe2e4e5f8f5
f1fbfffcfafffefbfffffdfefffffefffffffffffffffdfffffdfffffdffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffefffffefffffefffdff
fffbfffefdfffcfffffefffffefffefff7f4fdf8f7ffd7daff6569c1292cac1514be130dca1612
c51a18c50a0bb30000a40002a50000a20001a50403a70200a20600a50400a80500a70500a40600
a60000a80000a70000a40000a40100a40000a40100a40000a40100a40000a40100a50000a40100
a40000a40100a40000a40100a40604991b178ea2a1ebeef5fffafffcfef9fbfffdfefffffafcff
f8fdfffcfdfffefffffffffffffffefffffefffffefffffefffdfffffdfffffffffefffffeffff
fefffffefffefffffefffffefffffefffdfefffbfffffbfefffbfffffbfffffbfffefafffdfafd
fbfcfcfcfcfefefafffffafefffffcfefffcfefdfdfdfdfffffafffef1fdffe5fdffcdf9ff9ae7
ff69cdfd3bb2f027adf318a9f411a9f70ba9fc08a8fc0aa8fc09a9fd04a9ff04aaff06a8ff04a0
ff0498fc0192f80090f80493f41f9af03ca1e64d95cb77a7cbb7d3e4d0e0e6d9e5e5f1f9f8fbff
fffdfffffdfefffdfffffbfffffbfffffdfffffdfffffffeffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffcfffffafcfbfdfefbfffffbfffcfdfffcfffb
fdfffbfffdfcfef4f8ffbbc0ff5255c12126b11416ba100fc31b17ce1915c20d0bb10200a60100
a40302a60302a60201a50400a50300a40300a40300a50300a50500a40300a40100a50100a40100
a40100a30300a30100a30300a30100a30300a30100a30300a40100a30300a30100a30300a30100
a30300a3080695302d94bcbcf8e9edfffbfffffffcfefefbfdfdfffcfafffbfafffbfbfffcfffe
fffffefffffdfffffeffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffefffdfffffdfffffdfffffdfffffdfffffdfffffffffffffffffffffffdff
fffdfffffffffffffffffffffffffffffdfffffbfffff6ffffefffffe4feffd6feffb3eaff86d2
fc53b9ea30aee918abf10caaf808a8fc06a9ff03a5fd06a8ff05aaff04a8ff08a7ff07a5ff009b
fe0091f50a93f71091ee28a1f0359fdc4695c081b6d1c1dbe9d4dde1ebeaecfbf8fafbfefff7fe
fff7fffefafffefcfffbfefffbfefdfffffefffefefefcfcfcfafcfcfbfdfdfefdfffffdfffffe
fffffefffffefffffefffffbfcfffffffdfefff9fdfef9fffaf4f6f6fdf9fffaf6ffedefff9397
d84044b5181aae1316be1115c8191ace100ebe0401aa0100a30100a20100a30400a50000a20100
a20000a20300a40100a30300a40100a30300a40100a30300a40100a30300a40100a30300a40100
a30300a40100a30300a40100a30300a40100a30300a40100a30300a40100a30300a40805962421
8eaeacf2dbddfbe8ebf3f7f5fbfcf9fbfdfffefafffbfbfffcfdfffefffefffffdfffffdfffffe
fffffffefffffeffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffff8ffffecfeffdafeffb6f3ff8adeff57c3
f333afeb24aaf01daefa17acfc0da9fc03a7fa00a7fa01a9fe06abff0aa9ff0ba4ff0398ff0598
fe0196f10f99eb2fa4e7429cd2629dc498bad7c6d7ead1dbe5e0eaf1f2fbfef7fffef9fefcfeff
fbfffefafdfbfbfefbfdfefefefdfffffbfffefcfffdfefefefffffffffefffffefffffefffffe
fffefffbfdfefcfdfbfffcfbfffcfffdfafefff3f5ffc1c2fe5c5abe2825aa1d19b81715c31919
c91316c50708b60101ab0000a30001a00201a40003a20100a30001a00100a30104a30100a30002
a10100a30002a10100a30002a10100a30001a30100a40000a40100a50000a40100a50000a40100
a50000a40100a50000a40100a50000a40100a50000a40100a505029e120a93564fb7bcbff2d8de
f1e8e9f3e9e8ecf2f0f0fffffefffffefffffffffefffffefffffefffffffffdfffefdfffeffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffdfffff6fefdf1feffebfeffe1fdffd0f9ffaeeaff7dccf74cb4
e92dabeb16a9f107a9f803abfe03abff03a8fe07a6fd08a7ff04a7ff03a2ff029cfb0094f20995
ef1c9bf02c98e94198db5c9aca9ac2dfc6dce8d7e0e3ebedeefdfbfbfdfdfdfffdfdfffefffffd
fefbfbfbf6fbf9f8fef9fcfffbfffefdfefcfbfffefffffffffdfffffbfffffbfffcf9fbfbfffb
fffffcfffdfffff2f7ffa7aae13e409f2522ad1a16bc1713c61714c81818c40708b00000a60000
a50103a50303a30202a20000a000009f0000a00101a10101a10101a10101a10101a10101a10101
a10101a10101a10100a30100a40100a40100a40100a40100a40100a40100a40100a40100a40100
a40100a40100a40100a40100a40100a40301a108019e120c8f3e40987075ac8a8ab2b4b1cae9e6
effffefffffefffffefffffefffffffffdfffffdfffefdfffffdffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffefbfffafffffbfffffcfefefef7fdffeafdffd3faffb6f4ff83d9ff5dc8fb3ab4
f024abef1babf217acf611acf50babf905a7ff01a4ff0aa8ff0aa7ff019dfe0096f50594f51c9a
f2359be44997cc70a6c7a1c6dac4dae6d5e0e8e7eaf2fbfafefffafbfffdfcfbfffffafffefbff
fcfdfefafffefafffffcfffffefffffffdfffffbfffff8fdfefcfefffffbfffffcfffdfffff0f4
ff8081d72726a61a1ab41617bf1616c20f0fb90609a700009d0001a50103a80000a30401a40401
a40300a30300a30401a40300a30200a20300a30300a30300a30300a30300a30300a30300a30300
a30301a10301a10301a10301a10301a10301a10301a10301a10301a10301a10301a10301a10301
a10301a10301a10101a10203a70206a1080b951013861d1e797878b4f5f6fff9fbfcfffffeffff
fefdfffffbfffffbfffcfbfffefffefffffdfffffeffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffcff
fdfefffdfffdfdfefbfdfbfdfef7fefff0feffe8fdffe3ffffd6faffbcebff96d7fd68c5f240b6
ea1eade70ca7ec0da8fd0aa8ff09aaff05a9fc04a9ff06a8ff039ff90699f50f98f41f9cf12b9a
e23b98cf62a9cb9ac7dccadaebdbdde7ebf0eff4fbf6f6fffff6fefefafcfcfffffefffffcfcfb
f7fffffefffffefffffefffffefcfefefdfdfdfffdfffffefffcfefff0f3ff8180d02c2c9e2528
a82023a92223a915159710118b17189010128f0e0f8f1110901613911714921613911512901512
9016139116139115129015129015129015129015129015129015129015129015138f15138f1513
8f15138f15138f15138f15138f15138f15138f15138f15138f15138f15138f15138f15138f1312
900d1195090e92111794161a8b161674908fcdf6f6fffafcfdfffffffffffffbfffffafffffaff
fcfbfffcfffefffffdfffffeffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffcfffdfbfefcfffdfdfffd
fffffffffffffffbfefcfcfdfbfafbf9fbfdfef6fdffe5fcffc6f8ff9fe9ff6fd6fd4fc5f637b0
ee26a5ea1da9ec17abf10ca9f30aacfa0cacff09a7ff04a0ff059dfc0799f31a9eeb339fd94396
c370a3cba7c7e4bbd8e6cbe4e8e1eff5f4fafffefdfffffcfdfefcfbfdfefafffffefdfffeffff
fffffffffffff7fffff8fffffefffdfef6f5f7fafbffdddfffb9bcefbdbff9bebffcb5b3efb9b4
f1beb6f5bab3f0bcb9f0b8b9ebbabaf0bab9f1bab9f1b9b8f0b8b7efb8b7efbab9f1bcbbf3bab9
f1bab9f1bab9f1bab9f1bab9f1bab9f1bab9f1bab9f1babaf0babaf0babaf0babaf0babaf0baba
f0babaf0babaf0babaf0babaf0babaf0babaf0babaf0babaf0babaf0b8b9f1b8b8f4b8b9f5b7bb
f0b5b9e9bdbce8dfddfbfdf9fffffefffffdfffffdfffdfdfffafefffafffffbfffefffffcffff
fcfffffeffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffbfefcfcfffdfffefefffdfdfdfcfefcfefefbff
fffbfffefafffdfbfffffafefff6fcffeefdffe6fdffdbfcffcdfaffb4eeff93dcfa6ac4ed44b1
e528abea19acf20ea8f507a5f808a8fc09a8ff09a8ff09a1f90e9aed1e9beb319ae43990d05da2
cd90bfdac4d8e9dfe2eaefeceefef9fafffffffafcfcfdfffefdfffffdfffffdfffffffff8ffff
f8fffcfbfffefefffefff7f8fcfafcfff4f7fff7fafff9f9fffaf8fffcf7fffbf4fffcf6fff9f9
fffafcfffafcfffafbfff9fafffafbfffafbfffafbfffafbfffafbfffafbfffafbfffafbfffafb
fffafbfffafbfffafbfffafbfffafafffafafffafafffafafffafafffafafffafafffafafffafa
fffafafffafafffafafffafafffafafffafafffafafff9f7fffafafff4f8fff3f7fffbfbfffdfb
fffffafcfffcfdfffdfffffdfffdfcfffbfefffbfffffdfffefffffcfffffcfffffeffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffefffdfffffefffefefffdfdfefdfffdfffffcfefef7fcfbfafffdfcff
fdfefffdfffefefffefffffefffefcfff6fcffecffffdafeffcafdffaaf0ff81dbff5fcafd44ba
f532aeee27a9ec22abf01aa8f516a8fa16a8ff12a1fc119cf3209eec339ddc4295c86a9fc49ebf
d9c4d8e9d6e0eae5ebf2f7fafefdfffffdfffffbfffffbfffffffffcfffffefffefffffefffdff
fffbfffffbfffffbfefffdfffffdfffffdfcfffdfbfffdfcfffbfdfffbfefffbfffffbfffffbfe
fffbfefffbfefffbfefffbfefffbfefffbfefffbfefffbfefffbfefffbfefffbfefffbfefffbfe
fffbfefffbfefffbfdfffbfdfffbfdfffbfdfffbfdfffbfdfffbfdfffbfdfffbfdfffbfdfffbfd
fffbfdfffbfdfffbfdfffbfefffdfefffdfefffbfefffbfefffbfdfffdfefffffffcfffffbfffe
fffffdfffdfefffdfffffffffffffffffffdfffffdffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffefffffcfffffefffffefffffffffffffffffffffffffffffefffffcfffffefffffffffe
fffffefffffdfffdfdfff8fdfff3ffffecffffe4ffffdcffffd2fdffc1f3ffaee8ff8bd1f970c4
f451b5eb3aaceb29abf11eabf615a9f514a8f416a5f01c9fe92fa1e83996d35a9aca94bbdbc4d4
e5dde0e8e5e7e8f3f6f4fbfffef9fffafffffffffffffdfefffdfefffbfffffbfffefdfffffdff
fffdfffbfdfffcfdfefffdfdfffdfefffdfffffdfffffdfffefdfffefdfffefdfffefdfffefdff
fefdfffefdfffefdfffefdfffefdfffefdfffefdfffefdfffefdfffefdfffefdfffffdfffffdff
fffdfffffdfffffdfffffdfffffdfffffdfffffdfffffdfffffdfffffdfffffdfffffdfffffdff
fffdfffffffffefffffefffffffdfffffdfefffdfffffdfffbfdfffbfdfffffdfefffdffffffff
fffffffefffffffffefffffdfffffeffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffefffffeffff
fefffffefffffffffffffffffffffffffffffefffffefffffffffffffffefffffefffffefffffd
fffffefffffffffcfffdf7fefbf8fefdf8fffff2fcffe5f8ffddfcffcdfaffb8f3ff9ae5ff79d4
ff5bc6f941bbef34b5ee2babec2dacf12ca8ef32a1e548a2dd579bca709fbe9cbfd3c7e1efcddf
e6deeaeceef6f5fbfffffbfffffbfffffbfffffdfffffdfffffbfefffbfefffbfffefbfffefdff
fffdfefffffdfffffefffffefffffeffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fefffffffffffffffefffffefffdfffcfdfffcfdfffffdfffffffffefffffcfffffefffffeffff
fffffeffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffefffffefffffffffffffffffffefdff
fefdfffffffffffffefffffefffffefffffefffffefffffffffffffefffffefffcfdfffffefdff
fcfafffbfefffbfffffefffffffafdfff1fdffecfdffeafbffe6fcffe0feffd4feffbdf5ffaaea
ff9bdffc85cff171c3ec5fbae74dade247abe145abdc43a1cc509abc98cce3cce6f4e7f1fbfbfe
fffbfffffdfffefffffefffffffffefffdfefffbfefffbfffffbfffffbfffffdfffffffefffffe
fffffefffffeffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffefffffffffffefffffffffffeffffffffff
fefffffffffffefffffffffffefffffffffffefffffffffffefffffffffffffffffffffefffffd
fffffdfffffffffdfffefdfffffffffffffffcfffffcfffffefffffefdfffefdfffeffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffdfffffdfffffdfffffdfffffdfffefdfffefdfffffdfffffffe
fffffefffffdfffffefffffffffffffefffffcfffffcfffcfdfffdfffdfffefdfffcfffffcfffe
fafffefafffdf9fdfdfdfcfefefffdfdfffdfdfefffdfaffffefffffe7ffffe1fcffddffffcefc
ffbbf6ff9de9ff87dfff77d8ff71cdf673c0e17db6d093b4c8b9d0e0fffefffffefffffeffffff
fefffffefffffcfffffefffffffdfefffbfefffbfffffdfffffffffffffffffffffefffffeffff
fffffefffffefffffefffffefffffefffffefffffefffffefffffefffffefffffefffffefffffe
fffffefffffefffffefffffffffffefffffffffffefffffffffffefffffffffffefffffffffffe
fffffffffffefffffffffffefffffffffffffefffffefffefffffdfffffbfffffcfffffeffffff
fffffffffffffefffffcfffffcfffffffffffffbfffcfbfffcfdfffeffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffdfffffbfffffafffffbfffffdfffffdfffffdfffffffffffffffffffefffffefffffefffffe
fffffffffffffefffffcfffffefffcfffffbfffffcfffefdfffcfffdfcfffdfdfffffffffefeff
fdfffffcfffffcfcfffdf7fafef6f9fdf8fcfdfafffff5fcfff6ffffeef8ffebfbffe3ffffdcfe
ffddfdffdfffffdefbffd0f1ffb0d6e8add7eafffffefffefffffefffffefffffffefffffcffff
fcfffffefffefffffefffdfffefdfffefffffffffffffffffefffffefffffffffefffffefffffe
fffffefffffefffffefffffefffffefffffefffffefffffefffffefffffefffffefffffefffffe
fffffefffffefffffefffffefffffefffffefffffefffffefffffefffffefffffefffffefffffe
fffffefffffffffffffefffffefffefffffdfffffbfffffdfffffffffffffeffffffffffffffff
fefffffefffffffffffffbfffefbfffefdffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffdfffffbff
fffbfffffdfffffdfffffdfffffffffffffffffffefffffefffffefffffeffffffffffffffffff
fefffffffffcfffffcfffffcfffefdfffcfefefbfffefbfffffdfffffffffcfcfdf9fbfcf8fcff
fdfbfefffdfefffffefefffefdfffdfdfffefefffcfdfffdfcf7faf8f8fdfbfffffef8f8f8f8fd
ffebfbffcfecfac3eaf8fffff9fffffcfdfefffbfefffbfffffdfffefffffffffffffffefffffe
fffffffbfffffcfffefffdfefffdfffffdfffffffffffdfffffffffffdfffffffffffdffffffff
fffdfffffffffffdfffffffffffdfffffffffffdfffffffffffdfffffffffffdfffffffffffdff
fffffffffdfffffffffffdfffffffffffdfffffffffffdfffffffffffdffffffffffffffffffff
fefffffffffefffffefffffefffdfffffdfffbfdfffbfdfffffffefffffffffffffffffefffffe
fffdfffffdffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffffffffffffffffffffefffffefffffffffdfffffdff
fffdfffffffffffffffffffffffffffffdfffffdfffffdfffffdfffffffffffdfffffafffefbff
fffffefffffffffefefefcfffdf9fefcfafdfbfefffdfffffefffffefefffdfdfdfdfcfcfcfffd
fdfffefefffffffcfefef7fcfbf9fffefdfffffefefefffefefffefefdfefff9fdfff3fefff3ff
fffffff7fffffbfbfefffafdfff8fffffafffffffefffffefffffefffffffefffff9fffffbfffe
fffdfdfffdfefffdfffffdfffffdfffffdfffffdfffffdfffffdfffffdfffffdfffffdfffffdff
fffdfffffdfffffdfffffdfffffdfffffdfffffdfffffdfffffdfffffdfffffdfffffdfffffdff
fffdfffffdfffffdfffffdfffffdfffffdfffffdfffffdfffffdfffffffffefffffffffefffffe
fffdfffffdfffcfbfff8fbfff9fdfffffdfefffffefffffffffffefffffefffdfefffdfffffffe
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffffffffffffffffffffefffffefffffffffffffffdfffffdffffffffffffff
fffffffffffffffdfffffbfffffbfffffbfffffdfffffbfffef9fffdfafffcfdfffffdfdfdfdfd
fdfcfffdfdfffefafffbfdfefcfffffefffffffffefdfdfefcfffffefffefefefbfdfefefefbff
fff8fffff7fffffcfefefffdfdfffbfcfefcfcfffcfffefdfffffefffcfcfc030000000000
}\cf3\fs52 
\par Plagiarism Checker X Originality Report\cf1\b\fs26 
\par Similarity Found: 12%\b0\fs24 
\par 
\par Date: Saturday, May 21, 2016
\par Statistics: 1409 words Plagiarized / 11847 Total words
\par Remarks: Low Plagiarism Detected - Your Document needs Optional Improvement.
\par -------------------------------------------------------------------------------------------
\par \pard 
\par Music Genre Categorization \highlight4 Using Machine Learning Techniques A\highlight2  Major Project Report Submitted in Partial Fulfilment \highlight4 for the Award of\highlight2  BACHELOR OF TECHNOLOGY IN COMPUTER SCIENCE ENGINEERING By Rahul Mishra (2012ECS 01) Sumit Jha (2012ECS 11) Mahendra Kumar (2012ECS 53) \highlight4 Under the Guidance of\highlight2  Mr. Sanjay Sharma To \highlight4 SHRI MATA VAISHNO DEVI UNIVERSITY,\highlight2  J&K, INDIA MAY, 2016 ii CERTIFICATE This is to certify that we, Rhra (2012ECSumiha (2012ECS11), Mahendr (2012ECS have worked \highlight4 under the guidance of\highlight2  \ldblquote  Mr. 
\par 
\par anjaS \rdblquote  on the project titled \ldblquote  Mure Cazationsininig Tnu \rdblquote  in the School \highlight4 of Computer Science\highlight2  & Engineering, College of Engineering, \highlight4 Shri Mata Vaishno Devi University,\highlight2  Kakryal, Jammu & Kashmir from 2nd Jan 2016 to 23 rd May 2016 \highlight4 for the award of\highlight2  Bachelor of Technology in Computer Science & Engineering. \highlight4 The contents of this\highlight2  project, \highlight4 in full or in\highlight2  parts, \highlight4 have not been submitted to any other\highlight2  Institute or University \highlight4 for the award of any degree or\highlight2  diploma. 
\par 
\par Student 1 Signature : Student 1 name : Rshra Student 2 Signature : Student 2 name : St J Student 3 Signature : Student 3 name : Mahendra This is to certify that the above student has worked for the project titled \ldblquote  MuGenre Categoriza ug Mache Lig Tnes \rdblquote  under my supervision. Mr. Sanjay Sharma Guide Name & Signature Date: ___________ ___ iii ACKNOWLEDGEMENT \highlight4 It is a\highlight2  moment of great pleasure and immense satisfaction for us to express our deepest sense of gratitude and indebtedness \highlight4 to all the\highlight2  people who have contributed in making of our major project a rich experience. \highlight4 We have taken\highlight2  efforts in this project. 
\par 
\par However, \highlight4 it would not have been possible without the kind support and help of many individuals and organizations.\highlight2  We \highlight4 would like to extend\highlight2  our \highlight4 sincere thanks to all of them.\highlight2  We are \highlight4 highly indebted to\highlight2  Mr. Sanjay Sharma for his guidance and constant supervision \highlight4 as well as\highlight2  for providing necessary \highlight4 information regarding the\highlight2  project & also for his support in completing the project. 
\par 
\par We \highlight4 would like to express\highlight2  our gratitude towards members \highlight4 of Shri Mata Vaishno Devi University\highlight2  for their kind co-operation and encouragement which help us in completion of this project. Finally, we \highlight4 would like to\highlight2  thank all our Teachers, Friends and Family Members who have supported us throughout and enlightened us \highlight4 to take the\highlight2  right path and reach there. The days we spent in this institute will be cherished forever and also be reckoned as a guiding factor in our career. Rahul Mishra Mahendra Sumit Jha B. Tech. 
\par 
\par 8th Semester (SCSE) iv ABSTRACT Music \highlight4 has some really\highlight2  powerful effect on our emotions, and Human ear is quite incredible at predicting the genre accurately, although music \highlight4 genre is a\highlight2  relatively complex concept that sometimes the music industry itself feels confused in assigning genre to some of the songs. Classification of genre by Machine \highlight4 is one of\highlight2  such technical approach which has a \highlight4 major drawback of\highlight2  predicting genre accurately. 
\par 
\par Previously many attempts has \highlight4 been made to\highlight2  design system to categorize music but the prediction result was not overwhelming. So, the problem continued that can machine predict genres of songs with better accuracy results? The Project discusses various Machine Learning concepts \highlight4 of classification and\highlight2  \highlight4 improving the accuracy of\highlight2  those classification techniques to be used for Genre based Music Categorization is the goal of our Project. 
\par 
\par In this project Million Song Dataset, made available by LabROSA, containing 30 summary features for each music files one of 10 genre, being \highlight4 used as training and testing\highlight2  data. The project focuses on implication of Classification algorithm like, Random Forest, Gaussian Naive Bayes, Support Vector Machine, Decision tree, K-Nearest Neighbor. 
\par 
\par Lyrical modelling concept has been the second approach improvising \highlight4 Bag of Words\highlight2  technique \highlight4 over the dataset.\highlight2  We aimed to study and apply various machine learning concepts \highlight4 to solve a\highlight2  real world problem like Music Categorization based on Genre and come out with an improved result of 62% F1-score while using Multiclass classification technique and 47% F1-score accuracy while applying Lyrical Modelling concept. 
\par 
\par For the fact that many songs are unlabeled \highlight4 and much more\highlight2  songs are being released daily, the classification technique predicting genre with an accuracy of 62% F1- score is quite of help. \highlight4 v List of Figures Figure\highlight2  1. \highlight4 Schematic overview of feature extraction\highlight2  and feature selection .......................................................... 9 Figure 2. \highlight4 Schematic Overview of\highlight2  \highlight4 music genre Classification\highlight2  ........................................................................... 12 Figure 3. 
\par 
\par Dataset Composition .......................................................................................................................... 13 Figure 4. Small part of Million Songs Genre Dataset ....................................................................................... 14 Figure 5 . Balanced Dataset Composition .......................................................................................................... 16 Figure 6 . 
\par 
\par Pickel of Lyrical Dataset .................................................................................................................... 21 Figure 7. Gaussian \highlight4 Naive Bayes Classifier\highlight2  ....................................................................................................... 32 Figure 8. \highlight4 Decision Tree Classifier\highlight2  ..................................................................................................................... 38 Figure 9 . 
\par 
\par \highlight4 K Nearest Neighbor\highlight2  Example ............................................................................................................ 41 Figure 10 . K \highlight4 Nearest Neighbor Classifier\highlight2  ......................................................................................................... 44 Figure 11 . Random Forest Example ................................................................................................................... 46 Figure 12 . 
\par 
\par \highlight4 Bag of Word\highlight2  Example ...................................................................................................................... 50 Figure 13 . Bag of Word Scheme Accuracy plot ................................................................................................ 53 vi \highlight4 Table of Contents\highlight2  1. INTRODUCTION ....................................................................................................................................... 1 1.1. 
\par 
\par Motivation ................................................................................................................................................. 1 1.2. System Overview ...................................................................................................................................... 2 1.3. Scope and Result of Project ...................................................................................................................... 3 2. 
\par 
\par Requirement Specification ......................................................................................................................... 5 2.1. Preprocessing the Data .............................................................................................................................. 5 2.2. Python Libraries ........................................................................................................................................ 5 3. 
\par 
\par Music Genre Classification ........................................................................................................................ 6 3.1. Genres and Feature vector ........................................................................................................................ 6 3.1.1. Genre ............................................................................................................................................. 7 3.1.2. 
\par 
\par Feature Extraction ......................................................................................................................... 8 3.1.3. Common Music Genres .............................................................................................................. 10 3.2. Schematic Model .................................................................................................................................... 12 3.3. Difficulty ................................................................................................................................................. 
\par 
\par 12 3.4. The Dataset and Features ........................................................................................................................ 13 3.4.1. Terminologies ............................................................................................................................. 15 3.4.2. \highlight4 Feature Selection and\highlight2  implementation ........................................................................................ 16 \highlight4 4. Machine Learning\highlight2  ..................................................................................................................................... 
\par 
\par 26 4.1. \highlight4 Role of Machine Learning\highlight2  ...................................................................................................................... 26 4.2. Classification Algorithm ......................................................................................................................... 27 4.2.1. \highlight4 Na\'efve Bayes Classifier\highlight2  ................................................................................................................ 27 4.2.2. 
\par 
\par Decision Tree Classifier .............................................................................................................. 33 4.2.3. K-nearest Neighbors Classifier ................................................................................................... 40 4.2.4. \highlight4 Random Forest Classifier (RFC)\highlight2  ................................................................................................. 46 4.3. 
\par 
\par Bag \highlight4 of words Classification\highlight2  Scheme (Tf-Idf Vectorizer) ....................................................................... 50 vii 5. Conclusion of Experimentation ............................................................................................................... 54 6. Important Codes In various phases of project ....................................................................................... 55 7. 
\par 
\par Future scope of the project ....................................................................................................................... 70 8. References .................................................................................................................................................. 71 1 1. 
\par 
\par INTRODUCTION \highlight4 Classifying Music in\highlight2  CD stores and in online digital media has genre categorization at its base because of its ease to differentiate music in varieties. It has been considered \highlight4 a tradition in\highlight2  CD stores to differentiate shelf \highlight4 on the basis of\highlight2  genre to guide consumers into specific album of specific singer. Apart from that, Online digital media and personal song collection also has genre \highlight4 as one of\highlight2  its main categorization criteria. 
\par 
\par Humans are quite remarkable in distinguishing Music Genre. Usually a rough classification \highlight4 can be done by\highlight2  us after listening few seconds of music but with the improvement \highlight4 in Machine Learning\highlight2  algorithms, after 2010 many attempts has \highlight4 been made to\highlight2  design system \highlight4 for Automatic Music Genre Classification\highlight2  but the result were not very good. 
\par 
\par For those who have used the same dataset of Million Song, provided by LabROSA, comprised of 10 different music genres, has yielded an F1-sore of 58% in [1], which \highlight4 needs to be\highlight2  improved. 1.1. Motivation Consumption \highlight4 of digital music\highlight2  is gaining popularity and its distribution over internet is increasing by significant amount day by day. 
\par 
\par Music genre are \highlight4 generally used to\highlight2  categorize digital music collection so as to facilitate navigation into it. Associating genres automatically to music \highlight4 has become so\highlight2  important firstly \highlight4 because of the increase in\highlight2  number of music unit and secondly because \highlight4 automatic music genre classification\highlight2  generates category independent of manual subjective category. In this digital era, millions of songs are being accessed by consumers. 
\par 
\par Also, with the technological advancement artist and producer \highlight4 are able to\highlight2  release and distribute songs instantly. This democratization of accessing digital media has arisen the requirement to develop efficient categorization systems. Humans have always been primary tool in attributing genre-tags to songs. Using machine to do the job is \highlight4 a more complex\highlight2  task, but is the requirement of present time. 
\par 
\par Since Machine learning excels majorly 2 in handling complex data very well, so, this project addresses learning of various \highlight4 Machine learning algorithm\highlight2  to be used for \highlight4 automatically classifying music\highlight2  files with improved prediction accuracy. Advantages of Music Genre Categorization Automatic classification based on genre will help creating music database \highlight4 in such a way that\highlight2  a general de scrpton lis clcalven by use and softe basehe clif doeshe fe sei allowing user to create playlist of his own selection criteria. 
\par 
\par Apart from its practical implication, \highlight4 music genre classification is\highlight2  interesting \highlight4 field of study\highlight2  as well. Rigorous study of the classification and machine based music processing will certainly enhance our knowledge about the \highlight4 human perception of\highlight2  music. 1.2. System Overview Extracting feature from music file for classification is not that easy. 
\par 
\par Digital music is discretized sampled waveform, although categorization over frequency domain is preferred than the time domain \highlight4 because of the\highlight2  ability of humans \highlight4 to differentiate between\highlight2  frequencies range like, deep bass in hip-hop is Low frequency while talking, singing is mid-range frequency and sharp claps are considered high-pitched frequency. 
\par 
\par The base of the project is Million Songs genre dataset that initially contains songs with 34 summary furesven asgenre, trd, artstitl ness, tempo, time signature, key, mode, duration and 24 difentmbrue f eac\rquote  ts cain one ofes, mainly classic pop and rock, classical, dance and electronica, folk, pop, hip-hop, jazz and blues, punk, metal & lastly soul and reggae. 
\par 
\par After that feature scaling has been applied \highlight4 over the dataset\highlight2  to obtain 30 summareaure namelloudness, tempo, tme sie, key, mode, duron and 24 dierent tie valf h \rquote alwih he genre\rquote f song. he ulantdat aset has been modified 3 into 9 genre collection by removing hip-hop. Before applying the \highlight4 machine learning algorithms\highlight2  over dataset it has been accessed to obtain almost equal \highlight4 number of features\highlight2  for each genre (approx. 
\par 
\par 2000 songs of each genre) type so as \highlight4 to provide a\highlight2  good training condition for Multiclass Classification algorithms. Some of the main classification algorithms applied are Decision Tree classifier, \highlight4 K Nearest Neighbor\highlight2  classifier, Random Forest and Na\'efve Bayes classifier, out of which \highlight4 Random Forest has\highlight2  given the best result of 62% F1-Score. 
\par 
\par The \highlight4 machine learning algorithm\highlight2  has been formulated using scikit learn library and numpy library of python programming. Apart from that, the dataset has been modified into 2 summary feature dataset, one being genre and other the lyrics of that particular song, for lyrical modelling approach \highlight4 to be applied\highlight2  over it. Based on tavaiitof yr oreacsong n he MSD\rquote  aseforonlappr24700 has formed \highlight4 that has been\highlight2  re-featured to a collection of approx. 
\par 
\par 7500 songs in 8 genres. In Lyrical Model t ofbag ofds\rquote mpled f cation. 1.3. Scope and Result of Project Overview This project involves evaluation of the current state of automatic genre based classification of music and enttmetof eld h mprntTwordoesn\rquote tiude audisi analysis process for feature extraction but shows the importance and usage of the feature provided in dataset for prediction process. 
\par 
\par The projected focuses specially on the algorithms applied on the features of song, its training, fitting of data \highlight4 and predicting the\highlight2  genre \highlight4 based on the\highlight2  learned data. 4 Structure The project is represented in an organized way given as: The starting has included the overview of Music genre, \highlight4 the Million Song dataset\highlight2  used and the feature detailing \highlight4 of the available\highlight2  features in the dataset. It has also enlisted the \highlight4 human perception of music\highlight2  and study of genre categorization by human. 
\par 
\par The next Section consists of the Basics \highlight4 of Machine Learning\highlight2  followed by various algorithm \highlight4 of multiclass classification\highlight2  and lyrical model approach \highlight4 that had been\highlight2  used for the categorization purpose. The following section shows dataset \highlight4 and machine learning technique\highlight2  correlation for fitting of data, learning from data \highlight4 and predicting the\highlight2  genre for the provided data. 
\par 
\par After that \highlight4 the next section\highlight2  provides the experimental overview of the project, defining the implication and result for \highlight4 each of the\highlight2  used algorithm, their advantages, drawbacks and comparison with one another to highlight \highlight4 the best model\highlight2  for classification purpose. The next is all the codes written followed by Conclusion and lastly references \highlight4 that has been\highlight2  of great support in the whole project. 
\par 
\par Result MultassclifiAlgort prediction accuracy has resulted in 62% F1-score, \highlight4 an increase of\highlight2  4% from the previous best F1 Score of 58% in [1], with \highlight4 the best model\highlight2  \highlight4 of Multiclass classification\highlight2  approach beist \highlight4 An increase of\highlight2  5% with Lyrical Modelling concept with F1-score of 47%. 5 2. Requirement Specification 2.1. Preprocessing the Data Before working on the dataset the data \highlight4 needs to be\highlight2  processed and formatted in suitable formats and for that we require following steps to be followed \highlight4 before we can\highlight2  work on dataset. 
\par 
\par ? First of all, feature scaling \highlight4 needs to be\highlight2  performed \highlight4 over the dataset\highlight2  \highlight4 so that the\highlight2  features are scaled between values (- 1 t. So, t a sie fure doe domies the prcton process only because it has higher ranges of value as \highlight4 compared to other\highlight2  features. ? All the features are needed to be converted to floating types and not mixed type, because if latter is the case numpy arrays generated by us, are converted to string type and that could \highlight4 lead to unexpected results.\highlight2  
\par 
\par ? In the Bag-of-word scheme, stemming should done before the bagging process as it could reduce \highlight4 the number of\highlight2  bags and could produce more meaningful results. ? Another important preprocessing step that \highlight4 needs to be\highlight2  done is \highlight4 Principal Component Analysis (PCA)\highlight2  for dimension reduction in bag-of-words so that we only consider important words only while classification. 
\par 
\par ? Splitting the dataset \highlight4 into training and testing set\highlight2  is little tricky but is quite well handled by sklearn library in a single line split them in 80:20 percentage respectively that too the elements are taken randomly to form the two sets so that no biasing occurs. 2.2. Python Libraries The few important libraries to be checked before running code on local environment. 
\par 
\par ? Sklearn (scikit-learn) ? Numpy ? Scipy ? Matplotlib ? Beautifulsoup ? Request ? Pickel 6 3. \highlight4 Music Genre Classification\highlight2  A common definition of terms is necessary in every field of science and that too is applicable for Music genrclasfion. , h nitdoesthappetexistiourfiofsteven he literature disagrees on the basic terminologies. 
\par 
\par Two of the main reasons identified for this are: ? Music being a part of daily life, has terms having an intuitive meaning, like for the features of music song such as tempo, rhythm, pitch. ? Human perceive sound \highlight4 depending on its\highlight2  personal, cultural and emotional aspect and so does happens for classification. This lack of simple basic hinders the progress \highlight4 of audio signal classification\highlight2  resulting in degradation in feature extraction on which the whole classification process majorly relies. 
\par 
\par Music \highlight4 genre classification is a\highlight2  subfield of the larger field \highlight4 of audio signal\highlight2  classification, defined as working with the extracted features \highlight4 of audio signal\highlight2  (obtaining \highlight4 relevant features from a sound\highlight2  and based on those identify the set of class the sound is most likely to be classified) to be used by the classification algorithms for genre . Automatic genre categorization refers to achieve this task with machines \highlight4 using machine learning\highlight2  techniques. 3.1. 
\par 
\par Genres and Feature vector Conventional classification approach that identifies music belonging to a particular tradition \highlight4 or set of conventions\highlight2  is Music genre [2]. Now days \highlight4 genre has become\highlight2  the very basic categorization criteria and so the music are categorized into different genres but \highlight4 because of the artistic nature of music\highlight2  these criteria of classification is considered subjective and it might happen that \highlight4 some genres may overlap.\highlight2  
\par 
\par Alhough toj doesn\rquote t on teate exttiechnique but the sts rl for \highlight4 the feature selection\highlight2  to be done from dataset so as to achieve better prediction result. Apart from 7 that \highlight4 based on the\highlight2  features availability the fitting of dataset for training purpose of the classifiers used throughout the project. 3.1.1. Genre History Initially genre analysis \highlight4 has been used\highlight2  for teaching and learning of English for special purpose, but the dition communitand naton er er s genrsttt digital field. Crowsten and William (1998) were some of \highlight4 the first to\highlight2  study genre for digital media. 
\par 
\par They identified \highlight4 the importance of\highlight2  study of genre for analysing \highlight4 digital world of\highlight2  internet because of ease of access [3]. \highlight4 They identified 48\highlight2  various genre after studying random 100 web pages. TerCybe re\rquote  frstned by Shephertts iigiale which was further termed in two categories \highlight4 based on the\highlight2  dependency on the media by many authors. 
\par 
\par ? Extant subgenre: genre of some media that migrated to another computer environment and replicated without exploiting the capabilities of the new media, e.g. newspaper, dictionaries, research articles and biographies. ? Novelgenr:genrestotly ndenton mediand dn\rquote texi n here.g. virtual games and homepages. Genre in Music TLatn d genusmeang s nd\rquote was he in orword e use oday. might be a considered a category \highlight4 that can be defined by\highlight2  structural or functional criteria. 
\par 
\par Sometimes criteria like musical techniques, \highlight4 style, the cultural context\highlight2  or the content \highlight4 of the music\highlight2  also plays important role to define \highlight4 a music genre or\highlight2  subgenre. Geographical origin also sometimes play important 8 crera o siy musigenrlke azz bl, hough sie aphicaty ght include many subgenres. \highlight4 Genre classification is\highlight2  always been a subjective term in respect of both listener and socio-cultural envionmentHence fitiormusigenran sts: \highlight4 A music genre is a\highlight2  specific class of music consisting of set of some common properties that an average listener perceive so as to distinguish musioftclassfothersongs\rquote  A specific genre has unique characteristic feature of rhythmic structure \highlight4 as well as the\highlight2  instrumentation property for that particular kind of music, although there are certain more features used human for manual \highlight4 categorization of music\highlight2  genre. 
\par 
\par The major challenge of automatic \highlight4 genre classification is\highlight2  to find out those factors and extracting those \highlight4 features from the\highlight2  music file. 3.1.2. Feature Extraction This includes the very basic key concept \highlight4 of feature extraction\highlight2  keeping signal processing in its bacound. he oj n\rquote tiementany ecque orfeae ron iorknowl of features of songs that gets extracted from song is needed before going to the implementation part \highlight4 of machine learning classifier\highlight2  algorithm so as to learn the relative feature to be used \highlight4 in the training\highlight2  process. 
\par 
\par The main difficulty of music genre categorization at first is \highlight4 to differentiate between\highlight2  music styles, i.e. to obtain feature vector for various genre song. It is similar to the fact of comparing two object (in our ca musisongs)ft miary dilitwhen hey n\rquote  diectlcompar Although our project directly access \highlight4 the million song dataset\highlight2  that already contains extracted features i.e. 
\par 
\par 34 summary feature \highlight4 that can be\highlight2  directly accessed only after separating the required features from dataset and applying feature scaling. 9 \highlight4 Feature Extraction is\highlight2  a process of transforming \highlight4 the data in order to make\highlight2  it accessible for essential information retrieval by computing a numerical representation for a segment of audio signal. For classification \highlight4 feature extraction is one of the two\highlight2  commonly used pre-processing technique. 
\par 
\par It applies \highlight4 one or more\highlight2  transformation over raw data to generate new features. The other one is feature selection \endash  that identifies a feature subset within the raw data to be used for effective classification which has been implemented within the project. \highlight4 The Feature selection process\highlight2  can be applied over \highlight4 the input dataset\highlight2  or over the output provided by Feature extraction process. 
\par 
\par A classification system might use both or either \highlight4 of the two\highlight2  techniques \highlight4 depending on the\highlight2  accuracy the \highlight4 feature extraction is\highlight2  giving as \highlight4 shown in Fig\highlight2  1. Our project uses only \highlight4 the Feature selection\highlight2  pre-processing as the Million songs dataset initially contains the extracted features of songs in it. \highlight4 The Feature selection\highlight2  pre-processing technique has been elaborated further in the project. Figure 1. 
\par 
\par Schematic overview \highlight4 of feature extraction\highlight2  and feature selection Most tnfmat audignals encoded ire and ttr component\rquote  amplitude. So, the information can be retrieved by examining tsis frequency spectrum that is sil t happen human audiorem. \lquote  Fourier Analysis \rquote s a mati tecque used for the above. Fourier transform, Short-Time Fourier Transform are some of Fourier analysis implementation method. For more detailing, one can consult books on signal processing. 
\par 
\par 10 3.1.3. Common Music Genres From rock to pop, from classical to hip-hop, music ranges in various type and styles. \highlight4 There is a very\highlight2  rich history of music genres that even contain enlightening geographical significance. This section introduces to some of the common genres \highlight4 that has been used\highlight2  for the classification purpose in the project. 
\par 
\par ? Classical pop and rock Classical \highlight4 rock is a radio format\highlight2  that has its origin in 1980s \highlight4 from the album-oriented rock\highlight2  format. It contains minimal voice component and is traditionally built on simple unsyncopated or unmodified rhythms. Pop c popul c\rquote (ms ng d changeay)hasorgifom he western world during 1950s and 60s. Music of this genre is generally featured by a consistent rhythmic element. 
\par 
\par Although rock and pop often have overlaps. Classical music do not contain repetitive and heavily pronounced rhythms and has less bass. ? Dance and electronica Also referred as \highlight4 Electronic Dance Music\highlight2  (EDM) is a kind of club music having \highlight4 broad range of\highlight2  persuasive electronic music. It has some subgenres namely Disco, Techno, House, Ambient, jungle, \highlight4 drum and bass\highlight2  and Electro. It has consistent bass rhythms i.e. all the quarter notes. 
\par 
\par ? Folk It is combination of \highlight4 both traditional music and the\highlight2  folk revival of 20th century \highlight4 that evolved from\highlight2  the traditional music itself. It is mainly geographically originated genre and is often related to a on\rquote s te. fk c shor ument e ed a ody repetitive word section. 11 ? Hip-hop Hip-ho p musiso terr hasin in ted Stathis genrist stylized rhythmic music i.e. a rhythmic and rhyming speech usually accompanies rapping. 
\par 
\par It is generally associated with \highlight4 deep, rhythmically repetitive\highlight2  bass. ? Jazz and blues Jazz and blues music was originated from \highlight4 African American communities during\highlight2  \highlight4 late 19th and early 20th century.\highlight2  This genre can refer either to blues containing advanced harmonies and rhythms or to jazz having rhythms real simple. 
\par 
\par This categorization genre have soft volume and excludes repetitive rhythms. ? Metal Metal or mostly called heavy metal \highlight4 is a genre of\highlight2  rock music have origin in UK and USA in betnd 70s. Loud diortts is mete\rquote raditi charerst. Its \highlight4 often characterized by\highlight2  emphatic music dense bass & drum sounds along with energized vocals. 
\par 
\par ? Punk \highlight4 This is a\highlight2  loud, fast and kind of distorted genre category that has its origin in US during 1970s. It hard edged melodies and stripped down instrumentation. ? Soul and reggae Reggae music genre has its origin during 1960s in Jamaica. \highlight4 The bass sound\highlight2  is often \highlight4 thick and heavy\highlight2  in this genre. \highlight4 The bass sound\highlight2  is equalized too \highlight4 so that the upper frequencies are removed and\highlight2  emphasized lower frequency is obtained. 12 3.2. 
\par 
\par Schematic Model As stated previously, Music genre categorization is all about classification of songs into some predefined categories. The goal is therefore to design algorithms that classifies the input digital music file into specific genre given the features \highlight4 of the song\highlight2  is provided with the song initially. Figure 2. 
\par 
\par Schematic Overview of \highlight4 music genre Classification\highlight2  The oval shape is \highlight4 the Million Song dataset\highlight2  that already contains the extracted featured \highlight4 of the songs\highlight2  and so \highlight4 the process of\highlight2  extraction over audio file \highlight4 is not required. However,\highlight2  the process has been \highlight4 discussed in the\highlight2  section 2.1.2. \highlight4 The only requirement\highlight2  to achieve goal is to do apply pre-processing technique feature selection (Section 2.1.2.) 
\par 
\par and then applying the classifier over the selected feature to do the final classification of songs into genres. The classification has been well deduced in Section 3. Figure 2. Shows \highlight4 the most simple\highlight2  representation of the classification been done. 3.3. Difficulty \highlight4 Music genre classification is a tough task to\highlight2  perform with machine being the classifying tool. 
\par 
\par This is mostly because of some of following reasons: First of all, \highlight4 it is a\highlight2  fact that music is a perceptual phenomenon. Although human ear receives the sound well but how it \highlight4 is actually perceived\highlight2  by us is still a major topic of discussion and has no clear 13 results. The knowledge we have about \highlight4 perception is not sufficient\highlight2  enough to build a system that perfectly simulates like human for music perception. 
\par 
\par Secondly, the \highlight4 human perception of\highlight2  a song genre is not always correct and hence the music genre clicaon human n\rquote talrultcorr. i s fitttrn systf classification purpose in presence of such ambiguity. So, to model a classification system, \highlight4 it might be\highlight2  a need to check if the system too does the mistakes in classifying particular genre of song \highlight4 that can be\highlight2  classified \highlight4 into more than one\highlight2  genre, similarly like the humans do. 3.4. 
\par 
\par The Dataset and Features For this project \highlight4 the Million Song\highlight2  Genre Dataset has been used, that is been made available by LabROSA at Columbia university [4], for educational study purpose. This dataset consists of about million songs of various genres, to be precise of 10 genres, namely classic pop and rock, classical, dance and electronica, folk, pop, hip-hop, jazz and blues, punk, metal & lastly soul and reggae. The distribution of songs into various genres can be recognized in Figure 3. Figure 3. 
\par 
\par Dataset Composition 14 This \highlight4 dataset is a\highlight2  well-organized classification dataset as it consist the features of \highlight4 each of the song\highlight2  in the dataset too. \highlight4 The Million Song Dataset\highlight2  has about million songs with related metadata and audio analysis features, in total 34 summary features give n asgenre, trk iti name, tle, ls, ti siurkey, durion 24 ferentte ue orease\rquote TFeat representation and value of each feature for some \highlight4 of the songs\highlight2  can be viewed in the Figure 4. 
\par 
\par In this dataset, we have each song as a training example containing 34 summary features along with the genre of the track, which would be of use during \highlight4 training as well as\highlight2  testing the classifiers for predicting the genre of particular combination of features. Figure 4. Small part of Million Songs Genre Dataset 15 3.4.1. Terminologies The dataset contains various features that needs little description. genre: is the music category of the particular track in the dataset. 
\par 
\par track_id: is the musicmatch track id of the track artist_name: is the song\rquote  artist name title: title \highlight4 of the song\highlight2  loudness: is the property \highlight4 of a sound\highlight2  that is primarily a psychological correlation of physical strength (amplitude). tempo: The \highlight4 tempo is the speed\highlight2  of the underlying beat for a piece of music. \highlight4 Tempo is measured in BPM, or\highlight2  Beats/Minute. 
\par 
\par The \highlight4 top number represents how many beats there are in a measure, and the bottom number represents the note value which\highlight2  makes one beat. key: \highlight4 The key of a piece is a group of pitches, or scale upon which a music composition is\highlight2  created. mode: \highlight4 Refers to a type of scale, coupled with a set of characteristic melodic\highlight2  behaviors. duration: song duration (in Secs). 
\par 
\par avg_timber1 - 12: Timbre \highlight4 is then a general term for the distinguishable characteristics of a tone.\highlight2  var_timber1 \endash  12: \highlight4 Timbre is mainly determined by the harmonic content of a sound\highlight2  and the dynamic characteristics. 16 3.4.2. \highlight4 Feature Selection and\highlight2  implementation For Multiclass Classification T he given dataset composition of songs is unbalanced as shown in Figure 3, that classifies genres with 40% prctiator \lquote ass r, since this genre is 40.09% of the whole dataset, which is quite a large composition, that enables the machine ttaibeterover assi ock pop\rquote and ve good testing result. 
\par 
\par So, we redistributed the dataset \highlight4 to obtain a\highlight2  balanced composition of songs given in Figure 5. Figure 5 . BacedDaset mpsitio Apar tom t, the furlon pr has beeeed, ttmporanttur of tgi34 y eae n dat rng o h racand ratigenrfm teateshe precty f ates namel \lquote  loudness, tempo, time signature, key, mode, duration and 24 different timbre value for each segment \rquote  appen a sie vec tmed fure vecorong wih genror eaacn tanced datt . 
\par 
\par Code Implementation 1. \highlight4 import numpy as np\highlight2  2. import math 3. import sys 4. import matplotlib 5. \highlight4 from sklearn.multiclass import OneVsRestClassifier\highlight2  6. \highlight4 from sklearn.svm import\highlight2  LinearSVC 7. \highlight4 from sklearn.cross_validation import train_test_split\highlight2  17 8. import time 9. \highlight4 from sklearn import\highlight2  tree 10. \highlight4 from sklearn.metrics import accuracy_score\highlight2  11. \highlight4 from sklearn.grid_search import GridSearchCV\highlight2  12. \highlight4 from sklearn.metrics import confusion_matrix\highlight2  13. \highlight4 from sklearn.ensemble import RandomForestClassifier\highlight2  14. \highlight4 from sklearn.neighbors import KNeighborsClassifier\highlight2  15. \highlight4 from sklearn.naive_bayes import\highlight2  GaussianNB 16. \highlight4 from sklearn.ensemble import\highlight2  AdaBoostClassifier 17. \highlight4 from sklearn.metrics import classification_report\highlight2  18. from sklearn.preprocessing import MinMaxScaler 19. from sklearn.decomposition import RandomizedPCA 20. #sys.stdout = open('output.txt', 'w') 21. 22. def HPOptimizationGridSearch(feature_train,label_train): 23. 
\par 
\par print \highlight4 "Fitting the classifier to the training set"\highlight2  24. t0 = time.time() 25. param_grid = \{ 26. 'min_samples_split': range(1,41), 27. 'min_samples_leaf': range(1,20), 28. 'n_estimators': range(1,500) 29. \} 30. clf = GridSearchCV(OneVsRestClassifier(RandomForestClassifier()), param_grid) 31. clf = clf.fit(feature_train,label_train) 32. print "done in %0.3fs" % (time.time() - t0) 33. print "Best estimator found by grid search:" 34. print clf.best_estimator_ 35. 36. def processItem(datapoint): 37. 38. info=[datapoint[0]] 18 39. for feature in datapoint[4:]: 40. info.append(float(feature)) 41. return info 42. 43. 
\par 
\par def targetFeatureSplit( data ): 44. """ 45. \highlight4 given a numpy array like the one returned from\highlight2  46. \highlight4 featureFormat, separate out the first\highlight2  feature 47. \highlight4 and put it into its own\highlight2  list (this should be the 48. quantity you want to predict) 49. 50. return targets and features as separate lists 51. 52. (sklearn can generally handle both lists and \highlight4 numpy arrays as\highlight2  53. input formats when training/predicting) 54. """ 55. target = [] 56. features = [] 57. 
\par 
\par for item in data: 58. target.append( item[0] ) 59. features.append( item[1:] ) 60. 61. return target, features 62. 63. genres=\{\} 64. data_list=[] 65. def done(): 66. line_num=0 #line number in text file 67. with open('msd_genre_dataset.txt','r') as f: 68. \highlight4 for line in\highlight2  f: 69. if line_num<10: 19 70. pass 71. else: 72. temp=line.split(',') 73. try: 74. if(genres[temp[0]] and genres[temp[0]]<2000): 75. if(temp[0]=="hip-hop"): 76. temp[0]='pop' 77. genres[temp[0]]+=1 78. 
\par 
\par data_list.append(processItem(temp)) 79. except: 80. genres[temp[0]]=1 81. line_num+=1 82. print "**************************************************************************" 83. print "No of songs: ",line_num-10 84. print "**************************************************************************" 85. 86. print "Dataset composition:" 87. for type in genres.keys(): 88. 
\par 
\par #print "\\""+ type+"\\",", 89. print type,genres[type] 90. print "**************************************************************************" 91. print "Loading data in numpy arrays." 92. t=time.time() 93. np_data=np.array(data_list) 94. print "Time elapsed:",time.time()-t,"secs." 95. t=time.time() 96. scaler=MinMaxScaler() 97. np_data[:,1:]=scaler.fit_transform(np_data[:,1:]) 98. print "Splitting data into target and features" 99. 
\par 
\par labels,features=targetFeatureSplit(np_data) 100. print "Time elapsed:",time.time()-t,"secs." 20 101. 102. print "Creating training set and Test set" 103. t=time.time() 104. feature_train,feature_test,label_train,label_test = train_test_split(features, labels, test_size=0.20, random_state=42) 105. print "Time elapsed:",time.time()-t,"secs." 106. print"Fitting \highlight4 and predicting the\highlight2  data" 107. t=time.time() 108. 109. #HPOptimizationGridSearch(feature_train,label_train) 110. 111. 
\par 
\par clf=OneVsRestClassifier(RandomForestClassifier(min_samples_split=2,min_samples_leaf=1,n_estimators=300)) 112. clf.fit(feature_train,label_train) 113. pred=clf.predict(feature_test) 114. print "Time elapsed:",time.time()-t,"secs." 115. print "accuracy_score=",accuracy_score(label_test,pred) 116. t=time.time() 117. print "confusion_matrix:" 118. print(classification_report(label_test,pred)) 119. print "classification_report:" 120. print classification_report(label_test,pred) 121. 122. 
\par 
\par done() For Lyrical Analysis Thniks on tyrcs ofracd on tabiy of songs [5] , datt for appr 24600 wasltch a baased on lcsabiy f each genre aw datet composiion washihe balned datas lyrcsorh trk i fure alt tgenrso applbag ds ecque. he ase viaf eatibag ds s \highlight4 shown in Fi\highlight2  21 Figure 6 .PioLl ta Code for Obtaining Lyrics for the tracks in the dataset 1. import requests 2. \highlight4 from bs4 import\highlight2  BeautifulSoup, Comment, NavigableString 3. 
\par 
\par import sys, codecs, json 4. 5. 6. def getLyrics(singer, song): 7. #Replace spaces with _ 8. singer = singer.replace(' ', '_') 9. song = song.replace(' ', '_') 10. r = requests.get('http://lyrics.wikia.com/\{0\}:\{1\}'.format(singer,song)) 11. s = BeautifulSoup(r.text,'lxml') 12. #Get main lyrics holder 13. lyrics = s.find("div",\{'class':'lyricbox'\}) 22 14. if lyrics is None: 15. #raise ValueError("Song or Singer does not exist or the API does not have Lyrics") 16. return None 17. #Remove Scripts 18. [s.extract() for s in lyrics('script')] 19. 20. #Remove Comments 21. comments = lyrics.findAll(text=lambda text:isinstance(text, Comment)) 22. [comment.extract() for comment in comments] 23. 24. #Remove unecessary tags 25. for tag in ['div','i','b','a']: 26. for match in lyrics.findAll(tag): 27. match.replaceWithChildren() 28. #Get output as a string and remove non unicode characters and replace <br> with newlines 29. lyrics= str(lyrics).replace('\\n','').replace('<br/>',' ') 30. 
\par 
\par output=lyrics[22:-6:] 31. try: 32. return output 33. except: 34. return output.encode('utf-8') 35. 36. genres=\{\} 37. lyrics_found=0 38. import codecs 39. y=codecs.open("songLyrics1.txt","w") 40. line_num=0 41. with codecs.open('msd_genre_dataset.txt','r') as f: 42. \highlight4 for line in\highlight2  f: 43. if line_num<=27432: 44. pass 23 45. else: 46. temp=line.split(',') 47. #print "artist name=",temp[2],"Title=",temp[3] 48. lyrics=getLyrics(temp[2],temp[3]) 49. if(lyrics!=None): 50. if(lyrics.split(' ')[0]!='<span'): 51. try: 52. 
\par 
\par genres[temp[0]]+=1 53. except: 54. genres[temp[0]]=1 55. lyrics_found+=1 56. y.write(temp[0]+'**/**'+lyrics) 57. y.write('\\n') 58. if(line_num%100==0): 59. print "At present progress\\n" 60. print "Songs processed: "+ str(line_num) 61. print "Lyrics saved upto now:" +str(lyrics_found) 62. for gen in genres.keys(): 63. print gen,":",genres[gen] 64. line_num+=1 65. y.close() Code for obtaining \highlight4 bag of words\highlight2  from Pickel Data 1. from __future__ import division 2. from nltk.corpus import stopwords 3. from nltk.stem import SnowballStemmer 4. import unicodedata 5. import codecs 6. import string 7. import pickle 24 8. 
\par 
\par stemmer = SnowballStemmer('english') 9. cachedStopWords = stopwords.words("english") 10. data=[] 11. with codecs.open('finalLyricsList2.txt','r') as f: 12. lines=f.readlines() 13. count=0 14. \highlight4 for line in\highlight2  lines: 15. 16. labels,features=line.split('**/**') 17. features = unicode(features, "utf-8") 18. features = unicodedata.normalize('NFKD',features).encode('ascii','ignore') 19. features=features.translate(None, string.punctuation) 20. features=features.lower() 21. features=[word for word in features.split() if word not in cachedStopWords] 22. for word in features: 23. stemmer.stem(word) 24. features=" ".join(features) 25. data.append([labels,features]) 26. 
\par 
\par count+=1 27. if(count%500==0): 28. print "completed:",count/len(lines)*100 29. 30. genres=\{\} 31. \highlight4 for line in\highlight2  lines: 32. labels,features=line.split('**/**') 33. try: 34. genres[labels]+=1 35. except: 36. genres[labels]=0 37. print "File composition" 38. for g in genres.keys(): 25 39. print g+": ",genres[g] 40. 41. #saving into serialized object 42. stem_data=open("stemmed_text",'wb') 43. pickle.dump(data,stem_data) 44. stem_data.close() 45. 46. 47. 48. \highlight4 from sklearn.feature_extraction.text import\highlight2  CountVectorizer 49. vectorizer=CountVectorizer() 50. email=[] 51. bow=vectorizer.fit(email) 52. bow=vectorizer.transform(email) 53. vectorizer.vocabulary_.get("great") 26 \highlight4 4. Machine Learning\highlight2  4.1. 
\par 
\par Role \highlight4 of Machine Learning\highlight2  \highlight4 Machine learning is\highlight2  a subpart \highlight4 of computer science\highlight2  and engineering that developed and emerged from \highlight4 the study of\highlight2  pattern recognition and computational learning theory of programmable machines in AI (Artificial Intelligence). In late 20th century, Arthur Samuel coined the term \highlight4 of machine learning as a "Field of study that gives computers the ability to learn without being explicitly programmed".\highlight2  
\par 
\par Machine learning techniques identifies and researches the study and development of principles and theorem that can learn from and make prognostication on data. Such procedures work by building a standard from example inputs \highlight4 in order to make\highlight2  data-driven prognostication or decisions expressed as outputs, \highlight4 more or less\highlight2  than following factually stagnant program instructions. 
\par 
\par Machine learning is meticulously related to and usually overhang with computational statistics; a branch of statistics which also focuses in foreseeing through \highlight4 the use of\highlight2  computers. \highlight4 It has strong\highlight2  connection to mathematical optimization, which delivers mechanism, concept and operation domains to the field. Machine learning procedures are deployed \highlight4 in a variety of\highlight2  calculation tasks and problems where designing, developing and programming explicit procedures is not possible. 
\par 
\par Some of the major applications \highlight4 of machine learning algorithms\highlight2  includes computer vision (object identification), spam filtering (text classification), optical character recognition (OCR), search engines (search Engine Optimization) and lots of other applications in near future. \highlight4 Machine learning is\highlight2  often amalgamated with data mining, where the latter is a branch targets more on preparatory data analysis and is known as unsupervised learning. 
\par 
\par Within \highlight4 the field of\highlight2  data analytics, \highlight4 machine learning is\highlight2  \highlight4 a way that\highlight2  is used to develop complicated standards and procedure that lend themselves to foretelling the output. These analytical standards 27 allows different communities of researchers, data \highlight4 scientists, engineers, and\highlight2  analysts to "produce dependable, recurring decisions and outputs" and uncover "hidden details " through learning from chronicled relationships and trends in the data. 
\par 
\par A e tmiogy ormacne earby om Mitl statas For some performance value P and T being the value for some class of task, any machine is said to learn from experience E, if for varying experience value E, \highlight4 its performance at\highlight2  task T improves with E for measmentparameterP\rdblquote  . This statement is quite important for explaining \highlight4 machine learning in\highlight2  fundamentally operational ra t than cognive tms, thi fowed by Aluris i hipaper\ldblquote Computng nerand elgenct he gument\ldblquote Can hitnk?\rdblquote be exche agumenthi we c In this project report we will be majorly discussing three classification algorithms for categorizing various songs according to genre and then \highlight4 in the latter half of the\highlight2  report we will be using and implementing Lyrical analysis for classification using \highlight4 bag of words\highlight2  strategy. 
\par 
\par 4.2. Classification Algorithm 4.2.1. \highlight4 Na\'efve Bayes Classifier Na\'efve Bayes classifier\highlight2  \highlight4 is one of the\highlight2  common classifiers \highlight4 in machine learning\highlight2  that \highlight4 is based on\highlight2  Bayes theorem under the strong assumption that the features involved in the classification process are totally independent t o each ot\rquote urence Naive Bayes has been under thorough study since the middle of 20th century. 
\par 
\par It was introduced under a distinct name into the text retrieval community \highlight4 in the latter half of\highlight2  1950s, and stay a popular (basic standard) procedure for text classification, the problem of deciding documents as belonging to \highlight4 one category or the other\highlight2  (such as spam or important, sports ,fashion, politics, etc.) with word count as the features. With suitable pre-processing, it is emulous in this territory with more advanced procedures 28 including SVMs (Support Vector Machines). 
\par 
\par The \highlight4 Na\'efve Bayes classifier\highlight2  also finds application in automatic medical diagnosis that is being used widely at various popular research Institutes. Following are some important points in favour of working with Na\'efve Bayes classifier: ? \highlight4 Naive Bayes classifiers\highlight2  are easy to implement. ? They are scalable to large extend, needing \highlight4 a number of\highlight2  parameters linear \highlight4 in the number of\highlight2  variables (features/predictors) in \highlight4 a learning problem\highlight2  and there by solving problems rather very fast as \highlight4 compared to other\highlight2  algorithms. 
\par 
\par ? Maximum-likelihood training with Na\'efve Bayes Algorithm \highlight4 can be done by\highlight2  calculating \highlight4 a closed-form expression\highlight2  (which is a mathematical expression \highlight4 that can be\highlight2  evaluated in \highlight4 a finite number of\highlight2  operations) that takes asymptotically linear time, instead of computationally expensive monotonous nearness as used for many other types of classifiers. Naive Bayes procedures are known by many names, including simple Bayes and independence Bayes in various \highlight4 statistics and computer\highlight2  science literature. 
\par 
\par All these names give hint the regarding \highlight4 the use of\highlight2  Bayes' theorem in the classifier's decision rule, but naive Bayes is not typically a Bayesian method. \highlight4 Using the naive independence assumption that For all , this\highlight2  relationship is simplified to 29 Since is constant given the input, we can use the following classification rule: And we can use Maximum A Posteriori (MAP) estimation to estimate and ; the former is then \highlight4 the relative frequency of class\highlight2  \highlight4 in the training\highlight2  set. 
\par 
\par The \highlight4 different types of Naive Bayes classifiers\highlight2  differ mainly by the assumptions they make regarding the distribution of conditional probabilities hence, there accuracy can differ drastically \highlight4 depending on the nature of\highlight2  problem at hand. Now, \highlight4 we have the\highlight2  simple implementation of \highlight4 Na\'efve Bayes Classifier\highlight2  in sklearn In the above code, Line Number 1. Import the dataset module from sklearn library. 2. 
\par 
\par Loads \highlight4 the iris dataset\highlight2  from the module and saves \highlight4 the data in\highlight2  numpy array iris. 3. Imports the Gaussian \highlight4 Na\'efve Bayes classifier\highlight2  from sklearn.naive_bayes. 30 4. Defines the NBclassifier. 5. Fit the data and makes prediction over it , saves the result into variable y_pred 6. Prints \highlight4 the Number of\highlight2  mislabeled points out of total points. 
\par 
\par Hyper parameter tuning in \highlight4 Na\'efve Bayes Classifier\highlight2  Now as \highlight4 we can see\highlight2  from the line number 4, there are no hyper parameters to be tuned to increase acacof he edion hencwe o y oss daton ke ichCV to find tuning parameters for the above algorithm. And for the same reason the algorithm generally has significantly lesser accuracy but is very easy to implement and is fast to run over a large Dataset like \highlight4 Million Song Dataset.\highlight2  Actual Code Implementation 1. # importing necessary libraries 2. \highlight4 import numpy as np\highlight2  3. import math 4. \highlight4 from sklearn.cross_validation import train_test_split\highlight2  5. \highlight4 from sklearn.metrics import accuracy_score\highlight2  6. \highlight4 from sklearn.grid_search import GridSearchCV\highlight2  7. \highlight4 from sklearn.metrics import confusion_matrix\highlight2  8. \highlight4 from sklearn.naive_bayes import\highlight2  GaussianNB 9. \highlight4 import pickle as pkl\highlight2  10. \highlight4 import matplotlib.pyplot as plt\highlight2  11. 
\par 
\par #Loading labels and \highlight4 features from the\highlight2  pickle file 12. f=open('features','r') 13. labels=pkl.load(f) 14. features=pkl.load(f) 15. f.close() 31 16. print type(labels),type(features) 17. #spliting \highlight4 data into training and testing\highlight2  data 18. print "splitting \highlight4 the data into training and testing\highlight2  set" 19. feature_train,feature_test,label_train,label_test = train_test_split(features, labels, test_size=0.20, random_state=42) 20. print "Defining the classifier" 21. 
\par 
\par ############################################# 22. #Gaussian naive_bayes 23. ############################################# 24. \highlight4 from sklearn.naive_bayes import\highlight2  GaussianNB 25. clf = OneVsRestClassifier(GaussianNB()) 26. x=[] 27. y=[] 28. print len(feature_train) 29. print len(label_train) 30. for a in range(1,50): 31. pred = clf.fit(feature_train[:len(feature_train)/a],label_train[:len(feature_train)/a]).predict(feature_test) 32. x.append(len(feature_train)/a) 33. y.append(accuracy_score(label_test,pred)) 34. plt.plot(x,y) 35. plt.title('Gaussian Naive Bayes classifier') 36. plt.xlabel('No. of Training Samples') 37. plt.ylabel('Accuracy Score') 38. plt.show() Executing the Algorithm After running the algorithm over different sizes of \highlight4 training and testing data set\highlight2  we found out following trends which are plotted in the graph below with help of matplotlib. 32 Figure 7. 
\par 
\par Gaussian \highlight4 Naive Bayes Classifier\highlight2  Observation It is clear from the graph that after certain size \highlight4 of training data\highlight2  the algorithm breaks means the F1-score (accuracy) gradually decreases with increase in training size. Generally it is the case that the accuracy increases with \highlight4 the increase in\highlight2  the size of training set, but this case clearly \highlight4 suffers from the\highlight2  drawback of \highlight4 the Na\'efve Bayes\highlight2  classifier, that is the features \highlight4 in the training data\highlight2  have high co-relation that is causing the algorithm to break. 
\par 
\par Further Analysis We can further analyse the results we got from the graph above. We generated the confusion matrix that is obtained. 33 Genre name precision recall F1-score support classical pop and rock 0.26 0.25 0.26 389 classical 0.59 0.78 0.67 355 dance and electronica 0.39 0.35 0.37 427 folk 0.44 0.28 0.34 426 jazz and blues 0.51 0.27 0.36 386 metal 0.46 0.84 0.60 404 pop 0.29 0.45 0.36 395 punk 0.25 0.09 0.13 414 soul and reggae 0.42 0.43 0.43 381 Results: The highest obtained F1-score for \highlight4 the Na\'efve Bayes Classifier\highlight2  is 0.43 or 43% at most at 750 training samples. 
\par 
\par Then, it \highlight4 starts to decrease\highlight2  with increase with the increase of the size of training set .In other words the algorithm broke after that point. 4.2.2. \highlight4 Decision Tree Classifier\highlight2  Decision Tree classifier, sometimes called as regression trees, capitalizes \highlight4 a decision tree\highlight2  as a predictive standard which drawing out observations about a feature to find about the item's labelled value. 
\par 
\par Decision tree Classifier (Tree based method) \highlight4 is one of the predictive modelling\highlight2  techniques used in tree models where the label variable can take \highlight4 a finite set\highlight2  of values and are known as classification trees. In Decision trees, what we really care about is maximizing the information gain, when we split into branches according to certain features. 
\par 
\par 34 Few things \highlight4 to keep in mind\highlight2  while using this algorithm is concept of entropy or purity of a branch. \highlight4 As we already discussed\highlight2  about maximizing information gain, so while building the tree we look for the features that can do the same, i.e. maximize our information gain. Now, \highlight4 we can see\highlight2  simple implementation \highlight4 of Decision Tree Classifier\highlight2  in sklearn In the above code, Line Number 1. 
\par 
\par Import the dataset module from sklearn library. 2. Imports cross validation score module from sklearn.cross_validation. 3. Imports \highlight4 the Decision Tree classifier\highlight2  from sklearn.tree. 4. Defines the DecisionTreeClassifier with random state=0, which is a seed for random number generator. 5. \highlight4 Loads the iris\highlight2  dataset. 35 6. 
\par 
\par Using \highlight4 training and test\highlight2  data set \highlight4 divided into 10 equal\highlight2  folds cross validation score is being calculated and can be seen \highlight4 in the next\highlight2  line. Optimizing and tuning parameters \highlight4 of decision Tree First\highlight2  of all, we define a dictionary (pair of key and its value) of features and their possible values and this passed as an argument to the K-fold cross validation scheme, itself computes the result for all possible combination of values of features within their respective given ranges of value in constraints specified. 
\par 
\par Exhaustive search using K-fold cross validation and GridSearchCV, what it does is split the original dataset \highlight4 into k equal\highlight2  and separate folds and then randomly selects one fold and splits than \highlight4 into training and test\highlight2  data than generate cross validation score that is \highlight4 the accuracy of\highlight2  prediction in that fold the same process is repeated over k-1 times and all the cross validated score are taken and we take their mean. 
\par 
\par This process is repeated over the all the \highlight4 ordered pairs of\highlight2  parameters and best values are reported back by the cross validation procedure. But as \highlight4 we can see that this is\highlight2  very tedious task both computationally and memory wise, so to overcome this problem we used RandomSearchCV. RandomSearchCV reduces the complexity by avoid exhaustive search and focusing certain chosen values within the parameter grid. Actual code Implementation 1. 
\par 
\par # importing neccessary libraries 2. \highlight4 import numpy as np\highlight2  3. import math 4. \highlight4 from sklearn.cross_validation import train_test_split\highlight2  5. \highlight4 from sklearn import\highlight2  tree 36 6. \highlight4 from sklearn.metrics import classification_report\highlight2  7. \highlight4 import pickle as pkl\highlight2  8. \highlight4 import matplotlib.pyplot as plt\highlight2  9. 10. #Loading labels and \highlight4 features from the\highlight2  pickle file 11. f=open('features','r') 12. labels=pkl.load(f) 13. features=pkl.load(f) 14. f.close() 15. 
\par 
\par print type(labels),type(features) 16. 17. #spliting \highlight4 data into training and testing\highlight2  data 18. print "spliting \highlight4 the data into training and testing\highlight2  set" 19. 20. feature_train,feature_test,label_train,label_test = train_test_split(features, labels, test_size=0.20, random_state=42) 21. 22. print "Defining the classifier" 23. ############################################### 24. #Decision Tree 25. ############################################### 26. 27. x=[] 28. y=[] 29. 
\par 
\par for min_split in range(1,400,5): 30. clf = tree.DecisionTreeClassifier(min_samples_split=min_split) 31. clf.fit(feature_train,label_train) 32. pred=clf.predict(feature_test) 33. accuracy=accuracy_score(label_test,pred) 34. x.append(min_split) 35. y.append(accuracy) 36. plt.plot(x,y) 37 37. plt.title('Min_Samples_Split Parameter Optimization') 38. plt.xlabel('Value of min_samples_split for DecisionTreeClassifier ') 39. plt.ylabel('Cross Validated Accuracy') 40. plt.show() Alternate method of applying Decision Tree Algorithm 1. \highlight4 clf = tree.DecisionTreeClassifier()\highlight2  2. k_range=range(1,5) 3. param_grid=dict(min_samples_split=k_range) 4. 
\par 
\par grid=GridSearchCV(clf,param_grid,cv=10,scoring='accuracy') 5. grid.fit(features,labels) 6. print grid.grid_scores_ 7. 8. grid_mean_scores=[result.mean_validation_score \highlight4 for result in\highlight2  grid.grid_scores_] 9. print grid_mean_scores 10. plt.plot(k_range,grid_mean_scores) 11. plt.title('Min_Samples_Split Optimization') 12. plt.xlabel('value of k for KNN') 13. plt.ylabel('cross validated accuracy') 14. plt.show() 15. print grid.best_score_ 16. print grid.best_params_ 17. print grid.best_estimator_ Executing the Algorithm So, \highlight4 for our purposes\highlight2  we tuned minimum sample split parameter \highlight4 of decision tree\highlight2  and obtained the following result and is shown below using graph generated by python library matplotlib. The Algorithm 38 took significant time to execute \highlight4 over the dataset\highlight2  as the size of the dataset grew. 
\par 
\par As \highlight4 you can see in\highlight2  code rather than using GridSearchCV we have simply looped over the values for minimum sample split parameter by simple human intuition that its value can vary between 2 to 500. Minimum sample split Values above this range have underperformed drastically there for we took such constraint. Figure 8. \highlight4 Decision Tree Classifier\highlight2  As, it is clear from the graph the maximum accuracy obtained for classifying the genre was 0.465. 
\par 
\par It should be note that here we not actually talking about accuracy specifically but describing it \highlight4 in terms of\highlight2  F1-score. As \highlight4 in the case of multiclass classification\highlight2  \highlight4 it can be\highlight2  the case that the dataset be unbalanced, means to say that there can be very few songs of certain genre and \highlight4 a lot of\highlight2  songs of any other category this gives an unseen advantage to these classes with higher numbers and the algorithms favours those classes and works better predicting these classes. 
\par 
\par This problem of biasing classes can be solved by two ways either changing class weights according to class frequency in the dataset or by taking only equal number of samples from all the available classes. 39 For our case we took the liberty of using the second scenario as it would reduce both computational time as we were running the code over our local system with strict system constraints \highlight4 as well as the\highlight2  algorithms performed better on balanced dataset. 
\par 
\par Observation It is clear from the graph that accuracy score (F1-score) initially with the increase of minimum_sample_split parameter value up to 100, then after it \highlight4 starts to degrade the accuracy\highlight2  score of the algorithm .Optimal value obtained somewhere near minimum_sample_split =105. Further Analysis For Detailed recall and precision score of various genre categories \highlight4 we can see\highlight2  the \highlight4 confusion matrix for\highlight2  the above algorithm at the optimal value of minimum_sample_split. Genre name precision recall F1-score support classical pop and rock 0.28 0.26 0.27 389 0.68 0.72 0.70 355 0.47 0.41 0.44 427 0.40 0.43 0.41 426 0.39 0.37 0.38 386 0.72 0.73 0.73 0.33 0.39 395 0.55 0.48 0.51 0.37 0.40 0.38 avg /ot 0.47 0.46 0.46 3577 A ccuracy: 0.464355605256 40 Results The highest obtained F1-score for \highlight4 the Decision Tree Classifier\highlight2  is 0.465 or 46% after tuning hyper parameters. 
\par 
\par Then, it \highlight4 starts to decrease\highlight2  with increase with value of min_sample_split. 4.2.3. K-nearest Neighbors Classifier \highlight4 It is one of the\highlight2  coolest algorithm for \highlight4 classification and regression problems\highlight2  in the sense that it can accommodate to variety of problems of either type as \highlight4 compared to any other\highlight2  algorithm. 
\par 
\par Here, \highlight4 the value of k\highlight2  indicates \highlight4 the number of\highlight2  nearest k neighbors to consider to classify the given data point in a category. To every perfect thing there is always something bad in background same is the case with KNN algorithm though it is versatile in application but it is computationally very expensive. In this classification the outcome is class label. An object is decided to categorize to a category by a majority vote of neighboring data points. 
\par 
\par If \highlight4 the value of\highlight2  K=1, then the given data point is categorized to single nearest neighbor. \highlight4 This is a type of instance\highlight2  based learning algorithm a.k.a. lazy learning where the prediction is calculated according to local distribution of data points and till then the pre - processing and calculation is delayed until it classifies them. 
\par 
\par Both for \highlight4 classification and regression problem\highlight2  the algorithm \highlight4 can be useful\highlight2  for assigning weights to \highlight4 the neighbors, so\highlight2  \highlight4 the nearer neighbors contribute more to\highlight2  the expectation than the distant ones. The \highlight4 one of the major drawback\highlight2  that the algorithm sensitive to local \highlight4 structure of the\highlight2  data. 41 Figure 9 .K rest N eigoxale Now, here example of K-NN implementation of \highlight4 K-nearest Neighbor Algorithm\highlight2  in Sklearn In the above code, Line Number 1. 
\par 
\par Defines X as features numpy array. 2. Defines \highlight4 Y as a numpy array of\highlight2  labels. 3. Imports the KNeighborsClassifier from sklearn.neighbors. 42 4. Defines classifier neigh with nearest neighbor parameter set to 3. 5. Fits the classifier over the data. 6. Prints the prediction value of neighbor with X value 1.1. 7. Prints the probability estimates for test data 0.9. 
\par 
\par Optimizing or tuning the parameter of \highlight4 K-Nearest Neighbor Classifier\highlight2  The parameter under consideration of tuning this time is n_neighbors again we can apply exhaustive GridSearchCV or simple iterative approach over the values of n_neighbors can do the job for us. But since \highlight4 the K-nearest Neighbor\highlight2  is computationally expensive we would prefer to have RandomizedSearchCV for tuning this parameter. Actual Code Implementation 1. 
\par 
\par from \highlight4 sklearn.cross_validation import train_test_split\highlight2  2. import time 3. \highlight4 from sklearn.grid_search import GridSearchCV\highlight2  4. \highlight4 from sklearn.neighbors import KNeighborsClassifier\highlight2  5. \highlight4 import pickle as pkl\highlight2  6. \highlight4 import matplotlib.pyplot as plt\highlight2  7. 8. 9. #Loading labels and \highlight4 features from the\highlight2  pickle file 10. f=open('features','r') 11. labels=pkl.load(f) 12. features=pkl.load(f) 13. f.close() 14. print type(labels),type(features) 43 15. 
\par 
\par #spliting \highlight4 data into training and testing\highlight2  data 16. print "spliting \highlight4 the data into training and testing\highlight2  set" 17. feature_train,feature_test,label_train,label_test = train_test_split(features, labels, test_size=0.20, random_state=42) 18. 19. print "Defining the classifier" 20. 21. ########################################## 22. # \highlight4 K Nearest Neighbor Classifier\highlight2  23. ########################################## 24. 25. x=[] 26. y=[] 27. 
\par 
\par for k in range(1,400,5): 28. clf = KNeighborsClassifier(n_neighbors=k) 29. clf.fit(feature_train,label_train) 30. pred=clf.predict(feature_test) 31. accuracy=accuracy_score(label_test,pred) 32. x.append(k) 33. y.append(accuracy) 34. print "k :",k 35. plt.plot(x,y) 36. plt.title('KNeighnors Classifier Optimization') 37. plt.xlabel('Value of k for KNN') 38. plt.ylabel('Accuracy Score') 39. plt.show() 44 Executing the Algorithm So, \highlight4 for our purposes\highlight2  we tuned n_neighbors parameter of \highlight4 K nearest Neighbors\highlight2  and obtained the following result and is shown below using graph generated by python library matplotlib. The Algorithm took significant time to execute \highlight4 over the dataset\highlight2  as the size of the dataset grew. 
\par 
\par As \highlight4 you can see in\highlight2  code rather than using GridSearchCV we have simply looped over the values for n_neighbor parameter by simple human intuition that its value can vary 1 to 400. n_neighbor values above this range have underperformed drastically there for we took such constraint. Figure 10 .K rest Neighr Claier As, it is clear from the graph the maximum accuracy obtained for classifying the genre was 0.519. 
\par 
\par It should be note that here we not actually talking about accuracy specifically but describing it \highlight4 in terms of\highlight2  F1-score 45 Observation It is clear from the graph that accuracy score (F1-score) initially with the increase of n_neighbor parameter value up to 15, then after it \highlight4 starts to degrade the accuracy\highlight2  score of the algorithm .Maximum value obtained near n_neighbors =15. 
\par 
\par Further Analysis For Detailed recall and precision score of various genre categories \highlight4 we can see\highlight2  the \highlight4 confusion matrix for\highlight2  the above algorithm at the optimal value of n_neighbors. Genre name precision recall F1-score support classical pop and rock 0. 50 0.80 0.62 4742 0.64 0.62 0.63 392 0.59 0.19 0.29 991 0.52 0.48 0.50 2666 0.55 0.17 0.26 856 0.66 0.47 0.55 409 0.30 0.02 0.04 422 0.55 0.22 0.31 644 0.53 0.17 0.26 798 avg /ot 0.52 0.52 0.52 11920 Accuracy: 0.515939597315 Results The highest obtained F1-score for \highlight4 the Decision Tree Classifier\highlight2  is 0.519 or 52% after tuning hyper parameters. 
\par 
\par Then, it \highlight4 starts to decrease\highlight2  with increase with value of n_neighbors. 46 4.2.4. \highlight4 Random Forest Classifier (RFC)\highlight2  \highlight4 It is a\highlight2  meta-estimator that formulates and calculates \highlight4 a large number of decision trees\highlight2  classifiers on various sub parts \highlight4 of the same data set and then\highlight2  averaging all those computed results to improve the prediction accuracy and controlling over fitting the given data set. 
\par 
\par This classifier \highlight4 is an ensemble learning\highlight2  procedure for classification that operates on multiple decision trees. They act as saviours for decision trees preventing them from over fitting the dataset. The algorithm \highlight4 was developed by Leo Breiman and\highlight2  A. Cutler along with some features later on added \highlight4 independently by Ho and Amit and\highlight2  German to build them with control variance. 
\par 
\par In this methodology, all the generated small trees gives some group of ill conditioned (biased) classifier and \highlight4 each one of\highlight2  them weighs certain features more than others and then we draw out final decision tree based on all those biased trees so that over all accuracy goes up for all the classes and at the same time the over fitting problem is solved. Figure 11 .dooxa 47 Some important parameter of RFC that \highlight4 need to be\highlight2  considered while fitting and making predicts are: ? n_estimators: This \highlight4 the number of\highlight2  biased decision trees to be formed while fitting \highlight4 the data set.\highlight2  ? criterion: This function determines the quality of split. It has tw o val \ldblquote gior iiy meae antopy\rdblquote  f meae ofnfmaton gain .By def is value io gi. ? max_features: This is \highlight4 the number of features\highlight2  to be considered while fitting the data. 
\par 
\par For our purpose \highlight4 we have used\highlight2  sqrt (square root (n_features, \highlight4 which is the number of\highlight2  features)) which is same as using auto. ? min_sample_split: This determines \highlight4 the minimum number of\highlight2  data points for splitting criterion. ? n_jobs: To added parallel processing if supported by the system. Optimizing or tuning the parameter of \highlight4 Random Forest Classifier\highlight2  Since \highlight4 in the case of\highlight2  Random forest \highlight4 the number of\highlight2  parameter which we \highlight4 would like to\highlight2  tune or optimize are many and since \highlight4 it is a Gaussian process\highlight2  what we can do is apply Bayesian Optimization to tune the parameters. 
\par 
\par If we had used RandomisedSearchCV It would have taken more than a day to complete its execution that too is not guaranteed to complete in that interval. Actual Code Implementation 1. \highlight4 import numpy as np\highlight2  2. import math 3. \highlight4 from sklearn.multiclass import OneVsRestClassifier\highlight2  4. \highlight4 from sklearn.cross_validation import train_test_split\highlight2  5. \highlight4 from sklearn.ensemble import RandomForestClassifier\highlight2  6. \highlight4 import pickle as pkl\highlight2  7. \highlight4 import matplotlib.pyplot as plt\highlight2  8. \highlight4 from sklearn.grid_search import\highlight2  RandomizedSearchCV 48 9. #Loading labels and \highlight4 features from the\highlight2  pickle file 10. f=open('features','r') 11. labels=pkl.load(f) 12. features=pkl.load(f) 13. 
\par 
\par f.close() 14. print type(labels),type(features) 15. 16. 17. #spliting \highlight4 data into training and testing\highlight2  data 18. print "spliting \highlight4 the data into training and testing\highlight2  set" 19. feature_train,feature_test,label_train,label_test = train_test_split(features, labels, test_size=0.20, random_state=42) 20. print "Defining the classifier" 21. 
\par 
\par clf=OneVsRestClassifier(RandomForestClassifier(min_samples_split=2,min_samples_leaf=1,n_estimators=300)) 22. clf.fit(feature_train,label_train) 23. pred=clf.predict(feature_test) 24. print "confusion_matrix:" 25. print(classification_report(label_test,pred)) Executing the Algorithm First of all, we calculated the optimal parameter values that were obtained by running Bayesian Optimization over the algorithm and after \highlight4 few hours and\highlight2  roughly 30 iterations we got the optimized values for our algorithm. 
\par 
\par As can see \highlight4 we have used\highlight2  meta-estimator that is, OneVsRestClassifier that \highlight4 is used for\highlight2  multiclass classification problem but we already know that Random forest already supports multiclass classification but it is the fact that the every time we run this algorithm all those biased trees are different every time. Therefore, we followed the OneVsRest strategy that runs this algorithm n times and predicts or fits one class versus rest of other classes. 
\par 
\par 49 Observation \highlight4 When we ran\highlight2  the above code and generated the \highlight4 confusion matrix for\highlight2  the same. The result that we got was \highlight4 much better than\highlight2  what was calculated by any other algorithm. It reported a F1-Score of 0.62 or 62% Accuracy. Further Analysis For Detailed recall and precision score of various genre categories \highlight4 we can see\highlight2  the \highlight4 confusion matrix for\highlight2  the above algorithm at the optimal value \highlight4 of various parameters\highlight2  (min_samples_split, n_estimators, and max_features). Aferimii Genre name precision recall F1-score support classical pop and rock 0.46 0.41 0.43 387 0.77 0.84 0.80 362 0.63 0.62 0.62 422 0.54 0.60 0.57 403 0.61 0.57 0.59 390 0.82 0.81 0.81 431 0.47 0.54 0.50 390 0.70 0.59 0.64 0.54 0.57 0.56 384 avg /ot 0.62 0.62 0.62 3583 Results The highest obtained F1-score for \highlight4 the Random Forest Classifier\highlight2  is 0.62 or 62% after optimizing hyperparameters. 50 4.3. 
\par 
\par Bag \highlight4 of words Classification\highlight2  Scheme (Tf-Idf Vectorizer) The bag -of-words (BOW) method is simplified way of storing information \highlight4 of words in\highlight2  documents \highlight4 in terms of\highlight2  word count document wise. This scheme is used in NLP (Natural Language Processing), in this model a text (any word or sentence or document) is stored \highlight4 in the form of\highlight2  bag (multisets) of its words, irrespective of the grammar and even the word sequence but just keeping their frequency. 
\par 
\par In recent days, BOW (Bag-of-word) have been started to be deployed for solving computer vision problems. It \highlight4 is commonly used\highlight2  for document classification, where the frequency of \highlight4 each word in the\highlight2  document is important and it is used as a feature in prediction making. Figure 12 .Bagf rd mp 51 In this project we have implement this scheme over the lyrics \highlight4 of the songs\highlight2  that are there in the dataset and analyzed them for classification. 
\par 
\par For that we created \highlight4 a python script\highlight2  that ran \highlight4 over the dataset\highlight2  and downloaded the available lyrics from lyrics.wikia.com .Now \highlight4 , as the\highlight2  lyrics of any song are copyrighted material many of them are not available online for downloading them. Out of 60000 songs in the dataset we got lyrics of 24000 but again to balance the dataset we worked over 7500 song lyrics. 
\par 
\par The script required used of \highlight4 beautifulsoup and requests\highlight2  library for downloading and parsing out the lyrics \highlight4 out of the\highlight2  html document. After downloading those lyrics they were preprocessed all the punctuations, UTF-8 symbols were removed. After this step, we used NLTK (National Language Toolkit) Library to remove all the stopwords from the lyrics as they provide no information about the genres. 
\par 
\par After that we stemmed each word to its root using SnowBallStemmer so that words that almost mean the same but differ in prefixes get bagged in same bag and hence improving accuracy for predicting genre. Following this step, we used Tf-Idf (Term frequency \endash  Inverse Document Frequency) Vectorizer to form bag-of- words. After that we used \highlight4 Decision Tree classifier\highlight2  for to work on the generated \highlight4 bag of words.\highlight2  Actual Code Implementation 1. \highlight4 from sklearn.feature_extraction.text import\highlight2  TfidfVectorizer 2. import pickle 3. \highlight4 from sklearn.metrics import classification_report\highlight2  4. \highlight4 from sklearn.metrics import accuracy_score\highlight2  5. \highlight4 from sklearn.cross_validation import train_test_split\highlight2  6. \highlight4 from sklearn.feature_extraction.text import\highlight2  CountVectorizer 7. stem_data=open("stemmed_text","r") 52 8. data=pickle.load(stem_data) 9. 
\par 
\par 10. feature_train,feature_test,label_train,label_test = train_test_split(features, labels, test_size=0.20, random_state=42) 11. vectorizer=TfidfVectorizer(sublinear_tf=True,max_df=0.5) 12. feature_train=vectorizer.fit_transform(feature_train) 13. feature_test=vectorizer.transform(feature_test).toarray() 14. 15. \highlight4 from sklearn import\highlight2  tree 16. clf = tree.DecisionTreeClassifier(min_samples_split=23) 17. clf.fit(feature_train,label_train) 18. pred=clf.predict(feature_test) 19. importances = clf.feature_importances_ 20. \highlight4 import numpy as np\highlight2  21. indices = np.argsort(importances)[::-1] 22. print 'Feature Ranking: ' 23. for i in range(10): 24. print "\{\} feature no.\{\} (\{\})".format(i+1,indices[i],importances[indices[i]]) 25. accuracy=accuracy_score(label_test,pred) 26. print "accuracy=",accuracy 27. print "confusion_matrix:" 28. 
\par 
\par print(classification_report(label_test,pred)) Observation \highlight4 When we ran\highlight2  the above code and generated the \highlight4 confusion matrix for\highlight2  the same. The result that we got was \highlight4 much better than\highlight2  what was calculated by bag-of-word scheme used in the base paper. It reported a F1-Score of 0.51 or 51% accuracy. 53 Figure 13 .Bagf rd chrapt Results The highest obtained F1-score for the \highlight4 Bag of words\highlight2  scheme with \highlight4 decision tree Classifier\highlight2  is 0.51 or 51% after optimizing hyperparameters. 
\par 
\par 54 5. Conclusion of Experimentation After thorough analysis with various implementation of the problem following results were concluded. 1. \highlight4 Na\'efve Bayes classifier\highlight2  was very easy to implement and had very less execution time ,but due to strong co-relation between the various features the algorithm went south \highlight4 and unexpected results\highlight2  were obtained 2. 
\par 
\par Talking about accuracies that we obtained from the remaining three classifiers Classifier Name F1-Score Na\'efve Bayes 0.43 Decision Trees 0.46 K- Nearest Neighbor 0.52 Random Forest 0.62 3. \highlight4 Bag of words\highlight2  approach went very well for the smaller dataset, its accuracy is sure to go up if larger number of songs were used. 4. 
\par 
\par Unbalanced Datasets produce underperforming results. 5. Appropriate preprocessing of the dataset is required before \highlight4 it can be\highlight2  \highlight4 used in machine learning Algorithms.\highlight2  55 6. Important Codes In various phases of project FeatureExtraction.py This script helps in extracting out the various features and labels in \highlight4 the million song\highlight2  genre dataset and storing them in suitable format so that they are available to apply \highlight4 machine learning algorithms\highlight2  over them 1. ''''' 2. This file is extracting out the \highlight4 features from the million song\highlight2  genre dataset as per our requirement. 3. 
\par 
\par Making even, balanced dataset to work upon. 4. 5. ''' 6. 7. ''''' 8. No of songs: 59600 9. ************************************************************************** 10. Dataset composition: 11. jazz and blues 4334 12. classic pop and rock 23895 13. classical 1874 14. punk 3200 15. metal 2103 16. pop 1617 17. dance and electronica 4935 18. hip-hop 434 19. soul and reggae 4016 20. folk 13192 21. 22. '' 23. 
\par 
\par 56 24. ''''' 25. No of songs: 59600 26. ************************************************************************** 27. Dataset composition: 28. jazz and blues 4334 29. classic pop and rock 23895 30. classical 1874 31. punk 3200 32. metal 2103 33. pop 2051 34. dance and electronica 4935 35. soul and reggae 4016 36. folk 13192 37. 38. ''' 39. ''''' 40. No of songs: 59600 41. ************************************************************************** 42. 
\par 
\par Dataset composition: 43. jazz and blues: 2001 44. classic pop and rock: 2001 45. classical: 1874 46. punk: 2001 47. metal: 2001 48. pop: 2001 49. dance and electronica: 2001 50. soul and reggae: 2001 51. folk: 2001 52. ''' 53. 54. ########################################################################## 57 55. ''''' 56. 
\par 
\par Helper functions for pre-processing the data before creating pickle object 57. ''' 58. def processdata(lines): 59. features=[] 60. labels=[] 61. \highlight4 for line in\highlight2  lines: 62. temp=line.split(',') 63. labels.append(temp[0]) 64. l=[] 65. for feature in temp[4:]: 66. l.append(float(feature)) 67. features.append(l) 68. return labels,features 69. 70. def targetFeatureSplit( data ): 71. """ 72. \highlight4 given a numpy array like the one returned from\highlight2  73. 
\par 
\par featureFormat, \highlight4 separate out the first\highlight2  feature 74. \highlight4 and put it into its own\highlight2  list (this should be the 75. quantity you want to predict) 76. return targets and features as separate lists 77. (sklearn can generally handle both lists and \highlight4 numpy arrays as\highlight2  78. input formats when training/predicting) 79. """ 80. target = [] 81. features = [] 82. for item in data: 83. target.append( item[0] ) 84. features.append( item[1:] ) 85. 58 86. return target, features 87. 
\par 
\par ####################################################################### 88. \highlight4 import numpy as np\highlight2  89. import os 90. import pickle 91. from sklearn.preprocessing import MinMaxScaler 92. b=open("balanced_msd.txt",'w') 93. line_number=0 94. genres=\{\} 95. with open('msd_genre_dataset.txt','r') as f: 96. lines=f.readlines() 97. \highlight4 for line in\highlight2  lines: 98. line_number+=1 99. if line_number>10: 100. temp=line.split(',') 101. if(temp[0]=='hip-hop'): 102. temp[0]='pop' 103. b.write(",".join(temp)) 104. try: 105. genres[temp[0]]+=1 106. except: 107. genres[temp[0]]=1 108. ''''' 109. print "File composition" 110. for g in genres.keys(): 111. 
\par 
\par print g+": ",genres[g] 112. ''' 113. b.close() 114. ########################################################################### 115. # phase 2: balancing the dataset 116. ########################################################################### 59 117. genres=\{\} 118. b=open("balanced_msd_final.txt",'w') 119. with open('balanced_msd.txt','r') as f: 120. lines=f.readlines() 121. \highlight4 for line in\highlight2  lines: 122. temp=line.split(',') 123. try: 124. 
\par 
\par if(genres[temp[0]]<=2000): 125. genres[temp[0]]+=1 126. b.write(",".join(temp)) 127. except: 128. genres[temp[0]]=1 129. b.write(",".join(temp)) 130. try: 131. os.remove('balanced_msd.txt') 132. except: 133. print "balanced_msd.txt is missing " 134. print "#######################################################################" 135. print " Dataset composition" 136. print "#######################################################################" 137. for g in genres.keys(): 138. 
\par 
\par print g+": ",genres[g] 139. b.close() 140. ################################################################################ 141. ''''' 142. Formatting \highlight4 the data into numpy arrays\highlight2  ,suitable using them on the go. 143. 144. Using pickle to save the serialised object for future analysis of dataset 145. by various algorithms 146. ''' 147. ################################################################################ 60 148. with open('balanced_msd_final.txt','r') as f: 149. lines=f.readlines() 150. labels,features=processdata(lines) 151. np_features=np.array(features) 152. labels=np.array(labels) 153. 154. 
\par 
\par ########################### 155. #feature Scaling on dataset 156. ########################### 157. scaler=MinMaxScaler() 158. np_features=scaler.fit_transform(np_features) 159. 160. ######################## 161. #pickling the data 162. ######################## 163. #print len(features) 164. #print len(np_features) 165. 166. f=open("features","w") 167. pickle.dump(labels,f) 168. pickle.dump(np_features,f) 169. f.close() 170. 171. 
\par 
\par print "Successfully did preprocessing without any error" BayesianOptimization.py This code helps in Tuning the hyper parameters of random forest \highlight4 using Bayesian Optimization\highlight2  library 1. #from __future__ import print_function 2. from __future__ import division 61 3. 4. rom sklearn.datasets import make_classification 5. \highlight4 from sklearn.cross_validation import cross_val_score\highlight2  6. \highlight4 from sklearn.ensemble import RandomForestClassifier as\highlight2  RFC 7. \highlight4 from sklearn.cross_validation import train_test_split\highlight2  8. \highlight4 from sklearn.svm import SVC\highlight2  9. \highlight4 import pickle as pkl\highlight2  10. 
\par 
\par from bayes_opt import BayesianOptimization 11. 12. f=open('features','r') 13. labels=pkl.load(f) 14. features=pkl.load(f) 15. f.close() 16. print "spliting \highlight4 the data into training and testing\highlight2  set" 17. feature_train,feature_test,label_train,label_test = train_test_split(features, labels, test_size=0.20, random_state=42) 18. print "Defining the classifier" 19. 20. def rfccv(n_estimators, min_samples_split, max_features): 21. 
\par 
\par return cross_val_score(RFC(n_estimators=int(n_estimators), 22. min_samples_split=int(min_samples_split), 23. max_features=min(max_features, 0.999), 24. random_state=2), 25. feature_train, label_train, 'f1_weighted', cv=5).mean() 26. 27. \highlight4 if __name__ == "__main__":\highlight2  28. rfcBO = BayesianOptimization(rfccv, \{'n_estimators': (250, 400), 29. 'min_samples_split': (2,15), 30. 'max_features': (0.1, 0.999)\}) 31. 32. 33. 
\par 
\par print('-'*53) 62 34. rfcBO.maximize() 35. 36. print('-'*53) 37. print('Final Results') 38. print('RFC: %f' % rfcBO.res['max']['max_val']) Lyrics.py The Script helps in downloading and parsing the lyrics through lyrics.wikia.com and saving them into a text file for further processing. 1. import requests 2. \highlight4 from bs4 import\highlight2  BeautifulSoup, Comment, NavigableString 3. import sys, codecs, json 4. 5. 6. def getLyrics(singer, song): 7. #Replace spaces with _ 8. singer = singer.replace(' ', '_') 9. song = song.replace(' ', '_') 10. r = requests.get('http://lyrics.wikia.com/\{0\}:\{1\}'.format(singer,song)) 11. s = BeautifulSoup(r.text,'lxml') 12. 
\par 
\par #Get main lyrics holder 13. lyrics = s.find("div",\{'class':'lyricbox'\}) 14. if lyrics is None: 15. #raise ValueError("Song or Singer does not exist or the API does not have Lyrics") 16. return None 17. #Remove Scripts 18. [s.extract() for s in lyrics('script')] 19. 20. #Remove Comments 63 21. comments = lyrics.findAll(text=lambda text:isinstance(text, Comment)) 22. [comment.extract() for comment in comments] 23. 24. #Remove unecessary tags 25. for tag in ['div','i','b','a']: 26. for match in lyrics.findAll(tag): 27. match.replaceWithChildren() 28. #Get output as a string and remove non unicode characters and replace <br> with newlines 29. lyrics= str(lyrics).replace('\\n','').replace('<br/>',' ') 30. 
\par 
\par output=lyrics[22:-6:] 31. try: 32. return output 33. except: 34. return output.encode('utf-8') 35. 36. 37. genres=\{\} 38. lyrics_found=0 39. import codecs 40. y=codecs.open("songLyrics1.txt","w") 41. line_num=0 42. with codecs.open('msd_genre_dataset.txt','r') as f: 43. \highlight4 for line in\highlight2  f: 44. if line_num<=27432: 45. pass 46. else: 47. temp=line.split(',') 48. #print "artist name=",temp[2],"Title=",temp[3] 49. lyrics=getLyrics(temp[2],temp[3]) 50. if(lyrics!=None): 51. if(lyrics.split(' ')[0]!='<span'): 64 52. try: 53. 
\par 
\par genres[temp[0]]+=1 54. except: 55. genres[temp[0]]=1 56. lyrics_found+=1 57. y.write(temp[0]+'**/**'+lyrics) 58. y.write('\\n') 59. if(line_num%100==0): 60. print "At present progress\\n" 61. print "Songs processed: "+ str(line_num) 62. print "Lyrics saved upto now:" +str(lyrics_found) 63. for gen in genres.keys(): 64. print gen,":",genres[gen] 65. line_num+=1 66. y.close() ProcessLyrics.py After the lyrics have been downloaded and saved into text file, it \highlight4 has to be\highlight2  preprocessed before it, \highlight4 bag of words\highlight2  is generated and this script helps in the same. 
\par 
\par 1. from __future__ import division 2. from nltk.corpus import stopwords 3. from nltk.stem import SnowballStemmer 4. import unicodedata 5. import codecs 6. import string 7. import pickle 8. stemmer = SnowballStemmer('english') 65 9. cachedStopWords = stopwords.words("english") 10. data=[] 11. with codecs.open('finalLyricsList2.txt','r') as f: 12. lines=f.readlines() 13. count=0 14. \highlight4 for line in\highlight2  lines: 15. 16. labels,features=line.split('**/**') 17. features = unicode(features, "utf-8") 18. 
\par 
\par features = unicodedata.normalize('NFKD',features).encode('ascii','ignore') 19. features=features.translate(None, string.punctuation) 20. features=features.lower() 21. features=[word for word in features.split() if word not in cachedStopWords] 22. for word in features: 23. stemmer.stem(word) 24. features=" ".join(features) 25. data.append([labels,features]) 26. count+=1 27. if(count%500==0): 28. print "completed:",count/len(lines)*100 29. 30. 31. genres=\{\} 32. \highlight4 for line in\highlight2  lines: 33. 
\par 
\par labels,features=line.split('**/**') 34. try: 35. genres[labels]+=1 36. except: 37. genres[labels]=0 38. print "File composition" 39. for g in genres.keys(): 66 40. print g+": ",genres[g] 41. 42. #saving into serialized object 43. stem_data=open("stemmed_text",'wb') 44. pickle.dump(data,stem_data) 45. stem_data.close() load_stem_data.py Script is working with processed data to use \highlight4 bag of words\highlight2  and make prediction 1. \highlight4 from sklearn.feature_extraction.text import\highlight2  TfidfVectorizer 2. import pickle 3. 
\par 
\par from \highlight4 sklearn.metrics import classification_report\highlight2  4. \highlight4 from sklearn.metrics import accuracy_score\highlight2  5. \highlight4 from sklearn.cross_validation import train_test_split\highlight2  6. \highlight4 from sklearn.feature_extraction.text import\highlight2  CountVectorizer 7. stem_data=open("stemmed_text","r") 8. data=pickle.load(stem_data) 9. #print data[0] 10. ''''' 11. b=open("finalLyricsList.txt","w") 12. with open('songLyrics.txt','r') as f: 13. lines=f.readlines() 14. \highlight4 for line in\highlight2  lines: 15. labels,features=line.split('**/**') 16. if(labels=='hip-hop'): 17. b.write("pop**/**"+features) 18. if(labels!='classical' and labels!='hip-hop'): 19. b.write(line) 20. b.close() 67 21. b=open("finalLyricsList.txt","r") 22. lines=b.readlines() 23. genres=\{\} 24. \highlight4 for line in\highlight2  lines: 25. labels,features=line.split('**/**') 26. try: 27. genres[labels]+=1 28. except: 29. 
\par 
\par genres[labels]=0 30. print "File composition" 31. for g in genres.keys(): 32. print g+": ",genres[g] 33. ''' 34. 35. ''''' 36. genres=\{\} 37. b=open("finalLyricsList2.txt","w") 38. with open('finalLyricsList.txt','r') as f: 39. lines=f.readlines() 40. \highlight4 for line in\highlight2  lines: 41. labels,features=line.split('**/**') 42. try: 43. genres[labels]+=1 44. except: 45. genres[labels]=0 46. if(genres[labels]<=1000): 47. b.write(line) 48. b.close() 49. b=open("finalLyricsList2.txt","r") 50. lines=b.readlines() 51. genres=\{\} 68 52. \highlight4 for line in\highlight2  lines: 53. labels,features=line.split('**/**') 54. try: 55. genres[labels]+=1 56. except: 57. genres[labels]=0 58. 
\par 
\par print "File composition" 59. for g in genres.keys(): 60. print g+": ",genres[g] 61. 62. ''' 63. def targetFeatureSplit( data ): 64. """ 65. \highlight4 given a numpy array like the one returned from\highlight2  66. \highlight4 featureFormat, separate out the first\highlight2  feature 67. \highlight4 and put it into its own\highlight2  list (this should be the 68. quantity you want to predict) 69. 70. return targets and features as separate lists 71. 72. (sklearn can generally handle both lists and \highlight4 numpy arrays as\highlight2  73. 
\par 
\par input formats when training/predicting) 74. """ 75. target = [] 76. features = [] 77. for item in data: 78. target.append( item[0] ) 79. features.append( item[1] ) 80. return target, features 81. 82. labels,features=targetFeatureSplit(data) 69 83. #print data[0] 84. ''''' 85. 86. feature_train,feature_test,label_train,label_test = train_test_split(features, labels, test_size=0.20, random_state=42) 87. vectorizer=CountVectorizer() 88. 
\par 
\par train_counts = vectorizer.fit_transform(feature_train) 89. print train_counts.shape 90. print train_counts 91. print vectorizer.vocabulary_.get(u'la') 92. 93. ''' 94. feature_train,feature_test,label_train,label_test = train_test_split(features, labels, test_size=0.20, random_state=42) 95. vectorizer=TfidfVectorizer(sublinear_tf=True,max_df=0.5) 96. feature_train=vectorizer.fit_transform(feature_train) 97. feature_test=vectorizer.transform(feature_test).toarray() 98. \highlight4 from sklearn import\highlight2  tree 99. clf = tree.DecisionTreeClassifier(min_samples_split=23) 100. clf.fit(feature_train,label_train) 101. pred=clf.predict(feature_test) 102. importances = clf.feature_importances_ 103. \highlight4 import numpy as np\highlight2  104. indices = np.argsort(importances)[::-1] 105. print 'Feature Ranking: ' 106. for i in range(10): 107. print "\{\} feature no.\{\} (\{\})".format(i+1,indices[i],importances[indices[i]]) 108. print vectorizer.get_feature_names()[14343] 109. accuracy=accuracy_score(label_test,pred) 110. print "accuracy=",accuracy 111. print "confusion_matrix:" 112. 
\par 
\par print(classification_report(label_test,pred)) 70 7. Future scope of the project In future both \highlight4 bag of words\highlight2  \highlight4 and random forest\highlight2  strategy can be implemented together to further improve \highlight4 the accuracy of\highlight2  the resulting classifier and then same can be used in MIR systems (Music Identification and Recommender), \highlight4 that can be\highlight2  incorporated in a music app and can improve user experience. 71 8. 
\par 
\par References [1] From Classical to Hip-hop: Can Machine Learn Genre? A student publication by Aaron kravitz, Eliza lupone, Ryan Diaz [2] Music Genre https://en.wikipedia.org/wiki/Music_genre [3] \highlight4 Analysis of the organizational and informational value of links in psychology and geology popular science hyper\highlight2  articles, http://www.scielo.cl/scielo.php?pid=S071809342008000300004&script=sci_arttext [4] MSD genrase.\rdblquote  [ine]lable: http://labrosa.ee.columbia.edu/millionsong/sites/default/files/AdditionalFiles/msd genre dataset.zip [5] Lyrics Retrieving http://lyrics.wikia.com/ [6] Introduction to Machine Learning, https://www.udacity.com/course/intro-to-machine-learning--ud120 [7] Preprocessing data http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing [8] Python Libraries http://scikit-learn.org/stable/tutorial/basic/tutorial.html 
\par 
\par INTERNET SOURCES:
\par -------------------------------------------------------------------------------------------
\par 0% - https://www.scribd.com/doc/312347201/The
\par 0% - Empty
\par 0% - https://www.researchgate.net/profile/San
\par 0% - https://www.goodreads.com/work/quotes/22
\par 0% - http://tnu.podelise.ru/docs/index-299589
\par 0% - http://ethesis.nitrkl.ac.in/4295/1/Simul
\par 0% - http://www.slideshare.net/bostonredsoxsu
\par 0% - http://varimzg.ga/esw
\par 0% - http://acknowledgementsample.com/sample-
\par 0% - http://delhicourts.nic.in/annual_report.
\par 0% - https://issuu.com/saakshiterway/docs/und
\par 0% - https://www.goldenkey.org/scholarships-a
\par 0% - https://rateyourmusic.com/list/ElectricL
\par 0% - http://www.knowla.org/category/5/Music/
\par 0% - https://www.ijsr.net/archive/v3i6/MDIwMT
\par 0% - https://en.wikipedia.org/wiki/Antievolut
\par 0% - http://www.researchgate.net/profile/Alle
\par 0% - https://gist.github.com/mrflip/3307566
\par 0% - http://www.mdpi.com/1424-8220/15/12/2985
\par 0% - http://webscience.org.br/wiki/images/f/f
\par 0% - https://www.scribd.com/doc/296789242/Pra
\par 0% - http://tm.durusau.net/?cat=677
\par 0% - http://drum.lib.umd.edu/bitstream/1903/3
\par 0% - https://www.researchgate.net/figure/5094
\par 0% - https://en.wikipedia.org/wiki/Baysian_cl
\par 0% - https://www.researchgate.net/figure/2675
\par 0% - http://in.mathworks.com/help/stats/class
\par 0% - http://in.mathworks.com/help/stats/class
\par 0% - http://cs.brown.edu/courses/cs143/proj3/
\par 0% - http://trec.nist.gov/pubs/trec15/papers/
\par 0% - http://nptel.ac.in/courses/105105041/Mod
\par 0% - http://research.ijcaonline.org/volume112
\par 0% - http://www.cs.utexas.edu/users/ikarpov/R
\par 0% - http://www.freebiblecommentary.org/old_t
\par 0% - http://nptel.ac.in/courses/117106100/Mod
\par 0% - https://www.coursehero.com/file/p4k1jcl/
\par 0% - http://www.blueprint-epigenome.eu/UserFi
\par 0% - http://www.youtube.com/watch?v=u7uxkFl5w
\par 0% - https://sites.google.com/site/icmlwhealt
\par 0% - http://charuaggarwal.net/classbook.pdf
\par 0% - http://studentnet.cs.manchester.ac.uk/ug
\par 0% - https://pypi.python.org/pypi/DecisionTre
\par 0% - http://www.csee.umbc.edu/~tinoosh/cmpe65
\par 0% - http://link.springer.com/article/10.1007
\par 0% - https://www.researchgate.net/publication
\par 0% - http://biblehub.com/psalms/71-1.htm
\par 0% - https://en.wikipedia.org/wiki/Christmas
\par 0% - https://en.wikipedia.org/wiki/Art
\par 0% - http://www.cs.cmu.edu/~learning/
\par 0% - http://users.cis.fiu.edu/~taoli/pub/icas
\par 0% - http://www.holidayiq.com/Courteous-staff
\par 0% - http://www.123helpme.com/search.asp?text
\par 0% - https://en.wikipedia.org/wiki/Music_And_
\par 0% - http://publishing.sfu.ca/tag/book-publis
\par 0% - https://www.consumeraffairs.com/music-in
\par 0% - https://en.wikipedia.org/wiki/Sustainabi
\par 0% - http://ieeexplore.ieee.org/stamp/stamp.j
\par 0% - http://www.sciencedirect.com/science/art
\par 0% - http://alumni.media.mit.edu/~chaiwei/pap
\par 0% - http://dl.acm.org/citation.cfm?id=210657
\par 0% - http://www.answers.com/Q/What_is_a_high_
\par 0% - https://www.researchgate.net/publication
\par 0% - http://www.gaussianprocess.org/
\par 0% - http://www.ijoee.org/uploadfile/2013/100
\par 0% - http://bmcbioinformatics.biomedcentral.c
\par 0% - http://www.researchgate.net/publication/
\par 0% - http://natureofcode.com/book/chapter-10-
\par 0% - http://www.iaeng.org/publication/IMECS20
\par 0% - http://www.w3schools.com/tags/
\par 0% - http://alt.qcri.org/semeval2015/cdrom/pd
\par 0% - http://www.journals.elsevier.com/artific
\par 0% - https://msdn.microsoft.com/en-us/library
\par 0% - https://en.wikipedia.org/wiki/Principal_
\par 0% - http://www.municipalbev.com/magazines/ma
\par 0% - http://manuals.bioinformatics.ucr.edu/ho
\par 0% - https://eight2late.wordpress.com/categor
\par 0% - http://dl.acm.org/citation.cfm?id=860487
\par 0% - https://quizlet.com/5669972/ap-psycholog
\par 0% - http://www.researchgate.net/publication/
\par 0% - http://citeseerx.ist.psu.edu/showciting?
\par 0% - https://www.scribd.com/doc/296789242/Pra
\par 0% - http://www.researchgate.net/publication/
\par 0% - https://rateyourmusic.com/game_genre
\par 0% - https://en.wikipedia.org/wiki/Music_genr
\par 0% - https://dlsanthology.commons.mla.org/dig
\par 0% - https://open.library.ubc.ca/handle/2429/
\par 0% - http://www.researchgate.net/profile/Caro
\par 0% - http://dl1322.xiaoma.com/bbs/TPOtingliu.
\par 0% - https://en.wikipedia.org/wiki/Music_genr
\par 0% - http://cs229.stanford.edu/proj2013/Fauci
\par 0% - http://cs229.stanford.edu/proj2010/HuhMi
\par 0% - https://www.scribd.com/doc/293140408/Luc
\par 0% - http://csusap.csu.edu.au/~rpaul/paper/TB
\par 0% - http://www.ijetae.com/files/Volume3Issue
\par 0% - http://ijirset.com/upload/2016/march/64_
\par 0% - https://aps.arxiv.org/pdf/1605.03557.pdf
\par 0% - http://www.hindawi.com/journals/mpe/2015
\par 0% - http://www.google.com/patents/US6735550
\par 0% - http://www.digplanet.com/wiki/Short-time
\par 0% - https://en.wikipedia.org/wiki/List_of_hi
\par 0% - https://www.goodreads.com/book/show/7815
\par 0% - http://www.thesaurus.com/browse/classifi
\par 0% - https://en.wikipedia.org/wiki/Classic_Ro
\par 0% - https://en.wikipedia.org/wiki/Electronic
\par 0% - http://aqalu.com/Folk_music8430.htm
\par 0% - http://www.londonjazznews.com/2016/05/cd
\par 0% - http://www.youtube.com/watch?v=rTaEWNf5Z
\par 0% - https://en.wikipedia.org/wiki/Drum_and_b
\par 0% - http://www.punkstory.com/
\par 0% - http://schools-wikipedia.org/wp/r/Reggae
\par 0% - http://www.answers.com/Q/In_this_reggae_
\par 0% - http://dataffiti.com/
\par 0% - https://www.irs.gov/irm/part4/irm_04-032
\par 0% - http://web.niaccist.niacc.edu/~milleste/
\par 0% - http://homepages.inf.ed.ac.uk/rbf/HIPR2/
\par 0% - http://www.ijarcsse.com/docs/papers/Volu
\par 0% - http://www.britannica.com/topic/attentio
\par 0% - http://hume.ucdavis.edu/mattey/phi102/an
\par 0% - https://en.wikipedia.org/wiki/Joke
\par 0% - https://discussions.apple.com/thread/567
\par 0% - http://www.academia.edu/2821380/Music_Ge
\par 0% - http://users.cis.fiu.edu/~lli003/Music/m
\par 0% - http://hivoltagerecords.com/cd/metal-pun
\par 0% - https://litigation-essentials.lexisnexis
\par 0% - http://making.nextbigsound.com/post/9780
\par 0% - http://www.guitarforbeginners.com/tempo.
\par 0% - http://www.wikihow.com/Calculate-the-Tim
\par 0% - https://en.wikipedia.org/wiki/Musical_ke
\par 0% - https://www.studyblue.com/notes/note/n/m
\par 0% - http://www.physicsphunhouse.com/physics/
\par 0% - http://www.dolmetsch.com/defst2.htm
\par 0% - http://dl.acm.org/citation.cfm?id=149765
\par 0% - http://stackoverflow.com/questions/31681
\par 0% - http://pastebin.com/HAZMghw4
\par 0% - https://shankarmsy.github.io/posts/svm-s
\par 0% - http://lenguyenthedat.com/minimal-data-s
\par 0% - http://mydown.yesky.com/wenku/187/999276
\par 0% - http://napitupulu-jon.appspot.com/posts/
\par 0% - http://napitupulu-jon.appspot.com/posts/
\par 0% - http://www.iaeme.com/MasterAdmin/UploadF
\par 0% - http://stackoverflow.com/questions/32775
\par 0% - http://sourceforge.net/p/docutils/mailma
\par 0% - http://stackoverflow.com/questions/16050
\par 0% - http://stackoverflow.com/questions/84505
\par 0% - http://54081964.r.msn.com/?ld=d35eghhv6b
\par 0% - https://en.wikipedia.org/wiki/Artificial
\par 0% - http://www.tutorialspoint.com/artificial
\par 0% - https://www.scribd.com/doc/192497909/Pos
\par 0% - http://dl.acm.org/citation.cfm?id=156360
\par 0% - http://hbswk.hbs.edu/item/whats-the-best
\par 0% - https://en.wikipedia.org/wiki/Machine_le
\par 0% - http://www.cs.tufts.edu/research/ml/inde
\par 0% - http://www.clopinet.com/isabelle/Project
\par 0% - http://www.advancedsourcecode.com/google
\par 0% - https://home.ubalt.edu/ntsbarsh/business
\par 0% - http://nepis.epa.gov/Exe/ZyPURL.cgi?Dock
\par 0% - https://en.wikipedia.org/wiki/Data_minin
\par 0% - https://wireless.vt.edu/pdfs/WVT_Seminar
\par 0% - https://www.scribd.com/doc/136861079/Kit
\par 0% - http://bsolano.com/ecci/claroline/backen
\par 0% - http://www.cs.ucr.edu/~eamonn/CE/Bayesia
\par 0% - http://catalog.flatworldknowledge.com/bo
\par 0% - https://www.scribd.com/doc/271941657/Mac
\par 0% - http://www.sciencedirect.com/science/art
\par 
\par 0% - https://en.m.wikipedia.org/wiki/Naive_Ba
\par 0% - https://msdn.microsoft.com/en-us/library
\par 0% - https://www.researchgate.net/publication
\par 0% - https://en.wikipedia.org/wiki/Naive_Baye
\par 0% - https://www.coursehero.com/file/p19un5b/
\par 0% - http://web.cse.ohio-state.edu/~srini/674
\par 0% - http://documentation.statsoft.com/STATIS
\par 0% - https://www.psychologytoday.com/blog/han
\par 0% - http://machinelearningmastery.com/naive-
\par 0% - http://fyae.sdes.ucf.edu/documents/calcu
\par 0% - http://www.ncbi.nlm.nih.gov/pmc/articles
\par 0% - https://gist.github.com/1fc75314652e1a99
\par 0% - http://pastebin.com/KzHFiqv3
\par 0% - https://www.researchgate.net/topic/optim
\par 0% - http://www.sciencedirect.com/science/art
\par 0% - http://sites.insead.edu/facultyresearch/
\par 0% - http://pulsemusic.proboards.com/thread/1
\par 0% - http://bmcbioinformatics.biomedcentral.c
\par 0% - http://docs.opencv.org/2.4/modules/ml/do
\par 0% - http://link.springer.com/article/10.1007
\par 0% - http://sciencedomain.org/download/MTE1MD
\par 0% - https://en.wikipedia.org/wiki/Talk:Entro
\par 0% - http://www.rchelicopterfun.com/rc-helico
\par 0% - http://www.ats.ucla.edu/stat/stata/dae/l
\par 0% - http://stackoverflow.com/questions/29451
\par 0% - https://shankarmsy.github.io/stories/rf-
\par 0% - http://rasbt.github.io/mlxtend/user_guid
\par 0% - http://bmcbioinformatics.biomedcentral.c
\par 0% - http://www.tutorialspoint.com/data_minin
\par 0% - https://en.wikipedia.org/wiki/Cross-vali
\par 0% - http://www.edii.uclm.es/~useR-2013/Tutor
\par 0% - http://altons.github.io/sas/2013/05/22/c
\par 0% - http://www.sciencedirect.com/science/art
\par 0% - http://www.scipy-lectures.org/advanced/m
\par 0% - https://www.kaggle.com/c/datasciencebowl
\par 0% - http://www.cynthiaodonnell.com/category/
\par 0% - http://kitchingroup.cheme.cmu.edu/pycse/
\par 0% - http://courseprojects.souravsengupta.com
\par 0% - http://blog.csdn.net/rss.html?type=colum
\par 0% - http://demo.netfoucs.com/jasonding1354/a
\par 0% - http://www.ncbi.nlm.nih.gov/pmc/articles
\par 0% - http://www.danafosmer.com/2/category/lab
\par 0% - https://engineering.purdue.edu/~landgreb
\par 0% - http://www.public.iastate.edu/~carlos/so
\par 0% - https://www.researchgate.net/publication
\par 0% - https://docs.google.com/document/d/1i5hW
\par 0% - http://getbootstrap.com/css/
\par 0% - http://www.sciencedirect.com/science/art
\par 0% - http://www.researchgate.net/profile/Moha
\par 0% - http://www.sciencedirect.com/science/art
\par 0% - http://www.sciencedirect.com/science/art
\par 0% - https://www.scribd.com/doc/6910841/Stati
\par 0% - http://wwwimages.adobe.com/www.adobe.com
\par 0% - https://www.researchgate.net/publication
\par 0% - http://scikit-learn.org/stable/modules/n
\par 0% - http://citeseerx.ist.psu.edu/viewdoc/dow
\par 0% - http://arxiv.org/pdf/1007.0085
\par 0% - http://scikit-learn.org/stable/modules/n
\par 0% - http://www.academia.edu/9990916/Classifi
\par 0% - https://en.wikipedia.org/wiki/K-means_cl
\par 0% - http://machinelearningmastery.com/tutori
\par 0% - https://shankarmsy.github.io/stories/knn
\par 0% - http://www.wikicoursenote.com/wiki/Stat8
\par 0% - https://rkbookreviews.wordpress.com/cate
\par 0% - http://pastebin.com/DbQTRcKw
\par 0% - http://stackoverflow.com/questions/33078
\par 0% - http://bmcbioinformatics.biomedcentral.c
\par 0% - http://php-nlp-tools.com/blog/
\par 0% - https://en.wikipedia.org/wiki/Talk:Faith
\par 0% - https://www.scribd.com/doc/310008409/Eva
\par 0% - http://www.sciencedirect.com/science/art
\par 0% - http://ufdc.ufl.edu/UF00094069/00026
\par 0% - http://dl.acm.org/citation.cfm?id=167724
\par 0% - http://illuminations.nctm.org/LessonDeta
\par 0% - https://www.researchgate.net/publication
\par 0% - http://documents.software.dell.com/stati
\par 0% - https://en.wikipedia.org/wiki/Random_for
\par 0% - https://advanceddataanalytics.net/whatis
\par 0% - https://advanceddataanalytics.net/whatis
\par 0% - http://www.sciencedirect.com/science/art
\par 0% - https://www.scribd.com/doc/307428035/Net
\par 0% - http://www.nltk.org/book/ch06.html
\par 0% - https://www.researchgate.net/profile/Vic
\par 0% - https://en.wikipedia.org/wiki/Software_t
\par 0% - http://link.springer.com/article/10.1007
\par 0% - http://jmlr.org/proceedings/papers/v51/w
\par 0% - http://stackoverflow.com/questions/31681
\par 0% - http://online.cambridgecoding.com/notebo
\par 0% - http://www.kuntalganguly.com/feeds/posts
\par 0% - http://www.c2.com/cgi/wiki?OptimizationS
\par 0% - https://en.wikibooks.org/wiki/Algorithms
\par 0% - https://www.udacity.com/course/viewer#!/
\par 0% - http://www.researchgate.net/publication/
\par 0% - http://www.sciencedirect.com/science/art
\par 0% - http://www.science.gov/topicpages/r/resu
\par 0% - http://www.montanarigiulio.com/wp-conten
\par 0% - http://waset.org/publications/10000118/r
\par 0% - http://www.researchgate.net/profile/Khai
\par 0% - http://golancourses.net/2011spring/categ
\par 0% - https://www.quora.com/Is-it-possible-to-
\par 0% - https://www.researchgate.net/topic/decis
\par 0% - http://pastebin.com/NW2nv1i6
\par 0% - http://slideplayer.com/slide/4206439/
\par 0% - http://www.cynthiaodonnell.com/category/
\par 0% - https://shankarmsy.github.io/stories/rf-
\par 0% - http://ieeexplore.ieee.org/xpls/icp.jsp?
\par 0% - http://dl.acm.org/citation.cfm?id=187925
\par 0% - http://pages.vassar.edu/abigailbaird/fil
\par 0% - http://statforge.com/k-nearest-neighbor/
\par 0% - http://shodhganga.inflibnet.ac.in/bitstr
\par 0% - http://dl.acm.org/citation.cfm?doid=2187
\par 0% - https://www.scribd.com/doc/98146956/Cvpr
\par 0% - http://people.duke.edu/~ccc14/pcfb/capst
\par 0% - https://www.scribd.com/doc/30104271/NCER
\par 0% - http://www.science.gov/topicpages/d/diam
\par 0% - http://blog.sigopt.com/post/140871698423
\par 0% - https://www.kaggle.com/c/datasciencebowl
\par 0% - https://iwatobipen.wordpress.com/tag/rdk
\par 0% - https://www.datarobot.com/blog/classific
\par 0% - http://aidiary.hatenablog.com/rss
\par 0% - http://www.schuirink.net/xml/news.php/it
\par 0% - http://stackoverflow.com/questions/16367
\par 0% - http://bcdcspatial.blogspot.de/
\par 0% - http://stackoverflow.com/questions/32495
\par 0% - http://napitupulu-jon.appspot.com/posts/
\par 0% - https://gist.github.com/1fc75314652e1a99
\par 0% - http://pixelmonkey.org/pub/python-traini
\par 0% - https://scrutinizer-ci.com/g/quantopian/
\par 0% - http://blogs.mathworks.com/loren/2006/06
\par 0% - http://radimrehurek.com/data_science_pyt
\par 0% - https://www.scribd.com/doc/307671183/Sci
\par 0% - http://www.slideshare.net/yuhuang/object
\par 0% - http://www.academia.edu/8545982/Analysis
\par 0% - http://www.youtube.com/watch?v=lSwvUmZCv
\par 0% - http://toolsforbigdata.com/week-03-pytho
\par \f1 
\par }

